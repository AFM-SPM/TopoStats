{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from unet import unet_model\n",
    "from unet_any_size_single_output import unet_model\n",
    "import random\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "from datetime import datetime\n",
    "\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.filters import hessian\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from skimage.morphology import label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "# TopoStats needs to be >= version 2.1.0\n",
    "# from topostats import io\n",
    "# from topostats import grain_finding_cats_unet\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for key, value in os.environ.items():\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that your GPU is working\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_IMAGE_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/images_flattened_all/\")\n",
    "MASK_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/images_edge_detection_upper_labels_multiclass_sigma_4\")\n",
    "\n",
    "MODEL_SAVE_DIR = Path(\"./saved_models\")\n",
    "CHANNELS = 1\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Get the number of .png images\n",
    "NUM_IMAGES = len(list(ORIGINAL_IMAGE_DIR.glob(\"*.png\")))\n",
    "print(f\"Number of images: {NUM_IMAGES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An image generator that loads images as they are needed\n",
    "def image_generator(image_indexes, batch_size=4):\n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_image_indexes = np.random.choice(a=image_indexes, size=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "\n",
    "        # Load the image and ground truth\n",
    "        for index in batch_image_indexes:\n",
    "            # Find the index as the only number in the filename\n",
    "            # index = re.search(r\"\\d+\", image_path)\n",
    "            # print(index)\n",
    "            image = cv2.imread(str(ORIGINAL_IMAGE_DIR / f\"training_image_{index}.png\"), 0)\n",
    "            image = Image.fromarray(image)\n",
    "            image = image.resize((512, 512))\n",
    "            image = np.array(image)\n",
    "            # Normalise the image\n",
    "            image = image - np.min(image)\n",
    "            image = image / np.max(image)\n",
    "\n",
    "            ground_truth = np.load(MASK_DIR / f\"mask_array_{index}.npy\")\n",
    "            ground_truth = ground_truth.astype(bool)\n",
    "            ground_truth = Image.fromarray(ground_truth.astype(np.uint8))\n",
    "            ground_truth = ground_truth.resize((512, 512))\n",
    "            ground_truth = np.array(ground_truth).astype(int)\n",
    "\n",
    "            # Augment the images\n",
    "            # Flip the images 50% of the time\n",
    "            if random.choice([0, 1]) == 1:\n",
    "                image = np.flip(image, axis=1)\n",
    "                ground_truth = np.flip(ground_truth, axis=1)\n",
    "            # Rotate the images by either 0, 90, 180, or 270 degrees\n",
    "            rotation = random.choice([0, 1, 2, 3])\n",
    "            image = np.rot90(image, rotation)\n",
    "            ground_truth = np.rot90(ground_truth, rotation)\n",
    "\n",
    "            batch_input.append(image)\n",
    "            batch_output.append(ground_truth)\n",
    "\n",
    "        batch_x = np.array(batch_input).astype(np.float32)\n",
    "        batch_y = np.array(batch_output).astype(np.float32)\n",
    "\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the generator is doing the right thing\n",
    "batch_generator = image_generator([0, 1, 2, 3, 4], batch_size=4)\n",
    "(batch_x, batch_y) = next(batch_generator)\n",
    "for image, mask in zip(batch_x, batch_y):\n",
    "    plt.imshow(image)\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    print(f\"image max: {np.max(image)}\")\n",
    "    print(f\"image min: {np.min(image)}\")\n",
    "    plt.show()\n",
    "    plt.imshow(mask)\n",
    "    print(f\"mask shape: {mask.shape}\")\n",
    "    print(f\"mask unique: {np.unique(mask)}\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"mask dtype: {mask.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split what images are used for training and validation\n",
    "train_image_indexes, validation_image_indexes = train_test_split(range(0, NUM_IMAGES), test_size=0.2, random_state=SEED)\n",
    "\n",
    "print(f\"Number of training images: {len(train_image_indexes)}\")\n",
    "print(f\"Number of validation images: {len(validation_image_indexes)}\")\n",
    "\n",
    "print(f\"Training image indexes: {train_image_indexes}\")\n",
    "print(f\"Validation image indexes: {validation_image_indexes}\")\n",
    "\n",
    "# Create the generators\n",
    "train_generator = image_generator(train_image_indexes, batch_size=4)\n",
    "validation_generator = image_generator(validation_image_indexes, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "model = unet_model(IMG_HEIGHT=512, IMG_WIDTH=512, IMG_CHANNELS=CHANNELS)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    # How many steps (batches of samples) to draw from generator before declaring one epoch finished and starting the next epoch\n",
    "    steps_per_epoch=NUM_IMAGES // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    # How many steps (batches) to yield from validation generator at the end of every epoch\n",
    "    validation_steps=NUM_IMAGES // BATCH_SIZE,\n",
    "    verbose=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-or-truck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
