{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from unet import unet_model\n",
    "from multi_class_unet import multiclass_unet_model\n",
    "import random\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "from datetime import datetime\n",
    "\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.filters import hessian\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from skimage.morphology import label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "# TopoStats needs to be >= version 2.1.0\n",
    "from topostats import io\n",
    "from topostats import grain_finding_cats_unet\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for key, value in os.environ.items():\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that your GPU is working\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_DIR = Path('/home/sylvia/Desktop/dl_data/images/')\n",
    "# MASK_DIR = Path('/home/sylvia/Desktop/dl_data/ground_truth/')\n",
    "# MODEL_SAVE_DIR = Path('/home/sylvia/Desktop/dl_data/saved_models/')\n",
    "IMAGE_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/images_edge_detection_upper_training_sigma_4/\")\n",
    "ORIGINAL_IMAGE_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/images_flattened_all/\")\n",
    "# MASK_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/ground_truth_edges/\")\n",
    "# MASK_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/images_edge_detection_upper_labels_sigma_4/\")\n",
    "MASK_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/images_edge_detection_upper_labels_multiclass_sigma_4/\")\n",
    "\n",
    "MODEL_SAVE_DIR = Path(\"./catsnet/saved_models/\")\n",
    "SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ridges(gray, sigma=1.0):\n",
    "    H_elems = hessian_matrix(gray, sigma=sigma, order=\"rc\")\n",
    "    maxima_ridges, minima_ridges = hessian_matrix_eigvals(H_elems)\n",
    "    return minima_ridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_dataset = []\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "print(\" -- images --\")\n",
    "\n",
    "\n",
    "original_images = ORIGINAL_IMAGE_DIR.glob(\"*.png\")\n",
    "original_images = sorted(original_images, key=lambda p: p.name)\n",
    "print(original_images)\n",
    "for index, image_name in enumerate(original_images):\n",
    "    print(image_name)\n",
    "    image = cv2.imread(str(ORIGINAL_IMAGE_DIR / image_name), 0)\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((SIZE, SIZE))\n",
    "    image = np.array(image)\n",
    "    # Nomalise\n",
    "    image = image - np.min(image)\n",
    "    image = image / np.max(image)\n",
    "    original_image_dataset.append(image)\n",
    "\n",
    "images = os.listdir(IMAGE_DIR)\n",
    "images = sorted(images)\n",
    "print(images)\n",
    "for index, image_name in enumerate(images):\n",
    "    print(image_name)\n",
    "    if image_name.split(\".\")[-1] == \"png\":\n",
    "        image = cv2.imread(str(IMAGE_DIR / image_name), 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image = np.array(image)\n",
    "        # Detect ridges\n",
    "        # image = detect_ridges(image)\n",
    "        # fig, ax = plt.subplots(1, 2, figsize=(3, 3))\n",
    "        # sns.kdeplot(image.flatten(), ax=ax[0])\n",
    "        image = image - np.min(image)\n",
    "        image = image / np.max(image)\n",
    "        image_dataset.append(image)\n",
    "        # sns.kdeplot(image.flatten(), ax=ax[1])\n",
    "        # plt.show()\n",
    "        # print(f\"image min: {np.min(image)} image max: {np.max(image)}\")\n",
    "        # image_flip_y = np.flip(image, axis=0)\n",
    "        # image_flip_x = np.flip(image, axis=1)\n",
    "        # image_flip_xy = np.flip(image_flip_y, 1)\n",
    "        # for im in [image, image_flip_y, image_flip_x, image_flip_xy]:\n",
    "        #     image_dataset.append(im)\n",
    "        #     image_dataset.append(cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE))\n",
    "        #     image_dataset.append(cv2.rotate(im, cv2.ROTATE_180))\n",
    "        #     image_dataset.append(cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "\n",
    "print(\"-- masks --\")\n",
    "\n",
    "mask_files = list(MASK_DIR.glob(\"*.npy\"))\n",
    "mask_files = sorted(mask_files, key=lambda p: p.name)\n",
    "print(mask_files)\n",
    "for index, mask_file in enumerate(mask_files):\n",
    "    print(mask_file.name)\n",
    "    # image = cv2.imread(str(MASK_DIR / image_name), 0)\n",
    "    image = np.load(mask_file)\n",
    "    image = Image.fromarray(image.astype(np.uint8))\n",
    "    image = image.resize((SIZE, SIZE))\n",
    "    image = np.array(image)\n",
    "    mask_dataset.append(image.astype(int))\n",
    "    # print(f\"mask unique: {np.unique(image)}\")\n",
    "    # image_flip_y = np.flip(image, axis=0)\n",
    "    # image_flip_x = np.flip(image, axis=1)\n",
    "    # image_flip_xy = np.flip(image_flip_y, axis=1)\n",
    "    # for im in [image, image_flip_y, image_flip_x, image_flip_xy]:\n",
    "    #     mask_dataset.append(im.astype(bool))\n",
    "    #     mask_dataset.append(cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE).astype(bool))\n",
    "    #     mask_dataset.append(cv2.rotate(im, cv2.ROTATE_180).astype(bool))\n",
    "    #     mask_dataset.append(cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE).astype(bool))\n",
    "\n",
    "# CLEAN UP\n",
    "# del (images, masks, image, im, image_name, index, image_flip_y, image_flip_x, image_flip_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data has been loaded correctly\n",
    "\n",
    "print(f\"image dataset size: {len(image_dataset)}\")\n",
    "print(f\"mask dataset size: {len(mask_dataset)}\")\n",
    "\n",
    "index = np.random.randint(0, len(image_dataset) - 1)\n",
    "print(f\"index: {index}\")\n",
    "\n",
    "plt.imshow(original_image_dataset[index])\n",
    "plt.show()\n",
    "print(f\"original image dataset | min: {np.min(original_image_dataset)} max: {np.max(original_image_dataset)}\")\n",
    "print(np.shape(original_image_dataset[index]))\n",
    "\n",
    "plt.imshow(image_dataset[index])\n",
    "plt.show()\n",
    "print(f\"img dataset | min: {np.min(image_dataset)} max: {np.max(image_dataset)}\")\n",
    "print(np.shape(image_dataset[index]))\n",
    "\n",
    "plt.imshow(mask_dataset[index])\n",
    "plt.show()\n",
    "print(f\"unique: {np.unique(mask_dataset[index])}\")\n",
    "print(f\"shape: {np.shape(mask_dataset[index])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from integer based classes to one-hot encoding\n",
    "mask_dataset = np.array(mask_dataset)\n",
    "print(mask_dataset.shape)\n",
    "mask_dataset = to_categorical(mask_dataset, 3)\n",
    "print(mask_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN MORE THAN ONCE\n",
    "\n",
    "# Expand dims because the model doesn't work unless we add an extra dimension, don't know why.\n",
    "original_image_dataset = np.expand_dims(np.array(original_image_dataset), 3)\n",
    "image_dataset = np.expand_dims(np.array(image_dataset), 3)\n",
    "# mask_dataset = np.expand_dims(np.array(mask_dataset), 3)\n",
    "\n",
    "print(image_dataset.shape)\n",
    "print(mask_dataset.shape)\n",
    "print(f\"image dataset min, max: {np.min(image_dataset), np.max(image_dataset)}\")\n",
    "print(f\"mask unique values: {np.unique(mask_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original image dataset and ridges image dataset for training\n",
    "image_dataset = np.append(image_dataset, original_image_dataset, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_dataset.shape)\n",
    "plt.imshow(image_dataset[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(image_dataset[0, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size=0.1, random_state=SEED)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image: np.ndarray, angle_90_multiple: int):\n",
    "    return np.rot90(image, k=angle_90_multiple)\n",
    "\n",
    "\n",
    "def flip_image(image: np.ndarray):\n",
    "    return np.flipud(image)\n",
    "\n",
    "\n",
    "def augment_image(image: np.ndarray):\n",
    "    images = []\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def augment_image_set(training_set: np.ndarray):\n",
    "    augmented_set = np.zeros(\n",
    "        (training_set.shape[0] * 8, training_set.shape[1], training_set.shape[2], training_set.shape[3])\n",
    "    )\n",
    "\n",
    "    for layer_index in range(training_set.shape[3]):\n",
    "        for index in range(training_set.shape[0]):\n",
    "            image = training_set[index, :, :, layer_index]\n",
    "            image_flipped = flip_image(image)\n",
    "            augmented_set[index * 8 + 0, :, :, layer_index] = image\n",
    "            augmented_set[index * 8 + 1, :, :, layer_index] = image_flipped.copy()\n",
    "            augmented_set[index * 8 + 2, :, :, layer_index] = rotate_image(image_flipped.copy(), 1)\n",
    "            augmented_set[index * 8 + 3, :, :, layer_index] = rotate_image(image_flipped.copy(), 2)\n",
    "            augmented_set[index * 8 + 4, :, :, layer_index] = rotate_image(image_flipped.copy(), 3)\n",
    "\n",
    "            augmented_set[index * 8 + 5, :, :, layer_index] = rotate_image(image.copy(), 1)\n",
    "            augmented_set[index * 8 + 6, :, :, layer_index] = rotate_image(image.copy(), 2)\n",
    "            augmented_set[index * 8 + 7, :, :, layer_index] = rotate_image(image.copy(), 3)\n",
    "\n",
    "    return augmented_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train = augment_image_set(X_train)\n",
    "y_train = augment_image_set(y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(X_train))\n",
    "print(np.min(X_train))\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check things are working correctly\n",
    "image_number = random.randint(0, len(X_train) - 1)\n",
    "print(f\"image number: {image_number} / {len(X_train)}\")\n",
    "plt.imshow(X_train[image_number, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(X_train[image_number, :, :, 1])\n",
    "plt.show()\n",
    "plt.imshow(y_train[image_number, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(y_train[image_number, :, :, 1])\n",
    "plt.show()\n",
    "plt.imshow(y_train[image_number, :, :, 2])\n",
    "plt.show()\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(np.reshape(X_train[image_number], (SIZE, SIZE)), cmap=\"gray\")\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(np.reshape(y_train[image_number], (SIZE, SIZE)), cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = image_dataset.shape[1]\n",
    "IMG_WIDTH = image_dataset.shape[2]\n",
    "IMG_CHANNELS = image_dataset.shape[3]\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    return multiclass_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 50\n",
    "history = model.fit(\n",
    "    X_train, y_train, batch_size=4, verbose=1, epochs=50, validation_data=(X_test, y_test), shuffle=False\n",
    ")\n",
    "\n",
    "# SAVE THE MODEL WITH DATE AND PARAMS IN THE NAME\n",
    "now = datetime.now()\n",
    "dt_string = str(now.strftime(\"%Y%m%d_%H-%M-%S\"))\n",
    "filename = str(MODEL_SAVE_DIR / f\"{dt_string}_cats_{SIZE}_b{BATCH_SIZE}_e{EPOCHS}_hessian_upper_4_0_multiclass.hdf5\")\n",
    "print(f\"saving file: {filename}\")\n",
    "model.save(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD MODEL\n",
    "# model = tf.keras.models.load_model(MODEL_SAVE_DIR / \"20230811_14-26-19_cats.hdf5\")\n",
    "path_to_model = MODEL_SAVE_DIR / \"20230817_10-26-23_cats_512_b4_e50_hessian_upper_4_0.hdf5\"\n",
    "print(path_to_model)\n",
    "model = tf.keras.models.load_model(path_to_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model accuracy\n",
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"y\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label=\"Valdation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(epochs, acc, \"y\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IOU for each class\n",
    "num_classes = 3\n",
    "ious = []\n",
    "y_pred = model.predict(X_test)\n",
    "for class_idx in range(num_classes):\n",
    "    y_pred_class = y_pred[..., class_idx] > 0.1  # this value is a probability cutoff\n",
    "    y_test_class = y_test[..., class_idx]\n",
    "\n",
    "    intersection = np.logical_and(y_test_class, y_pred_class)\n",
    "    union = np.logical_or(y_test_class, y_pred_class)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    ious.append(iou_score)\n",
    "\n",
    "# Calculate mean IOU\n",
    "mean_iou = np.mean(ious)\n",
    "print(f\"Mean IoU score: {mean_iou}\")\n",
    "print(f\"IoU Scores: {ious}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load other model for comparison\n",
    "path_to_model = MODEL_SAVE_DIR / \"20230817_10-26-23_cats_512_b4_e50_hessian_upper_4_0.hdf5\"\n",
    "print(path_to_model)\n",
    "other_model = tf.keras.models.load_model(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how it predicts our testing dataset\n",
    "\n",
    "threshold = 0.1\n",
    "\n",
    "# test_img_number = random.randint(0, len(X_test) - 1)\n",
    "test_img_number = 2\n",
    "# print(f\"test image number: {test_img_number} / {len(X_test)}\")\n",
    "# test_img = X_test[test_img_number, :, :, :]\n",
    "print(f\"test image number: {test_img_number} / {len(X_train)}\")\n",
    "test_img = X_train[test_img_number, :, :, :]\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "print(test_img.shape)\n",
    "# ground_truth = y_test[test_img_number, :, :, 0]\n",
    "ground_truth = y_train[test_img_number, :, :, 0]\n",
    "ground_truth = ground_truth.reshape(512, 512)\n",
    "print(f\"shape: {test_img.shape} min: {np.min(test_img)} max: {np.max(test_img)}\")\n",
    "print(f\"dtype: {test_img.dtype}\")\n",
    "prediction = model.predict(test_img)\n",
    "\n",
    "prediction_background = prediction[0, :, :, 0]\n",
    "prediction_background = (prediction_background > threshold).astype(np.uint8)\n",
    "\n",
    "prediction_edges = prediction[0, :, :, 1]\n",
    "prediction_edges = (prediction_edges > threshold).astype(np.uint8)\n",
    "\n",
    "prediction_noodle = prediction[0, :, :, 2]\n",
    "prediction_noodle = (prediction_noodle > threshold).astype(np.uint8)\n",
    "\n",
    "previous_prediction = other_model.predict(test_img[:, :, :, 0])[0, :, :, 0] > threshold\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(331)\n",
    "plt.imshow(test_img[0, :, :, 1], cmap=\"gray\")\n",
    "plt.title(\"Test image layer 0 (original)\")\n",
    "plt.subplot(332)\n",
    "plt.title(\"Test image layer 1 (ridges)\")\n",
    "plt.imshow(test_img[0, :, :, 0], cmap=\"gray\")\n",
    "plt.subplot(333)\n",
    "plt.imshow(ground_truth, cmap=\"gray\")\n",
    "plt.title(\"Testing label\")\n",
    "plt.subplot(334)\n",
    "plt.imshow(prediction_background, cmap=\"gray\")\n",
    "plt.title(\"Multi class prediction: background\")\n",
    "plt.subplot(335)\n",
    "plt.imshow(prediction_noodle, cmap=\"gray\")\n",
    "plt.title(\"Multi class prediction: noodle\")\n",
    "plt.subplot(336)\n",
    "plt.imshow(prediction_edges, cmap=\"gray\")\n",
    "plt.title(\"Multi class prediction: edges\")\n",
    "plt.subplot(337)\n",
    "plt.imshow(previous_prediction, cmap=\"gray\")\n",
    "plt.title(\"Single channel (previous) model prediction\")\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# ax.imshow(test_img)\n",
    "# ax.imshow(np.ma.masked_where(prediction == 0, prediction))\n",
    "# plt.show()\n",
    "\n",
    "# prediction = prediction == 0\n",
    "# print(f\"prediction shape: {prediction.shape}\")\n",
    "# difference = ground_truth.astype(int) - prediction.astype(int)\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# ax.imshow(difference)\n",
    "# ax.set_title(\"prediction difference - yellow is prediction, teal is ground truth\")\n",
    "# plt.show()\n",
    "\n",
    "# labelled = label(prediction)\n",
    "# coloured = label2rgb(labelled)\n",
    "# plt.imshow(coloured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a completely new image\n",
    "\n",
    "# FROM PNG\n",
    "# another_image_file = './dl_data/to_be_labelled/20230207_MeO_perov_10um.0_00001.png'\n",
    "# another_image_file = str(\n",
    "#     Path(\n",
    "#         \"/Users/sylvi/topo_data/textured-silicon/flattened_images/tapp_ref_perovskite_si_fraunhofer_5um.0_00000_sylvia_freq_split_1DFFT_filter.png\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "image_number = random.randint(0, 20)\n",
    "print(f\"image number: {image_number}\")\n",
    "another_image_file = str(\n",
    "    Path(\n",
    "        f\"/Users/sylvi/topo_data/cats/training_data/images_edge_detection_upper_all_sigma_4/training_image_{image_number}.png\"\n",
    "    )\n",
    "    # Path(f\"/Users/sylvi/topo_data/cats/toms_low_res/ridges/ridges_{image_number}.png\")\n",
    "    # Path(f\"/Users/sylvi/topo_data/cats/eddie-haribo/on-target/ridges/ridges_{image_number}.png\")\n",
    ")\n",
    "\n",
    "original_image_file = str(\n",
    "    Path(f\"/Users/sylvi/topo_data/cats/training_data/images_flattened_all/training_image_{image_number}.png\")\n",
    "    # Path(f\"/Users/sylvi/topo_data/cats/toms_low_res/flattened/flattened_{image_number}.png\")\n",
    "    # Path(f\"/Users/sylvi/topo_data/cats/eddie-haribo/on-target/flattened/flattened_{image_number}.png\")\n",
    ")\n",
    "\n",
    "image = cv2.imread(another_image_file, 0)\n",
    "print(f\"original shape: {np.sqrt(image.size)}\")\n",
    "\n",
    "original_image = cv2.imread(original_image_file, 0)\n",
    "\n",
    "threshold = 0.1\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "# FROM SPM\n",
    "# another_image_file = Path('/home/sylvia/Desktop/unseen_data/spm_images/20230512-Me41-100NPBSpin-512-5um.0_00000.spm')\n",
    "# another_image_file = Path('/Users/sylvi/topo_data/perovskite/perovskite_images/Me/20230512-Me41-100NPBSpin-512-5um.0_00000.spm')\n",
    "# another_image_file = Path('/Users/sylvi/topo_data/perovskite/perovskite_images/AR/AR123_926F_FACsPbI3_evap_5um.0_00002.spm')\n",
    "# another_image_file = Path('/Users/sylvi/topo_data/perovskite/perovskite_images/AR/AR115_25_BA_MAPbI3_10um.ibw')\n",
    "\n",
    "# loadscan = io.LoadScans(img_paths = [another_image_file], channel='HeightRetrace')\n",
    "# loadscan = io.LoadScans(img_paths = [another_image_file], channel='Height')\n",
    "# loadscan.get_data()\n",
    "# image, pixel_to_nm = loadscan.load_ibw()\n",
    "# image, pixel_to_nm = loadscan.load_spm()\n",
    "\n",
    "# image = perov_flatten.flatten_image(image, order=3, plot_steps=True)\n",
    "\n",
    "# ====== Loading PNG images =========\n",
    "# another_image_file = Path(\"/Users/sylvi/topo_data/textured-silicon/flattened_images/tapp_ref_perovskite_si_fraunhofer_5um.0_00000_sylvia_freq_split_1DFFT_filter.png\")\n",
    "# another_image_file = cv2.imread(str(image), cv2.IMREAD_GRAYSCALE)\n",
    "# ===================================\n",
    "\n",
    "# image = detect_ridges(image, sigma=1.0)\n",
    "\n",
    "# Normalize image\n",
    "# sns.kdeplot(image.flatten())\n",
    "# plt.show()\n",
    "# print(f\"min: {np.min(image)} max: {np.max(image)}\")\n",
    "image = image - np.min(image)\n",
    "image = image / np.max(image)\n",
    "# image = image - np.min(image)\n",
    "# print(f'min: {np.min(image)} max: {np.max(image)}')\n",
    "# image = normalize(image)\n",
    "# image = image / np.max(image)\n",
    "# print(f\"min: {np.min(image)} max: {np.max(image)}\")\n",
    "# sns.kdeplot(image.flatten())\n",
    "# plt.show()\n",
    "\n",
    "# Resize image to the correct size\n",
    "# print(f\"image shape: {image.shape}\")\n",
    "# print(f\"min, max values: {np.min(image), np.max(image)}\")\n",
    "# print(np.unique(image))\n",
    "# image = Image.fromarray(image)\n",
    "# image = image.resize((SIZE, SIZE))\n",
    "# image = np.array(image)\n",
    "# print(f\"image shape: {image.shape}\")\n",
    "\n",
    "# # Get the input image into the right form (since training was in A x 512 x 512 x 1 shape)\n",
    "# # This was just trial and error, I don't really have a good understanding of this bit\n",
    "# to_predict = [image]\n",
    "# to_predict = np.array(to_predict)\n",
    "# print(f\"to predict shape: {to_predict.shape}\")\n",
    "# to_predict = np.expand_dims(to_predict, 3)\n",
    "# print(f\"to predict shape: {to_predict.shape}\")\n",
    "# # Fetch image from the strange array\n",
    "# test_img = to_predict[0]\n",
    "# test_img = test_img[:, :, 0][:, :, None]\n",
    "# test_img = np.expand_dims(test_img, 0)\n",
    "# print(f\"to predict shape: {test_img.shape}\")\n",
    "\n",
    "\n",
    "def predict_unet(image: np.ndarray, confidence: float, model_image_size: int) -> np.ndarray:\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    # Get the image into the correct format for prediction\n",
    "    # Resize image\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((model_image_size, model_image_size))\n",
    "    image = np.array(image)\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    image = [image]\n",
    "    # print(f\"image shape: {image.shape}\")\n",
    "    image = np.array(image)\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    image = np.expand_dims(image, 3)\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    image = image[0]\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    image = image[:, :, 0][:, :, None]\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    image = np.expand_dims(image, 0)\n",
    "\n",
    "    return (model.predict(image)[0, :, :, 0] > confidence).astype(np.uint8)\n",
    "\n",
    "\n",
    "# Get prediction\n",
    "# prediction = (model.predict(test_img)[0, :, :, 0] > threshold).astype(np.uint8)\n",
    "prediction = predict_unet(image=image, confidence=threshold, model_image_size=512)\n",
    "\n",
    "# print(f\"prediction unique vals: {np.unique(prediction)}\")\n",
    "# prediction = skeletonize(prediction)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 7))\n",
    "ax[1].imshow(image)\n",
    "ax[1].set_title(\"ridges\")\n",
    "ax[0].imshow(original_image)\n",
    "ax[0].set_title(\"original image\")\n",
    "ax[2].imshow(prediction)\n",
    "ax[2].set_title(\"prediction\")\n",
    "fig.suptitle(f\"strictness: {threshold}\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "# # Pot prediction\n",
    "# fig, ax = plt.subplots(figsize=(20, 20))\n",
    "# ax.imshow(image)\n",
    "# masked = np.ma.masked_where(prediction.astype(int) == 0, prediction)\n",
    "# ax.imshow(masked)\n",
    "# ax.set_title(\"prediction\")\n",
    "# plt.show()\n",
    "\n",
    "# labelled = label(prediction == 0, connectivity=1)\n",
    "# coloured = label2rgb(labelled)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(coloured)\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(14, 14))\n",
    "# test_mask = np.zeros(image.shape)\n",
    "# for j in range(coloured.shape[0]):\n",
    "#     for i in range(coloured.shape[1]):\n",
    "#         if np.array_equal(coloured[j, i], np.array([0, 0, 0])):\n",
    "#             test_mask[j, i] = 1\n",
    "\n",
    "\n",
    "# overlay = np.zeros(image.shape)\n",
    "\n",
    "# test_masked = np.ma.masked_where(test_mask == 1, overlay)\n",
    "# ax.imshow(image)\n",
    "# ax.imshow(test_masked, alpha=0.1, cmap=\"binary\")\n",
    "# ax.set_title(\"overlay\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot skeletonised segmentation\n",
    "# skeleton_prediction = skeletonize(prediction)\n",
    "# print(f\"unique skeleton prediction: {np.unique(skeleton_prediction)}\")\n",
    "# plt.imshow(skeleton_prediction)\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(20, 20))\n",
    "# ax.imshow(image)\n",
    "# ax.set_title(\"flattened image\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number = random.randint(0, 20)\n",
    "print(f\"image number: {image_number}\")\n",
    "another_image_file = str(\n",
    "    Path(\n",
    "        f\"/Users/sylvi/topo_data/cats/training_data/images_edge_detection_upper_all_sigma_4/training_image_{image_number}.png\"\n",
    "    )\n",
    "    # Path(f\"/Users/sylvi/topo_data/cats/toms_low_res/ridges/ridges_{image_number}.png\")\n",
    "    # Path(f\"/Users/sylvi/topo_data/cats/eddie-haribo/on-target/ridges/ridges_{image_number}.png\")\n",
    ")\n",
    "\n",
    "original_image_file = str(\n",
    "    Path(f\"/Users/sylvi/topo_data/cats/training_data/images_flattened_all/training_image_{image_number}.png\")\n",
    "    # Path(f\"/Users/sylvi/topo_data/cats/toms_low_res/flattened/flattened_{image_number}.png\")\n",
    "    # Path(f\"/Users/sylvi/topo_data/cats/eddie-haribo/on-target/flattened/flattened_{image_number}.png\")\n",
    ")\n",
    "\n",
    "image = cv2.imread(another_image_file, 0)\n",
    "print(f\"original shape: {np.sqrt(image.size)}\")\n",
    "\n",
    "original_image = cv2.imread(original_image_file, 0)\n",
    "\n",
    "original_image = original_image - np.min(original_image)\n",
    "original_image = original_image / np.max(original_image)\n",
    "\n",
    "ridges = detect_ridges(original_image, sigma=4.0)\n",
    "plt.imshow(ridges, cmap=\"viridis\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# predicted = grain_finding_cats_unet.predict_unet(\n",
    "#     image=original_image, confidence=0.1, model_image_size=512, image_output_dir=Path(\"./\"), filename=\"test-image\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-or-truck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
