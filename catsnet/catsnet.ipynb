{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from unet import unet_model\n",
    "import random\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "from datetime import datetime\n",
    "\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.filters import hessian\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from skimage.morphology import label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "# TopoStats needs to be >= version 2.1.0\n",
    "from topostats import io\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that your GPU is working\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds\n",
    "SEED = 0\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_DIR = Path('/home/sylvia/Desktop/dl_data/images/')\n",
    "# MASK_DIR = Path('/home/sylvia/Desktop/dl_data/ground_truth/')\n",
    "# MODEL_SAVE_DIR = Path('/home/sylvia/Desktop/dl_data/saved_models/')\n",
    "IMAGE_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/images_edge_detection_lower_training_sigma_1/\")\n",
    "# MASK_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/ground_truth_edges/\")\n",
    "MASK_DIR = Path(\"/Users/sylvi/topo_data/cats/training_data/images_edge_detection_lower_labels_sigma_1/\")\n",
    "MODEL_SAVE_DIR = Path(\"./catsnet/saved_models/\")\n",
    "SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ridges(gray, sigma=1.0):\n",
    "    H_elems = hessian_matrix(gray, sigma=sigma, order=\"rc\")\n",
    "    maxima_ridges, minima_ridges = hessian_matrix_eigvals(H_elems)\n",
    "    return maxima_ridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "print(\" -- images --\")\n",
    "\n",
    "images = os.listdir(IMAGE_DIR)\n",
    "images = sorted(images)\n",
    "print(images)\n",
    "for index, image_name in enumerate(images):\n",
    "    print(image_name)\n",
    "    if image_name.split(\".\")[-1] == \"png\":\n",
    "        image = cv2.imread(str(IMAGE_DIR / image_name), 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image = np.array(image)\n",
    "        # Detect ridges\n",
    "        # image = detect_ridges(image)\n",
    "        # fig, ax = plt.subplots(1, 2, figsize=(3, 3))\n",
    "        # sns.kdeplot(image.flatten(), ax=ax[0])\n",
    "        image = image - np.min(image)\n",
    "        image = image / np.max(image)\n",
    "        image_dataset.append(image)\n",
    "        # sns.kdeplot(image.flatten(), ax=ax[1])\n",
    "        # plt.show()\n",
    "        # print(f\"image min: {np.min(image)} image max: {np.max(image)}\")\n",
    "        # image_flip_y = np.flip(image, axis=0)\n",
    "        # image_flip_x = np.flip(image, axis=1)\n",
    "        # image_flip_xy = np.flip(image_flip_y, 1)\n",
    "        # for im in [image, image_flip_y, image_flip_x, image_flip_xy]:\n",
    "        #     image_dataset.append(im)\n",
    "        #     image_dataset.append(cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE))\n",
    "        #     image_dataset.append(cv2.rotate(im, cv2.ROTATE_180))\n",
    "        #     image_dataset.append(cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "\n",
    "print(\"-- masks --\")\n",
    "\n",
    "masks = os.listdir(MASK_DIR)\n",
    "masks = sorted(masks)\n",
    "print(masks)\n",
    "for index, image_name in enumerate(masks):\n",
    "    print(image_name)\n",
    "    if image_name.split(\".\")[1] == \"png\":\n",
    "        image = cv2.imread(str(MASK_DIR / image_name), 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image = np.array(image)\n",
    "        mask_dataset.append(image.astype(bool))\n",
    "        # print(f\"mask unique: {np.unique(image)}\")\n",
    "        # image_flip_y = np.flip(image, axis=0)\n",
    "        # image_flip_x = np.flip(image, axis=1)\n",
    "        # image_flip_xy = np.flip(image_flip_y, axis=1)\n",
    "        # for im in [image, image_flip_y, image_flip_x, image_flip_xy]:\n",
    "        #     mask_dataset.append(im.astype(bool))\n",
    "        #     mask_dataset.append(cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE).astype(bool))\n",
    "        #     mask_dataset.append(cv2.rotate(im, cv2.ROTATE_180).astype(bool))\n",
    "        #     mask_dataset.append(cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE).astype(bool))\n",
    "\n",
    "# CLEAN UP\n",
    "# del (images, masks, image, im, image_name, index, image_flip_y, image_flip_x, image_flip_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data has been loaded correctly\n",
    "\n",
    "print(f\"image dataset size: {len(image_dataset)}\")\n",
    "print(f\"mask dataset size: {len(mask_dataset)}\")\n",
    "\n",
    "index = np.random.randint(0, len(image_dataset) - 1)\n",
    "print(f\"index: {index}\")\n",
    "\n",
    "plt.imshow(image_dataset[index])\n",
    "plt.show()\n",
    "print(f\"img dataset | min: {np.min(image_dataset)} max: {np.max(image_dataset)}\")\n",
    "print(np.shape(image_dataset[index]))\n",
    "\n",
    "plt.imshow(mask_dataset[index])\n",
    "plt.show()\n",
    "print(f\"unique: {np.unique(mask_dataset[index])}\")\n",
    "print(f\"shape: {np.shape(mask_dataset[index])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN MORE THAN ONCE\n",
    "\n",
    "# Expand dims because the model doesn't work unless we add an extra dimension, don't know why.\n",
    "image_dataset = np.expand_dims(np.array(image_dataset), 3)\n",
    "mask_dataset = np.expand_dims(np.array(mask_dataset), 3)\n",
    "\n",
    "print(image_dataset.shape)\n",
    "print(mask_dataset.shape)\n",
    "print(f\"image dataset min, max: {np.min(image_dataset), np.max(image_dataset)}\")\n",
    "print(f\"mask unique values: {np.unique(mask_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size=0.1, random_state=SEED)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image: np.ndarray, angle_90_multiple: int):\n",
    "    return np.rot90(image, k=angle_90_multiple)\n",
    "\n",
    "\n",
    "def flip_image(image: np.ndarray):\n",
    "    return np.flipud(image)\n",
    "\n",
    "\n",
    "def augment_image(image: np.ndarray):\n",
    "    images = []\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def augment_image_set(training_set: np.ndarray):\n",
    "    augmented_set = np.zeros(\n",
    "        (training_set.shape[0] * 8, training_set.shape[1], training_set.shape[2], training_set.shape[3])\n",
    "    )\n",
    "\n",
    "    for index in range(training_set.shape[0]):\n",
    "        image = training_set[index, :, :, 0]\n",
    "        image_flipped = flip_image(image)\n",
    "        augmented_set[index * 8 + 0, :, :, 0] = image\n",
    "        augmented_set[index * 8 + 1, :, :, 0] = image_flipped.copy()\n",
    "        augmented_set[index * 8 + 2, :, :, 0] = rotate_image(image_flipped.copy(), 1)\n",
    "        augmented_set[index * 8 + 3, :, :, 0] = rotate_image(image_flipped.copy(), 2)\n",
    "        augmented_set[index * 8 + 4, :, :, 0] = rotate_image(image_flipped.copy(), 3)\n",
    "\n",
    "        augmented_set[index * 8 + 5, :, :, 0] = rotate_image(image.copy(), 1)\n",
    "        augmented_set[index * 8 + 6, :, :, 0] = rotate_image(image.copy(), 2)\n",
    "        augmented_set[index * 8 + 7, :, :, 0] = rotate_image(image.copy(), 3)\n",
    "\n",
    "    return augmented_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train = augment_image_set(X_train)\n",
    "y_train = augment_image_set(y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(X_train))\n",
    "print(np.min(X_train))\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check things are working correctly\n",
    "image_number = random.randint(0, len(X_train) - 1)\n",
    "print(f\"image number: {image_number} / {len(X_train)}\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape(X_train[image_number], (SIZE, SIZE)), cmap=\"gray\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(y_train[image_number], (SIZE, SIZE)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = image_dataset.shape[1]\n",
    "IMG_WIDTH = image_dataset.shape[2]\n",
    "IMG_CHANNELS = image_dataset.shape[3]\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    return unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 50\n",
    "history = model.fit(\n",
    "    X_train, y_train, batch_size=4, verbose=1, epochs=50, validation_data=(X_test, y_test), shuffle=False\n",
    ")\n",
    "\n",
    "# SAVE THE MODEL WITH DATE AND PARAMS IN THE NAME\n",
    "now = datetime.now()\n",
    "dt_string = str(now.strftime(\"%Y%m%d_%H-%M-%S\"))\n",
    "filename = str(MODEL_SAVE_DIR / f\"{dt_string}_cats_{SIZE}_b{BATCH_SIZE}_e{EPOCHS}_hessian_lower_1_0.hdf5\")\n",
    "print(f\"saving file: {filename}\")\n",
    "model.save(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD MODEL\n",
    "# model = tf.keras.models.load_model(MODEL_SAVE_DIR / \"20230811_14-26-19_cats.hdf5\")\n",
    "model = tf.keras.models.load_model(MODEL_SAVE_DIR / \"20230815_17-50-23_cats_512_b4_e50_hessian_lower_4_0.hdf5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model accuracy\n",
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"y\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label=\"Valdation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "plt.plot(epochs, acc, \"y\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that for semantic segmentation, accuracy is not the correct metric.\n",
    "\n",
    "# Calculate IOU\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_thresholded = y_pred > 0.5  # this value is a probability cutoff\n",
    "\n",
    "intersection = np.logical_and(y_test, y_pred_thresholded)\n",
    "union = np.logical_or(y_test, y_pred_thresholded)\n",
    "iou_score = np.sum(intersection) / np.sum(union)\n",
    "print(f\"IoU score: {iou_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how it predicts our testing dataset\n",
    "\n",
    "threshold = 0.15\n",
    "\n",
    "test_img_number = random.randint(0, len(X_test) - 1)\n",
    "print(f\"test image number: {test_img_number} / {len(X_test)}\")\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth = y_test[test_img_number]\n",
    "ground_truth = ground_truth.reshape(512, 512)\n",
    "print(f\"ground truth shape: {ground_truth.shape}\")\n",
    "test_img_norm = test_img[:, :, 0][:, :, None]\n",
    "plt.hist(test_img_norm[:, :, 0])\n",
    "test_img_input = np.expand_dims(test_img_norm, 0)\n",
    "prediction = (model.predict(test_img_input)[0, :, :, 0] > threshold).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Test image\")\n",
    "plt.imshow(test_img[:, :, 0], cmap=\"gray\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(ground_truth, cmap=\"gray\")\n",
    "plt.title(\"Testing label\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(prediction, cmap=\"gray\")\n",
    "plt.title(\"Prediction\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(test_img)\n",
    "ax.imshow(np.ma.masked_where(prediction == 0, prediction))\n",
    "plt.show()\n",
    "\n",
    "prediction = prediction == 0\n",
    "print(f\"prediction shape: {prediction.shape}\")\n",
    "difference = ground_truth.astype(int) - prediction.astype(int)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(difference)\n",
    "ax.set_title(\"prediction difference - yellow is prediction, teal is ground truth\")\n",
    "plt.show()\n",
    "\n",
    "labelled = label(prediction)\n",
    "coloured = label2rgb(labelled)\n",
    "plt.imshow(coloured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a completely new image\n",
    "\n",
    "# FROM PNG\n",
    "# another_image_file = './dl_data/to_be_labelled/20230207_MeO_perov_10um.0_00001.png'\n",
    "# another_image_file = str(\n",
    "#     Path(\n",
    "#         \"/Users/sylvi/topo_data/textured-silicon/flattened_images/tapp_ref_perovskite_si_fraunhofer_5um.0_00000_sylvia_freq_split_1DFFT_filter.png\"\n",
    "#     )\n",
    "# )\n",
    "another_image_file = str(\n",
    "    Path(\"/Users/sylvi/topo_data/cats/training_data/images_edge_detection_lower_all_sigma_1/training_image_11.png\")\n",
    ")\n",
    "image = cv2.imread(another_image_file, 0)\n",
    "print(f\"original shape: {np.sqrt(image.size)}\")\n",
    "\n",
    "threshold = 0.01\n",
    "\n",
    "# FROM SPM\n",
    "# another_image_file = Path('/home/sylvia/Desktop/unseen_data/spm_images/20230512-Me41-100NPBSpin-512-5um.0_00000.spm')\n",
    "# another_image_file = Path('/Users/sylvi/topo_data/perovskite/perovskite_images/Me/20230512-Me41-100NPBSpin-512-5um.0_00000.spm')\n",
    "# another_image_file = Path('/Users/sylvi/topo_data/perovskite/perovskite_images/AR/AR123_926F_FACsPbI3_evap_5um.0_00002.spm')\n",
    "# another_image_file = Path('/Users/sylvi/topo_data/perovskite/perovskite_images/AR/AR115_25_BA_MAPbI3_10um.ibw')\n",
    "\n",
    "# loadscan = io.LoadScans(img_paths = [another_image_file], channel='HeightRetrace')\n",
    "# loadscan = io.LoadScans(img_paths = [another_image_file], channel='Height')\n",
    "# loadscan.get_data()\n",
    "# image, pixel_to_nm = loadscan.load_ibw()\n",
    "# image, pixel_to_nm = loadscan.load_spm()\n",
    "\n",
    "# image = perov_flatten.flatten_image(image, order=3, plot_steps=True)\n",
    "\n",
    "# ====== Loading PNG images =========\n",
    "# another_image_file = Path(\"/Users/sylvi/topo_data/textured-silicon/flattened_images/tapp_ref_perovskite_si_fraunhofer_5um.0_00000_sylvia_freq_split_1DFFT_filter.png\")\n",
    "# another_image_file = cv2.imread(str(image), cv2.IMREAD_GRAYSCALE)\n",
    "# ===================================\n",
    "\n",
    "# image = detect_ridges(image, sigma=1.0)\n",
    "\n",
    "# Normalize image\n",
    "sns.kdeplot(image.flatten())\n",
    "plt.show()\n",
    "print(f\"min: {np.min(image)} max: {np.max(image)}\")\n",
    "image = image - np.min(image)\n",
    "image = image / np.max(image)\n",
    "# image = image - np.min(image)\n",
    "# print(f'min: {np.min(image)} max: {np.max(image)}')\n",
    "# image = normalize(image)\n",
    "# image = image / np.max(image)\n",
    "print(f\"min: {np.min(image)} max: {np.max(image)}\")\n",
    "sns.kdeplot(image.flatten())\n",
    "plt.show()\n",
    "\n",
    "# Resize image to the correct size\n",
    "print(f\"image shape: {image.shape}\")\n",
    "print(f\"min, max values: {np.min(image), np.max(image)}\")\n",
    "print(np.unique(image))\n",
    "image = Image.fromarray(image)\n",
    "image = image.resize((SIZE, SIZE))\n",
    "image = np.array(image)\n",
    "print(f\"image shape: {image.shape}\")\n",
    "\n",
    "# Get the input image into the right form (since training was in A x 512 x 512 x 1 shape)\n",
    "# This was just trial and error, I don't really have a good understanding of this bit\n",
    "to_predict = [image]\n",
    "to_predict = np.array(to_predict)\n",
    "print(f\"to predict shape: {to_predict.shape}\")\n",
    "to_predict = np.expand_dims(to_predict, 3)\n",
    "print(f\"to predict shape: {to_predict.shape}\")\n",
    "# Fetch image from the strange array\n",
    "test_img = to_predict[0]\n",
    "test_img = test_img[:, :, 0][:, :, None]\n",
    "test_img = np.expand_dims(test_img, 0)\n",
    "print(f\"to predict shape: {test_img.shape}\")\n",
    "\n",
    "# Get prediction\n",
    "prediction = (model.predict(test_img)[0, :, :, 0] > threshold).astype(np.uint8)\n",
    "print(f\"prediction unique vals: {np.unique(prediction)}\")\n",
    "# prediction = skeletonize(prediction)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.imshow(prediction)\n",
    "plt.show()\n",
    "\n",
    "# # Pot prediction\n",
    "# fig, ax = plt.subplots(figsize=(20, 20))\n",
    "# ax.imshow(image)\n",
    "# masked = np.ma.masked_where(prediction.astype(int) == 0, prediction)\n",
    "# ax.imshow(masked)\n",
    "# ax.set_title(\"prediction\")\n",
    "# plt.show()\n",
    "\n",
    "# labelled = label(prediction == 0, connectivity=1)\n",
    "# coloured = label2rgb(labelled)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(coloured)\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(14, 14))\n",
    "# test_mask = np.zeros(image.shape)\n",
    "# for j in range(coloured.shape[0]):\n",
    "#     for i in range(coloured.shape[1]):\n",
    "#         if np.array_equal(coloured[j, i], np.array([0, 0, 0])):\n",
    "#             test_mask[j, i] = 1\n",
    "\n",
    "\n",
    "# overlay = np.zeros(image.shape)\n",
    "\n",
    "# test_masked = np.ma.masked_where(test_mask == 1, overlay)\n",
    "# ax.imshow(image)\n",
    "# ax.imshow(test_masked, alpha=0.1, cmap=\"binary\")\n",
    "# ax.set_title(\"overlay\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot skeletonised segmentation\n",
    "# skeleton_prediction = skeletonize(prediction)\n",
    "# print(f\"unique skeleton prediction: {np.unique(skeleton_prediction)}\")\n",
    "# plt.imshow(skeleton_prediction)\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(20, 20))\n",
    "# ax.imshow(image)\n",
    "# ax.set_title(\"flattened image\")\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(20, 20))\n",
    "# ax.imshow(image)\n",
    "# masked = np.ma.masked_where(skeleton_prediction == 0, skeleton_prediction.astype(int))\n",
    "# ax.imshow(masked)\n",
    "# plt.title(\"skeletonized prediction - if cannot see skeleton, increase image size\")\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(4, 2, figsize=(10, 22))\n",
    "# section_size = 40\n",
    "# vmin = np.min(image)\n",
    "# vmax = np.max(image)\n",
    "# for index in range(ax.shape[0]):\n",
    "#     y = np.random.randint(0, image.shape[0] - section_size)\n",
    "#     x = np.random.randint(0, image.shape[1] - section_size)\n",
    "#     img_section = image[y : y + section_size + 1, x : x + section_size + 1]\n",
    "#     mask_section = masked[y : y + section_size + 1, x : x + section_size + 1]\n",
    "#     ax[index, 0].imshow(img_section, vmin=vmin, vmax=vmax)\n",
    "#     ax[index, 1].imshow(img_section, vmin=vmin, vmax=vmax)\n",
    "#     ax[index, 1].imshow(mask_section)\n",
    "#     ax[index, 0].set_title(f\"coords: x: {x}, y: {y}\")\n",
    "#     ax[index, 1].set_title(f\"coords: x: {x}, y: {y}\")\n",
    "# fig.suptitle(f\"file: {another_image_file} | section size:{section_size}\")\n",
    "# fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-or-truck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
