{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Summarising and Plotting Statistics\n",
    "\n",
    "After a successful run of `run_topostats` you will have a `all_statistics.csv` file that contains a summary of various\n",
    "statistics about the detected molecules across all image files that were processed. There is a class\n",
    "`topostats.plotting.TopoSum` that uses this file to generate plots automatically and a convenience command\n",
    "`toposum` which provides an entry point to re-run the plotting at the command line.\n",
    "\n",
    "Inevitably though there will be a point where you want to tweak plots for publication or otherwise in some manner that\n",
    "is not conducive to scripting in this manner because making every single option from\n",
    "[Seaborn](https://seaborn.pydata.org/) and [Matplotlib](https://matplotlib.org/) accessible via this class is a\n",
    "considerable amount of work writing [boilerplate code](https://en.wikipedia.org/wiki/Boilerplate_code). Instead the\n",
    "plots should be generated and tweaked interactively a notebook. This Notebook serves as a sample showing how to use the\n",
    "`TopoSum` class and some examples of creating plots directly using [Pandas](https://pandas.pydata.org/).\n",
    "\n",
    "If you are unfamiliar with these packages it is recommended that you read the documentation. It is worth bearing in mind\n",
    "that both Pandas and Seaborn build on the basic functionality that Matplotlib provides, providing easier methods for\n",
    "generating plots. If you are stuck doing something with either of these refer to Matplotlib for how to achieve what you\n",
    "are trying to do.\n",
    "\n",
    "* [Pandas](https://pandas.pydata.org/docs/)\n",
    "* [10 minutes to pandas](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
    "* [Chart visualization — pandas](https://pandas.pydata.org/docs/user_guide/visualization.html?highlight=plotting)\n",
    "* [seaborn: statistical data visualization](https://seaborn.pydata.org/index.html)\n",
    "* [An introduction to seaborn](https://seaborn.pydata.org/tutorial/introduction.html)\n",
    "* [Matplotlib — Visualization with Python](https://matplotlib.org/)\n",
    "* [Tutorials — Matplotlib](https://matplotlib.org/stable/tutorials/index)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from topostats.plotting import TopoSum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Load  `all_statistics.csv`\n",
    "\n",
    "You need to load your data to be able to work with it, this is best achieved by importing it using\n",
    "[Pandas](https://pandas.pydata.org/). Here we use the `tests/resources/minicircle_default_all_statistics.csv` that is\n",
    "part of the TopoStats repository and load it into the object called `df` (short for \"Data Frame\"). You will need to\n",
    "change this path to reflect your output. \n",
    "\n",
    "Because `molecule_number` is unique to the `image` and `threshold` we set a multi-level index of these three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../tests/resources/minicircle_default_all_statistics.csv\")\n",
    "df.set_index([\"image\", \"threshold\", \"molecule_number\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "\n",
    "Sometimes it is desirable to extract further information from the CSV, for example sub-folder names. Pandas is an\n",
    "excellent tool for doing this, but it can be a bit overwhelming with working out where to start as there are so many\n",
    "options. This section contains some simple recipes for manipulating the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Splitting `basename`\n",
    "\n",
    "The `basename` variable contains the directory paths and at times it may be desirable to group distribution plots across\n",
    "images based on the directory from which they originate. The specific directory name is part of the longer string\n",
    "`basename` and so this needs splitting to access the directory components.\n",
    "\n",
    "**NB** The value for `pat` (the pattern on which the string is split) may vary depending on the operating system the\n",
    "images were processed on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and expand `basename` into a new dataframe\n",
    "basename_components_df = df[\"basename\"].str.split(\"/\", expand=True)\n",
    "basename_components_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "You can now select which elements of `basename_components_df` to merge back into the original `df`. To just include both\n",
    "components of the split `basename` you would"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "basename_components_df.columns = [\"basename1\", \"basename2\"]\n",
    "\n",
    "df = df.merge(basename_components_df, left_index=True, right_index=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Plotting with Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Plotting Contour Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"contour_length\"].plot.hist(figsize=(16, 9), bins=20, title=\"Contour Lengths\", alpha=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Plotting End to End Distance of non-Circular grains\n",
    "\n",
    "Circular grains are excluded since their end-to-end length is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"circular\"] == False][\"end_to_end_distance\"].plot.hist(\n",
    "    figsize=(16, 9), bins=20, title=\"End to End Distance\", alpha=0.5\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Multiple Images\n",
    "\n",
    "Often you will have processed multiple images and you will want to plot the distributions of metrics for each image\n",
    "separately.\n",
    "\n",
    "For this example we duplicate the data and append it, adjusting the values slightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(df: pd.DataFrame, scale: float, image: str) -> pd.DataFrame:\n",
    "    \"\"\"Scale the numerical values of a data frame. Retains string variables and the index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        Pandas Dataframe to scale.\n",
    "    scale: float\n",
    "        Factor by which to scale the data.\n",
    "    image: str\n",
    "        Name for new (dummy) image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Scaled data frame\n",
    "    \"\"\"\n",
    "    _df = df[df.select_dtypes(include=[\"number\"]).columns] * scale\n",
    "    _df.reset_index(inplace=True)\n",
    "    _df[\"image\"] = image\n",
    "    _df = pd.concat([_df, df[[\"circular\", \"basename\"]]], axis=1)\n",
    "    _df.set_index([\"image\", \"threshold\", \"molecule_number\"], inplace=True)\n",
    "    return _df\n",
    "\n",
    "\n",
    "smaller = scale_df(df, scale=0.4, image=\"smaller\")\n",
    "larger = scale_df(df, scale=1.5, image=\"larger\")\n",
    "df_three_images = pd.concat([smaller, df, larger])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Contour Length from Three Processed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_three_images[\"contour_length\"].groupby(\"image\").plot.hist(\n",
    "    figsize=(16, 9),\n",
    "    bins=20,\n",
    "    title=\"Contour Lengths\",\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "The bin width in above figure varies for each \"image\" (`smaller`, `larger` and `minicircle`). This is because each\n",
    "image's data is plotted separately (but overlaid on the same graph) and determined dynamically from the range of the data\n",
    "and is a known shortcoming of Pandas (see [ENH: groupby.hist bins don't match\n",
    "#22222](https://github.com/pandas-dev/pandas/issues/22222). To get around this you can specify the number of `bins`\n",
    "explicitly based on the range of _all_ observed data (i.e. `min` to `max`) using `np.linspace()` (from the NumPy\n",
    "package) along with the number of bins across the _total_ space (bins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "min = df_three_images[\"contour_length\"].min()\n",
    "max = df_three_images[\"contour_length\"].max()\n",
    "bins = 20\n",
    "df_three_images[\"contour_length\"].groupby(\"image\").plot.hist(\n",
    "    figsize=(16, 9),\n",
    "    bins=np.linspace(min, max, num=bins),  # Sets the bin width based on total range\n",
    "    title=\"Contour Lengths\",\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Ignoring Image\n",
    "\n",
    "It is possible to plot the distribution of summary statistics without regard to the image from which they are\n",
    "derived. Simply omit the `.groupby(\"image\")` from the plotting command.\n",
    "\n",
    "We also manually set the `fontsize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({\"font.size\": 20})\n",
    "df_three_images[\"contour_length\"].plot.hist(figsize=(16, 9), bins=20, title=\"Contour Lengths\", alpha=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Violin Plot of `max_feret` using Seaborn\n",
    "\n",
    "Pandas does not have built-in support for Violin Plots so we switch to using Seaborn. Here the `fig` and `ax` objects\n",
    "are created first and we use the `ax.text()` method to add a string (`text_str`) in a box to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset dataframe index to make `image` readily available\n",
    "df_three_images.reset_index(inplace=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "sns.violinplot(data=df_three_images, x=\"image\", y=\"max_feret\", hue=\"image\", alpha=0.5)\n",
    "plt.title(\"Minimum Feret\")\n",
    "plt.ylabel(\"Minimum Feret / nm\")\n",
    "# Define text for the string to go in a blue text box.\n",
    "text_str = \"\\n\".join(\n",
    "    [\"Sodium Concentration    : 0.001mM\", \"Scan Size                        : 200x200\", \"More useful information : :-)\"]\n",
    ")\n",
    "props = dict(boxstyle=\"round\", alpha=0.5)\n",
    "ax.text(\n",
    "    0.5,\n",
    "    0.85,\n",
    "    text_str,\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=12,  # verticalalignment=\"top\",\n",
    "    horizontalalignment=\"center\",\n",
    "    bbox=props,\n",
    ")\n",
    "# Return the index\n",
    "df_three_images.set_index([\"image\", \"threshold\", \"molecule_number\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Joint Plot\n",
    "[Joint  Plots](https://seaborn.pydata.org/generated/seaborn.jointplot.html) showing the relationship between two variables can be plotted easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "sns.jointplot(data=df, x=\"min_feret\", y=\"max_feret\", hue=\"circular\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Loading Pickles\n",
    "\n",
    "One of the features of the `topostats.plotting` module is that it will save the graphs it has generated in Python's own\n",
    "format for storing objects. These are known as [pickles](https://realpython.com/python-pickle-module/) and typically\n",
    "have the file extension `.pkl`. After running TopoStats via `run_topostats` and plotting distributions of statistics a\n",
    "`.pkl` will by default be saved in the output directory. Here we load (\"unpickle\") such a saved file which is typically\n",
    "located at `output/summary_distributions/distribution_plots.pkl` and check its type (its a `dict`ionary of plots).\n",
    "\n",
    "**NB** You will _must_ have successfully processed some images with `run_topostats` to generate a pickle file and you\n",
    "should adjust `Path()` in the cell below to reflect the location of this. You can use absolute or relative paths.\n",
    "\n",
    "TopoStats includes the `load_pkl` function which loads and returns the contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from topostats.io import load_pkl\n",
    "\n",
    "# NB - If you get an error saying the file could not be found then you need to modify this line to point to the location\n",
    "# the file was saved to.\n",
    "pkl_path = Path(\"../output/summary_distributions/distribution_plots.pkl\")\n",
    "my_plots = load_pkl(pkl_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "The object `my_plots` is a nested dictionary where the \"keys\" to the dictionary are the names of the statistic that have been\n",
    "plotted, and the values of these are themselves dictionaries of the types of plots that have been generated. We can\n",
    "check what statistics were plotted and saved in a pickle by looking at the first level of keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plots.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "We see that the `area`, `area_cartesian_bbox` and `contour_length`, `end_to_end_distance` and `volume` statistics are\n",
    "available for plotting. We can now look at what types of plots were generated by checking the keys for the dictionary\n",
    "nested under this top-level (**NB** because of the way plots are generated all statistics will have the same plots\n",
    "generated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plots[\"area\"].keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "We see that both `dist` and `violin` plots were generated. To extract these to objects we unpack the values of the\n",
    "dictionary. The following extracts the `figure` (the plot itself) and its `ax` (the \"axes\" which are the properties of\n",
    "the plot) to their own objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_area_dist, ax_area_dist = my_plots[\"area\"][\"dist\"].values()\n",
    "figure_area_violin, ax_area_violin = my_plots[\"area\"][\"violin\"].values()\n",
    "figure_contour_length_violin, ax_contour_length_violin = my_plots[\"contour_length\"][\"violin\"].values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "We can now look at the figure and modify these as we would like, for example to change the `title` and `xlabel` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_area_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_area_dist.set_title(\"This is the Area of minicircle grains\")\n",
    "ax_area_dist.set_xlabel(\"Area in nanometres squared\")\n",
    "figure_area_dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "name": "02-Summary-statistics-and-plots.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
