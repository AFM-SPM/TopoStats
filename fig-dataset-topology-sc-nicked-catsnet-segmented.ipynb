{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5956c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from topostats.io import LoadScans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/Users/sylvi/topo_data/topostats_2/datasets/topology-plasmids\")\n",
    "results_dir = base_dir / \"output_old_catsnet\"\n",
    "assert results_dir.exists()\n",
    "dir_processed_nicked = results_dir / \"plasmid_nic/processed\"\n",
    "assert dir_processed_nicked.exists()\n",
    "dir_processed_sc = results_dir / \"plasmid_sup/processed\"\n",
    "assert dir_processed_sc.exists()\n",
    "\n",
    "file_allstats = results_dir / \"all_statistics.csv\"\n",
    "assert file_allstats.exists()\n",
    "df_allstats = pd.read_csv(file_allstats)\n",
    "print(df_allstats.columns)\n",
    "\n",
    "# convert to nm\n",
    "df_allstats[\"area\"] = df_allstats[\"area\"] * 1e18\n",
    "df_allstats[\"total_contour_length\"] = df_allstats[\"total_contour_length\"] * 1e9\n",
    "df_allstats[\"volume\"] = df_allstats[\"volume\"] * 1e27\n",
    "\n",
    "# print the writhe_string column unique values\n",
    "print(df_allstats[\"writhe_string\"].unique())\n",
    "\n",
    "\n",
    "def calculate_num_char_in_string(input_string: str, character: str) -> int:\n",
    "    \"\"\"Calculate the number of occurrences of a specific character in a string.\"\"\"\n",
    "    # check if nan\n",
    "    if pd.isna(input_string):\n",
    "        return 0\n",
    "    return input_string.count(character)\n",
    "\n",
    "\n",
    "def remove_datapoints_outside_n_std(df: pd.DataFrame, column: str, n_std: float) -> pd.DataFrame:\n",
    "    \"\"\"Remove datapoints outside n standard deviations from the mean.\"\"\"\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    lower_bound = mean - n_std * std\n",
    "    upper_bound = mean + n_std * std\n",
    "    df_filtered = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "df_allstats[\"num_plusses\"] = df_allstats[\"writhe_string\"].apply(calculate_num_char_in_string, character=\"+\")\n",
    "df_allstats[\"num_minuses\"] = df_allstats[\"writhe_string\"].apply(calculate_num_char_in_string, character=\"-\")\n",
    "df_allstats[\"num_plusses_or_minuses\"] = df_allstats[\"num_plusses\"] + df_allstats[\"num_minuses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin of length based on basename\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_allstats, column=\"total_contour_length\", n_std=3), x=\"basename\", y=\"total_contour_length\", inner=\"point\")\n",
    "plt.ylabel(\"Contour Length (nm)\")\n",
    "plt.show()\n",
    "\n",
    "# plot num of plusses or minuses based on basename\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_allstats, column=\"num_plusses_or_minuses\", n_std=3), x=\"basename\", y=\"num_plusses_or_minuses\", inner=\"point\")\n",
    "plt.ylabel(\"Number of crossings\")\n",
    "plt.show()\n",
    "\n",
    "# volume\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_allstats, column=\"volume\", n_std=3), x=\"basename\", y=\"volume\", inner=\"point\")\n",
    "plt.ylabel(\"Volume (nm^3)\")\n",
    "plt.show()\n",
    "\n",
    "# height min\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_allstats, column=\"height_min\", n_std=3), x=\"basename\", y=\"height_min\", inner=\"point\")\n",
    "plt.ylabel(\"Minimum Height (nm)\")\n",
    "plt.show()\n",
    "\n",
    "# height median\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_allstats, column=\"height_median\", n_std=3), x=\"basename\", y=\"height_median\", inner=\"point\")\n",
    "plt.ylabel(\"Median Height (nm)\")\n",
    "plt.show()\n",
    "# height mean\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_allstats, column=\"height_mean\", n_std=3), x=\"basename\", y=\"height_mean\", inner=\"point\")\n",
    "plt.ylabel(\"Mean Height (nm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the files for the sc and nic processed data\n",
    "files_ts_nic = list(sorted(dir_processed_nicked.glob(\"*.topostats\")))\n",
    "print(f\"Found {len(files_ts_nic)} processed files for nicked plasmids\")\n",
    "files_ts_sc = list(sorted(dir_processed_sc.glob(\"*.topostats\")))\n",
    "print(f\"Found {len(files_ts_sc)} processed files for supercoiled plasmids\")\n",
    "\n",
    "loadscans_nic = LoadScans(img_paths=files_ts_nic, channel=\"dummy\")\n",
    "loadscans_nic.get_data()\n",
    "loadscans_dicts_nic = loadscans_nic.img_dict\n",
    "loadscans_sc = LoadScans(img_paths=files_ts_sc, channel=\"dummy\")\n",
    "loadscans_sc.get_data()\n",
    "loadscans_dicts_sc = loadscans_sc.img_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name, image_data in loadscans_dicts_nic.items():\n",
    "    image_data[\"sample_type\"] = \"nicked\"\n",
    "for image_name, image_data in loadscans_dicts_sc.items():\n",
    "    image_data[\"sample_type\"] = \"supercoiled\"\n",
    "\n",
    "# combine the dicts\n",
    "loadscans_dicts = {**loadscans_dicts_nic, **loadscans_dicts_sc}\n",
    "\n",
    "print(f\"num loaded images: {len(loadscans_dicts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e948aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_curvature_list = []\n",
    "for image_name, image_data in loadscans_dicts.items():\n",
    "    sample_type = image_data[\"sample_type\"]\n",
    "    if \"grain_curvature_stats\" not in image_data:\n",
    "        print(f\"No grain curvature data for {image_name}\")\n",
    "        continue\n",
    "    curvature_data = image_data[\"grain_curvature_stats\"][\"above\"]\n",
    "    for grain_id, grain_curvature_data in curvature_data.items():\n",
    "        for mol_id, mol_curvatures in grain_curvature_data.items():\n",
    "            # print(grain_id, mol_id)\n",
    "            min_curvature = np.min(mol_curvatures)\n",
    "            max_curvature = np.max(mol_curvatures)\n",
    "            mean_curvature = np.mean(mol_curvatures)\n",
    "            std_curvature = np.std(mol_curvatures)\n",
    "            percentile_25_curvature = np.percentile(mol_curvatures, 25)\n",
    "            percentile_75_curvature = np.percentile(mol_curvatures, 75)\n",
    "            percentile_iqr_curvature = percentile_75_curvature - percentile_25_curvature\n",
    "            stats_curvature_list.append(\n",
    "                {\n",
    "                    \"image_name\": image_name,\n",
    "                    \"sample_type\": sample_type,\n",
    "                    \"grain_id\": grain_id,\n",
    "                    \"mol_id\": mol_id,\n",
    "                    \"min_curvature\": min_curvature,\n",
    "                    \"max_curvature\": max_curvature,\n",
    "                    \"mean_curvature\": mean_curvature,\n",
    "                    \"std_curvature\": std_curvature,\n",
    "                    \"percentile_25_curvature\": percentile_25_curvature,\n",
    "                    \"percentile_75_curvature\": percentile_75_curvature,\n",
    "                    \"percentile_iqr_curvature\": percentile_iqr_curvature,\n",
    "                    \"total_curvature\": np.sum(mol_curvatures)\n",
    "                }\n",
    "            )\n",
    "\n",
    "df_stats_curvature = pd.DataFrame(stats_curvature_list)\n",
    "# plot min curvature based on sample type\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"min_curvature\", n_std=3), x=\"sample_type\", y=\"min_curvature\", inner=\"point\")\n",
    "plt.ylabel(\"Minimum Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot max curvature based on sample type\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"max_curvature\", n_std=3), x=\"sample_type\", y=\"max_curvature\", inner=\"point\")\n",
    "plt.ylabel(\"Maximum Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot mean curvature based on sample type\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"mean_curvature\", n_std=3), x=\"sample_type\", y=\"mean_curvature\", inner=\"point\")\n",
    "plt.ylabel(\"Mean Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot std curvature based on sample type\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"std_curvature\", n_std=3), x=\"sample_type\", y=\"std_curvature\", inner=\"point\")\n",
    "plt.ylabel(\"Standard Deviation of Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot iqr curvature based on sample type\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"percentile_iqr_curvature\", n_std=3), x=\"sample_type\", y=\"percentile_iqr_curvature\", inner=\"point\")\n",
    "plt.ylabel(\"Interquartile Range of Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot total curvature based on sample type\n",
    "sns.violinplot(data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"total_curvature\", n_std=3), x=\"sample_type\", y=\"total_curvature\", inner=\"point\")\n",
    "plt.ylabel(\"Total Curvature (1/nm)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo2paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
