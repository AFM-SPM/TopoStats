{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5956c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from topostats.io import LoadScans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/Users/sylvi/topo_data/topostats_2/datasets/topology-plasmids\")\n",
    "results_dir = base_dir / \"output_old_catsnet\"\n",
    "assert results_dir.exists()\n",
    "dir_processed_nicked = results_dir / \"plasmid_nic/processed\"\n",
    "assert dir_processed_nicked.exists()\n",
    "dir_processed_sc = results_dir / \"plasmid_sup/processed\"\n",
    "assert dir_processed_sc.exists()\n",
    "\n",
    "file_allstats = results_dir / \"all_statistics.csv\"\n",
    "assert file_allstats.exists()\n",
    "df_allstats = pd.read_csv(file_allstats)\n",
    "print(df_allstats.columns)\n",
    "\n",
    "# convert to nm\n",
    "df_allstats[\"area\"] = df_allstats[\"area\"] * 1e18\n",
    "df_allstats[\"total_contour_length\"] = df_allstats[\"total_contour_length\"] * 1e9\n",
    "df_allstats[\"volume\"] = df_allstats[\"volume\"] * 1e27\n",
    "\n",
    "# print the writhe_string column unique values\n",
    "print(df_allstats[\"writhe_string\"].unique())\n",
    "\n",
    "\n",
    "def calculate_num_char_in_string(input_string: str, character: str) -> int:\n",
    "    \"\"\"Calculate the number of occurrences of a specific character in a string.\"\"\"\n",
    "    # check if nan\n",
    "    if pd.isna(input_string):\n",
    "        return 0\n",
    "    return input_string.count(character)\n",
    "\n",
    "\n",
    "def remove_datapoints_outside_n_std(df: pd.DataFrame, column: str, n_std: float) -> pd.DataFrame:\n",
    "    \"\"\"Remove datapoints outside n standard deviations from the mean.\"\"\"\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    lower_bound = mean - n_std * std\n",
    "    upper_bound = mean + n_std * std\n",
    "    df_filtered = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "df_allstats[\"num_plusses\"] = df_allstats[\"writhe_string\"].apply(calculate_num_char_in_string, character=\"+\")\n",
    "df_allstats[\"num_minuses\"] = df_allstats[\"writhe_string\"].apply(calculate_num_char_in_string, character=\"-\")\n",
    "df_allstats[\"num_plusses_or_minuses\"] = df_allstats[\"num_plusses\"] + df_allstats[\"num_minuses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin of length based on basename\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_allstats, column=\"total_contour_length\", n_std=3),\n",
    "    x=\"basename\",\n",
    "    y=\"total_contour_length\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Contour Length (nm)\")\n",
    "plt.show()\n",
    "\n",
    "# plot num of plusses or minuses based on basename\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_allstats, column=\"num_plusses_or_minuses\", n_std=3),\n",
    "    x=\"basename\",\n",
    "    y=\"num_plusses_or_minuses\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Number of crossings\")\n",
    "plt.show()\n",
    "\n",
    "# volume\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_allstats, column=\"volume\", n_std=3),\n",
    "    x=\"basename\",\n",
    "    y=\"volume\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Volume (nm^3)\")\n",
    "plt.show()\n",
    "\n",
    "# height min\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_allstats, column=\"height_min\", n_std=3),\n",
    "    x=\"basename\",\n",
    "    y=\"height_min\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Minimum Height (nm)\")\n",
    "plt.show()\n",
    "\n",
    "# height median\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_allstats, column=\"height_median\", n_std=3),\n",
    "    x=\"basename\",\n",
    "    y=\"height_median\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Median Height (nm)\")\n",
    "plt.show()\n",
    "# height mean\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_allstats, column=\"height_mean\", n_std=3),\n",
    "    x=\"basename\",\n",
    "    y=\"height_mean\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Mean Height (nm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the files for the sc and nic processed data\n",
    "files_ts_nic = list(sorted(dir_processed_nicked.glob(\"*.topostats\")))\n",
    "print(f\"Found {len(files_ts_nic)} processed files for nicked plasmids\")\n",
    "files_ts_sc = list(sorted(dir_processed_sc.glob(\"*.topostats\")))\n",
    "print(f\"Found {len(files_ts_sc)} processed files for supercoiled plasmids\")\n",
    "\n",
    "loadscans_nic = LoadScans(img_paths=files_ts_nic, channel=\"dummy\")\n",
    "loadscans_nic.get_data()\n",
    "loadscans_dicts_nic = loadscans_nic.img_dict\n",
    "loadscans_sc = LoadScans(img_paths=files_ts_sc, channel=\"dummy\")\n",
    "loadscans_sc.get_data()\n",
    "loadscans_dicts_sc = loadscans_sc.img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name, image_data in loadscans_dicts_nic.items():\n",
    "    image_data[\"sample_type\"] = \"nicked\"\n",
    "for image_name, image_data in loadscans_dicts_sc.items():\n",
    "    image_data[\"sample_type\"] = \"supercoiled\"\n",
    "\n",
    "# combine the dicts\n",
    "loadscans_dicts = {**loadscans_dicts_nic, **loadscans_dicts_sc}\n",
    "\n",
    "print(f\"num loaded images: {len(loadscans_dicts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e948aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting = False\n",
    "verbose = False\n",
    "stats_curvature_list = []\n",
    "for image_name, image_data in loadscans_dicts.items():\n",
    "    sample_type = image_data[\"sample_type\"]\n",
    "    if verbose:\n",
    "        print(image_data.keys())\n",
    "    if \"grain_curvature_stats\" not in image_data:\n",
    "        print(f\"No grain curvature data for {image_name}\")\n",
    "        continue\n",
    "    curvature_data = image_data[\"grain_curvature_stats\"][\"above\"]\n",
    "    for grain_id, grain_curvature_data in curvature_data.items():\n",
    "        for mol_id, mol_curvatures in grain_curvature_data.items():\n",
    "            # print(grain_id, mol_id)\n",
    "            min_curvature = np.min(mol_curvatures)\n",
    "            max_curvature = np.max(mol_curvatures)\n",
    "            mean_curvature = np.mean(mol_curvatures)\n",
    "            std_curvature = np.std(mol_curvatures)\n",
    "            percentile_25_curvature = np.percentile(mol_curvatures, 25)\n",
    "            percentile_75_curvature = np.percentile(mol_curvatures, 75)\n",
    "            percentile_iqr_curvature = percentile_75_curvature - percentile_25_curvature\n",
    "\n",
    "            image = image_data[\"image\"]\n",
    "            if plotting:\n",
    "                plt.imshow(image)\n",
    "                plt.show()\n",
    "            p2nm = image_data[\"pixel_to_nm_scaling\"]\n",
    "\n",
    "            ordered_traces_data = image_data[\"ordered_traces\"][\"above\"][grain_id][mol_id]\n",
    "            ordered_coords = ordered_traces_data[\"ordered_coords\"]\n",
    "            ordered_heights = ordered_traces_data[\"heights\"]\n",
    "            if plotting:\n",
    "                plt.imshow(image)\n",
    "                plt.plot(ordered_coords[:, 1], ordered_coords[:, 0], \"o-\", label=\"Trace\", markersize=1)\n",
    "                plt.show()\n",
    "                plt.plot(ordered_heights)\n",
    "                plt.show()\n",
    "\n",
    "            smoothed_traces_data = image_data[\"splining\"][\"above\"][grain_id][mol_id]\n",
    "            smoothed_trace_bbox = smoothed_traces_data[\"bbox\"]\n",
    "            smoothed_trace_coords = smoothed_traces_data[\"spline_coords\"] + np.array(\n",
    "                [smoothed_trace_bbox[0], smoothed_trace_bbox[1]]\n",
    "            )\n",
    "            # smoothed coords are floats, in pixels, convert to int\n",
    "            smoothed_trace_coords_int = np.round(smoothed_trace_coords).astype(int)\n",
    "            smoothed_trace_heights = image[smoothed_trace_coords_int[:, 0], smoothed_trace_coords_int[:, 1]]\n",
    "            if plotting:\n",
    "                plt.imshow(image)\n",
    "                plt.plot(\n",
    "                    smoothed_trace_coords[:, 1],\n",
    "                    smoothed_trace_coords[:, 0],\n",
    "                    \"o-\",\n",
    "                    label=\"Smoothed Trace\",\n",
    "                    markersize=1,\n",
    "                )\n",
    "                plt.plot(smoothed_trace_coords[0, 1], smoothed_trace_coords[0, 0], \"o\", markersize=5, color=\"yellow\")\n",
    "                plt.show()\n",
    "                plt.plot(smoothed_trace_heights)\n",
    "                plt.show()\n",
    "\n",
    "            diffs_px = np.diff(smoothed_trace_coords, axis=0)\n",
    "            distances_px = np.linalg.norm(diffs_px, axis=1)\n",
    "            total_distance_px = np.sum(distances_px)\n",
    "            total_distance_nm = total_distance_px * p2nm\n",
    "\n",
    "            heights_percentile_10 = np.percentile(smoothed_trace_heights, 10)\n",
    "            heights_percentile_25 = np.percentile(smoothed_trace_heights, 25)\n",
    "\n",
    "            stats_curvature_list.append(\n",
    "                {\n",
    "                    \"image_name\": image_name,\n",
    "                    \"sample_type\": sample_type,\n",
    "                    \"grain_id\": grain_id,\n",
    "                    \"mol_id\": mol_id,\n",
    "                    \"min_curvature\": min_curvature,\n",
    "                    \"max_curvature\": max_curvature,\n",
    "                    \"mean_curvature\": mean_curvature,\n",
    "                    \"std_curvature\": std_curvature,\n",
    "                    \"percentile_25_curvature\": percentile_25_curvature,\n",
    "                    \"percentile_75_curvature\": percentile_75_curvature,\n",
    "                    \"percentile_iqr_curvature\": percentile_iqr_curvature,\n",
    "                    \"total_curvature\": np.sum(mol_curvatures),\n",
    "                    \"total_distance_nm\": total_distance_nm,\n",
    "                    \"heights_percentile_10\": heights_percentile_10,\n",
    "                    \"heights_percentile_25\": heights_percentile_25,\n",
    "                    \"total_curvature_over_total_length\": np.sum(mol_curvatures) / total_distance_nm\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "df_stats_curvature = pd.DataFrame(stats_curvature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a61f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot min curvature based on sample type\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"min_curvature\", n_std=3),\n",
    "    x=\"sample_type\",\n",
    "    y=\"min_curvature\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Minimum Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot max curvature based on sample type\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"max_curvature\", n_std=3),\n",
    "    x=\"sample_type\",\n",
    "    y=\"max_curvature\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Maximum Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot mean curvature based on sample type\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"mean_curvature\", n_std=3),\n",
    "    x=\"sample_type\",\n",
    "    y=\"mean_curvature\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Mean Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot std curvature based on sample type\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"std_curvature\", n_std=3),\n",
    "    x=\"sample_type\",\n",
    "    y=\"std_curvature\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Standard Deviation of Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot iqr curvature based on sample type\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"percentile_iqr_curvature\", n_std=3),\n",
    "    x=\"sample_type\",\n",
    "    y=\"percentile_iqr_curvature\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Interquartile Range of Curvature (1/nm)\")\n",
    "plt.show()\n",
    "# plot total curvature based on sample type\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_stats_curvature, column=\"total_curvature\", n_std=3),\n",
    "    x=\"sample_type\",\n",
    "    y=\"total_curvature\",\n",
    "    inner=\"point\",\n",
    ")\n",
    "plt.ylabel(\"Total Curvature (1/nm)\")\n",
    "plt.show()\n",
    "\n",
    "# grab the sc data that has total curvature above 50\n",
    "df_sc_high_total_curvature = df_stats_curvature[\n",
    "    (df_stats_curvature[\"sample_type\"] == \"supercoiled\") & (df_stats_curvature[\"total_curvature\"] > 50)\n",
    "]\n",
    "df_sc_low_total_curvature = df_stats_curvature[\n",
    "    (df_stats_curvature[\"sample_type\"] == \"supercoiled\") & (df_stats_curvature[\"total_curvature\"] <= 50)\n",
    "]\n",
    "\n",
    "# plot nth height percentile of sc high curvature against nth height percentile sc low curvature\n",
    "fig, ax = plt.subplots()\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_sc_high_total_curvature, column=\"heights_percentile_10\", n_std=5),\n",
    "    x=1,\n",
    "    y=\"heights_percentile_10\",\n",
    "    inner=\"point\",\n",
    "    label=\"high curvature\",\n",
    "    ax=ax\n",
    ")\n",
    "sns.violinplot(\n",
    "    data=remove_datapoints_outside_n_std(df_sc_low_total_curvature, column=\"heights_percentile_10\", n_std=5),\n",
    "    x=2,\n",
    "    y=\"heights_percentile_10\",\n",
    "    inner=\"point\",\n",
    "    label=\"low curvature\",\n",
    "    ax=ax\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo2paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
