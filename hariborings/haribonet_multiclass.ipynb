{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize, to_categorical\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from unet import unet_model\n",
    "from unet_multiclass import multiclass_unet_model\n",
    "import random\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "from skimage.morphology import binary_erosion, binary_dilation\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.filters import hessian\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from skimage.morphology import label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for key, value in os.environ.items():\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that your GPU is working\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MacOS\n",
    "# ORIGINAL_IMAGE_DIR = Path(\"/Users/sylvi/topo_data/hariborings/training_data/cropped/images/\")\n",
    "# MASK_DIR = Path(\"/Users/sylvi/topo_data/hariborings/training_data/cropped/multiclass_masks/\")\n",
    "\n",
    "ORIGINAL_IMAGE_DIR = Path(\n",
    "    \"/Users/sylvi/topo_data/hariborings/training_data/cropped/dna_cas9/big_dataset/images_all_extra_256/\"\n",
    ")\n",
    "MASK_DIR = Path(\"/Users/sylvi/topo_data/hariborings/training_data/cropped/dna_cas9/big_dataset/masks_all_extra_256/\")\n",
    "\n",
    "# Linux\n",
    "# ORIGINAL_IMAGE_DIR = Path(\"/home/sylvia/haribo_data/training_data/cropped/images/\")\n",
    "# MASK_DIR = Path(\"/home/sylvia/haribo_data/training_data/on_target_labelled\")\n",
    "# Linux Multi Class\n",
    "# MASK_DIR = Path(\"/home/sylvia/haribo_data/training_data/cropped/multiclass_masks/\")\n",
    "\n",
    "# Shared XDrive\n",
    "# MODEL_SAVE_DIR = Path(\n",
    "#     \"/Volumes/shared/pyne_group/Shared/AFM_Data/Cas9_Minicircles/deep_learning/saved_models\"\n",
    "# )\n",
    "MODEL_SAVE_DIR = Path(\"/Users/sylvi/topo_data/hariborings/saved_models\")\n",
    "\n",
    "# Get the number of .png images\n",
    "NUM_IMAGES = len(list(ORIGINAL_IMAGE_DIR.glob(\"image_*.npy\")))\n",
    "NUM_MASKS = len(list(MASK_DIR.glob(\"mask_*.npy\")))\n",
    "print(f\"Number of images: {NUM_IMAGES}, Number of masks: {NUM_MASKS}\")\n",
    "\n",
    "\n",
    "def plot_images(image_files, mask_files, width=4):\n",
    "    num_files = len(image_files)\n",
    "    fig, ax = plt.subplots(np.ceil(num_files / width).astype(int), width * 2, figsize=(20, 20))\n",
    "    for i, (image_file, mask_file) in enumerate(zip(image_files, mask_files)):\n",
    "        image = np.load(image_file)\n",
    "        mask = np.load(mask_file)\n",
    "        ax[i // width, i % width * 2].imshow(image, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2].axis(\"off\")\n",
    "        ax[i // width, i % width * 2 + 1].imshow(mask, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2 + 1].axis(\"off\")\n",
    "\n",
    "\n",
    "plot_images(\n",
    "    image_files=sorted(list(ORIGINAL_IMAGE_DIR.glob(\"image_*.npy\"))),\n",
    "    mask_files=sorted(list(MASK_DIR.glob(\"mask_*.npy\"))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_and_shift(image: np.ndarray, ground_truth: np.ndarray, max_zoom_percentage: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"Zooms in on the image by a random amount between 0 and max_zoom_percentage,\n",
    "    then shifts the image by a random amount up to the number of zoomed pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Choose a zoom percentage and caluculate the number of pixels to zoom in\n",
    "    zoom = np.random.uniform(0, 0.1)\n",
    "    zoom_pixels = int(image.shape[0] * zoom)\n",
    "\n",
    "    # If there is zoom, choose a random shift\n",
    "    if int(zoom_pixels) > 0:\n",
    "        shift_x = np.random.randint(int(-zoom_pixels), int(zoom_pixels))\n",
    "        shift_y = np.random.randint(int(-zoom_pixels), int(zoom_pixels))\n",
    "\n",
    "        # Zoom and shift the image\n",
    "        zoomed_and_shifted_image = image[\n",
    "            zoom_pixels + shift_x : -zoom_pixels + shift_x,\n",
    "            zoom_pixels + shift_y : -zoom_pixels + shift_y,\n",
    "        ]\n",
    "        zoomed_and_shifted_ground_truth = ground_truth[\n",
    "            zoom_pixels + shift_x : -zoom_pixels + shift_x,\n",
    "            zoom_pixels + shift_y : -zoom_pixels + shift_y,\n",
    "        ]\n",
    "    else:\n",
    "        # Do nothing\n",
    "        shift_x = 0\n",
    "        shift_y = 0\n",
    "\n",
    "        zoomed_and_shifted_image = image\n",
    "        zoomed_and_shifted_ground_truth = ground_truth\n",
    "\n",
    "    return zoomed_and_shifted_image, zoomed_and_shifted_ground_truth\n",
    "\n",
    "\n",
    "# An image generator that loads images as they are needed\n",
    "def image_generator(image_indexes, batch_size=4, loss=\"categorical_crossentropy\", num_classes=3):\n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_image_indexes = np.random.choice(a=image_indexes, size=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "\n",
    "        # Load the image and ground truth\n",
    "        for index in batch_image_indexes:\n",
    "            image = np.load(ORIGINAL_IMAGE_DIR / f\"image_{index}.npy\")\n",
    "            ground_truth = np.load(MASK_DIR / f\"mask_{index}.npy\")\n",
    "\n",
    "            # Randomly zoom and shift the image and ground truth before resizing\n",
    "            # image, ground_truth = zoom_and_shift(image, ground_truth, max_zoom_percentage=0.1)\n",
    "\n",
    "            # image = Image.fromarray(image)\n",
    "            # image = image.resize((512, 512))\n",
    "            # image = np.array(image)\n",
    "            # Normalise the image\n",
    "            # Cap the values for the image between known values.\n",
    "            # This should help teach the network about features at\n",
    "            # certain heights?\n",
    "            LOWER_LIMIT = -1\n",
    "            UPPER_LIMIT = 8\n",
    "            image = np.clip(image, LOWER_LIMIT, UPPER_LIMIT)\n",
    "            image = image - LOWER_LIMIT\n",
    "            image = image / (UPPER_LIMIT - LOWER_LIMIT)\n",
    "\n",
    "            ground_truth = ground_truth.astype(int)\n",
    "            # ground_truth = Image.fromarray(ground_truth.astype(np.uint8))\n",
    "            # ground_truth = ground_truth.resize(\n",
    "            #     (512, 512), resample=Image.NEAREST\n",
    "            # )  # no interpolation\n",
    "            # ground_truth = np.array(ground_truth).astype(int)\n",
    "\n",
    "            # Augment the images\n",
    "            # Flip the images 50% of the time\n",
    "            if random.choice([0, 1]) == 1:\n",
    "                image = np.flip(image, axis=1)\n",
    "                ground_truth = np.flip(ground_truth, axis=1)\n",
    "            # Rotate the images by either 0, 90, 180, or 270 degrees\n",
    "            rotation = random.choice([0, 1, 2, 3])\n",
    "            image = np.rot90(image, rotation)\n",
    "            ground_truth = np.rot90(ground_truth, rotation)\n",
    "\n",
    "            batch_input.append(image)\n",
    "\n",
    "            if loss == \"categorical_crossentropy\":\n",
    "                batch_output.append(to_categorical(ground_truth))\n",
    "            elif loss == \"dice_loss\":\n",
    "                ground_truth_masks = [(ground_truth == i) for i in range(num_classes)]\n",
    "                ground_truth = np.stack(ground_truth_masks, axis=-1)\n",
    "                batch_output.append(ground_truth)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown loss function\")\n",
    "\n",
    "        batch_x = np.array(batch_input).astype(np.float32)\n",
    "        batch_y = np.array(batch_output).astype(np.float32)\n",
    "\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 1\n",
    "BATCH_SIZE = 5\n",
    "EPOCHS = 50\n",
    "AUGMENTATION_FACTOR = 8\n",
    "LEARNING_RATE = 0.001\n",
    "LOSS_FUNCTION = \"categorical_crossentropy\"\n",
    "IMAGE_SIZE = 256\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the generator is doing the right thing\n",
    "batch_generator = image_generator([0, 1, 2, 3, 4], batch_size=4, loss=LOSS_FUNCTION, num_classes=NUM_CLASSES)\n",
    "(batch_x, batch_y) = next(batch_generator)\n",
    "for image, mask in zip(batch_x, batch_y):\n",
    "    print(f\"mask dtype: {mask.dtype}\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title(\"image\")\n",
    "    ax[1].imshow(mask[:, :, 0])\n",
    "    ax[1].set_title(\"channel 0: background\")\n",
    "    ax[2].imshow(mask[:, :, 1])\n",
    "    ax[2].set_title(\"channel 1: ring\")\n",
    "    ax[3].imshow(mask[:, :, 2])\n",
    "    ax[3].set_title(\"channel 2: gem\")\n",
    "    fig.suptitle(\n",
    "        f\"image shape: {image.shape}   image max: {np.round([np.max(image)], 2)}   image min: {np.round([np.min(image)],2)}   mask shape: {mask.shape}   mask unique: {np.unique(mask)}   mask dtype: {mask.dtype}\"\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split what images are used for training and validation\n",
    "train_image_indexes, validation_image_indexes = train_test_split(range(0, NUM_IMAGES), test_size=0.2, random_state=SEED)\n",
    "\n",
    "print(f\"Number of training images: {len(train_image_indexes)}\")\n",
    "print(f\"Number of validation images: {len(validation_image_indexes)}\")\n",
    "\n",
    "print(f\"Training image indexes: {train_image_indexes}\")\n",
    "print(f\"Validation image indexes: {validation_image_indexes}\")\n",
    "\n",
    "# Create the generators\n",
    "train_generator = image_generator(train_image_indexes, batch_size=4)\n",
    "validation_generator = image_generator(validation_image_indexes, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CREATE THE MODEL =====\n",
    "model = multiclass_unet_model(\n",
    "    IMG_HEIGHT=IMAGE_SIZE, IMG_WIDTH=IMAGE_SIZE, IMG_CHANNELS=CHANNELS, learning_rate=LEARNING_RATE\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    # How many steps (batches of samples) to draw from generator before declaring one epoch finished and starting the next epoch\n",
    "    steps_per_epoch=(NUM_IMAGES // BATCH_SIZE) * AUGMENTATION_FACTOR,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    # How many steps (batches) to yield from validation generator at the end of every epoch\n",
    "    validation_steps=(NUM_IMAGES // BATCH_SIZE) * AUGMENTATION_FACTOR,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# Plot all the metrics\n",
    "fig, ax = plt.subplots(len(history.history.keys()), 1, figsize=(20, 40))\n",
    "for i, metric in enumerate(history.history.keys()):\n",
    "    ax[i].plot(epochs, history.history[metric])\n",
    "    ax[i].plot(epochs, history.history[f\"{metric}\"])\n",
    "    ax[i].set_title(f\"Model {metric}\")\n",
    "    ax[i].set_xlabel(\"Epochs\")\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend([\"train\", \"val\"])\n",
    "    ax[i].set_ylim(0, None)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\n",
    "    MODEL_SAVE_DIR\n",
    "    / f\"haribonet_multiclass_improved_norm_big_95_bridging_v1{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results of the model on the testing set using the validation generator\n",
    "# Get the next batch from the generator\n",
    "(batch_x, batch_y) = next(validation_generator)\n",
    "# Predict the masks\n",
    "predicted_masks = model.predict(batch_x)\n",
    "\n",
    "print(f\"predicted masks shape: {predicted_masks.shape}\")\n",
    "\n",
    "# Threshold the masks\n",
    "# predicted_masks = (predicted_masks > 0.01).astype(np.uint8)\n",
    "# # Show the results\n",
    "# for image, mask, predicted_mask in zip(batch_x, batch_y, predicted_masks):\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "#     plt.imshow(mask)\n",
    "#     plt.show()\n",
    "#     plt.imshow(predicted_mask)\n",
    "#     plt.show()\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "for image, mask, predicted_mask in zip(batch_x, batch_y, predicted_masks):\n",
    "    # Gem predicted mask\n",
    "    predicted_gem_mask = predicted_mask[:, :, 2] > threshold\n",
    "    # Ring predicted mask\n",
    "    predicted_ring_mask = predicted_mask[:, :, 1] > threshold\n",
    "    # Background predicted mask\n",
    "    predicted_background_mask = predicted_mask[:, :, 0] > threshold\n",
    "\n",
    "    combined_predicted_mask = np.zeros_like(predicted_gem_mask).astype(int)\n",
    "    combined_predicted_mask[predicted_gem_mask] = 2\n",
    "    combined_predicted_mask[predicted_ring_mask] = 1\n",
    "\n",
    "    # plt.imshow(image)\n",
    "    # plt.title(\"Image\")\n",
    "    # plt.show()\n",
    "    # plt.imshow(predicted_gem_mask)\n",
    "    # plt.title(\"Predicted Gem Mask\")\n",
    "    # plt.show()\n",
    "    # plt.imshow(predicted_ring_mask)\n",
    "    # plt.title(\"Predicted Ring Mask\")\n",
    "    # plt.show()\n",
    "    # plt.imshow(predicted_background_mask)\n",
    "    # plt.title(\"Predicted Background Mask\")\n",
    "    # plt.show()\n",
    "    # plt.imshow(predicted_mask)\n",
    "    # plt.title(\"Predicted Mask\")\n",
    "    # plt.show()\n",
    "    # plt.title(\"Ground Truth\")\n",
    "    # plt.imshow(mask)\n",
    "    # plt.show()\n",
    "\n",
    "    # Combine these plots into one figure\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axs[0, 0].imshow(image)\n",
    "    axs[0, 0].set_title(\"Image\")\n",
    "    axs[0, 1].imshow(predicted_gem_mask)\n",
    "    axs[0, 1].set_title(\"Predicted Gem Mask\")\n",
    "    axs[1, 0].imshow(predicted_ring_mask)\n",
    "    axs[1, 0].set_title(\"Predicted Ring Mask\")\n",
    "    axs[1, 1].imshow(predicted_background_mask)\n",
    "    axs[1, 1].set_title(\"Predicted Background Mask\")\n",
    "    axs[2, 0].imshow(predicted_mask)\n",
    "    axs[2, 0].set_title(\"Predicted Mask\")\n",
    "    axs[2, 1].imshow(mask)\n",
    "    axs[2, 1].set_title(\"Ground Truth\")\n",
    "    axs[0, 2].imshow(combined_predicted_mask)\n",
    "    axs[0, 2].set_title(\"Combined Predicted Mask\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "# ===== LOAD THE MODEL =====\n",
    "\n",
    "MODEL_SAVE_DIR = Path(\"/Users/sylvi/topo_data/hariborings/saved_models/\")\n",
    "\n",
    "# List available models\n",
    "for model in MODEL_SAVE_DIR.glob(\"*\"):\n",
    "    print(model)\n",
    "\n",
    "filename = \"haribonet_multiclass_2023-10-20_14-01-15_intial_results_multiclass_cropped.h5\"\n",
    "# filename = \"haribonet_multiclass_2023-12-15_14-15-45.h5\"\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_SAVE_DIR / filename)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict images from another directory\n",
    "PREDICT_DIR = Path(\"/Users/sylvi/topo_data/hariborings/protein_crops copy/\")\n",
    "files = sorted(list(PREDICT_DIR.glob(\"*.npy\")))\n",
    "for file in files:\n",
    "    # image = np.load(ORIGINAL_IMAGE_DIR / f\"image_{index}.npy\")\n",
    "    image = np.load(file)\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((256, 256))\n",
    "    image = np.array(image)\n",
    "    # Normalise the image\n",
    "    # image = image - np.min(image)\n",
    "    # image = image / np.max(image)\n",
    "    LOWER_LIMIT = -1\n",
    "    UPPER_LIMIT = 8\n",
    "    image = np.clip(image, LOWER_LIMIT, UPPER_LIMIT)\n",
    "    image = image - LOWER_LIMIT\n",
    "    image = image / (UPPER_LIMIT - LOWER_LIMIT)\n",
    "\n",
    "    # ground_truth = np.load(MASK_DIR / f\"mask_{index}.npy\")\n",
    "    # ground_truth = ground_truth.astype(int)\n",
    "    # ground_truth = Image.fromarray(ground_truth.astype(np.uint8))\n",
    "    # No interpolation\n",
    "    # ground_truth = ground_truth.resize((512, 512), resample=Image.NEAREST)\n",
    "    # ground_truth = np.array(ground_truth).astype(int)\n",
    "\n",
    "    # Predict the mask\n",
    "    predicted_mask = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Gem predicted mask\n",
    "    predicted_gem_mask = predicted_mask[:, :, 2] > threshold\n",
    "    # Ring predicted mask\n",
    "    predicted_ring_mask = predicted_mask[:, :, 1] > threshold\n",
    "    # Background predicted mask\n",
    "    predicted_background_mask = predicted_mask[:, :, 0] > threshold\n",
    "\n",
    "    combined_predicted_mask = np.zeros_like(predicted_gem_mask).astype(int)\n",
    "    combined_predicted_mask[predicted_gem_mask] = 2\n",
    "    combined_predicted_mask[predicted_ring_mask] = 1\n",
    "\n",
    "    # Plot them side by side\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(12, 12))\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title(\"Image\")\n",
    "    axs[1].imshow(predicted_mask)\n",
    "    axs[1].set_title(\"Predicted Mask\")\n",
    "    axs[2].imshow(combined_predicted_mask)\n",
    "    axs[2].set_title(\"Combined Predicted Mask\")\n",
    "    axs[3].imshow(image)\n",
    "    axs[3].imshow(combined_predicted_mask, alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.savefig(PREDICT_DIR / f\"predicted_mask_{file.stem}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an image from the validation set\n",
    "index = 1\n",
    "image = np.load(ORIGINAL_IMAGE_DIR / f\"image_{index}.npy\")\n",
    "image = Image.fromarray(image)\n",
    "image = image.resize((512, 512))\n",
    "image = np.array(image)\n",
    "# Normalise the image\n",
    "image = image - np.min(image)\n",
    "image = image / np.max(image)\n",
    "\n",
    "ground_truth = np.load(MASK_DIR / f\"mask_{index}.npy\")\n",
    "ground_truth = ground_truth.astype(int)\n",
    "ground_truth = Image.fromarray(ground_truth.astype(np.uint8))\n",
    "# No interpolation\n",
    "ground_truth = ground_truth.resize((512, 512), resample=Image.NEAREST)\n",
    "ground_truth = np.array(ground_truth).astype(int)\n",
    "\n",
    "# Predict the mask\n",
    "predicted_mask = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Gem predicted mask\n",
    "predicted_gem_mask = predicted_mask[:, :, 2] > threshold\n",
    "# Ring predicted mask\n",
    "predicted_ring_mask = predicted_mask[:, :, 1] > threshold\n",
    "# Background predicted mask\n",
    "predicted_background_mask = predicted_mask[:, :, 0] > threshold\n",
    "\n",
    "combined_predicted_mask = np.zeros_like(predicted_gem_mask).astype(int)\n",
    "combined_predicted_mask[predicted_gem_mask] = 2\n",
    "combined_predicted_mask[predicted_ring_mask] = 1\n",
    "\n",
    "\n",
    "# Plot them side by side\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 12))\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title(\"Image\")\n",
    "axs[1].imshow(ground_truth)\n",
    "axs[1].set_title(\"Ground Truth\")\n",
    "axs[2].imshow(predicted_mask)\n",
    "axs[2].set_title(\"Predicted Mask\")\n",
    "axs[3].imshow(combined_predicted_mask)\n",
    "axs[3].set_title(\"Combined Predicted Mask\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Remove all but the largest connected component from the mask\n",
    "# Gem is label as 2\n",
    "# Ring is labelled as 1\n",
    "# Background is labelled as 0\n",
    "# Get the connected components\n",
    "\n",
    "# Get just the gem mask\n",
    "gem_mask = combined_predicted_mask == 2\n",
    "# Get the connected components\n",
    "gem_mask_components = label(gem_mask)\n",
    "\n",
    "# Plot the gem mask components with a text label for each component showing the value of the label\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(gem_mask_components)\n",
    "for region in regionprops(gem_mask_components):\n",
    "    # Draw rectangle around segmented coins.\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    bx = (minc, maxc, maxc, minc, minc)\n",
    "    by = (minr, minr, maxr, maxr, minr)\n",
    "    ax.plot(bx, by, \"-r\", linewidth=2.5)\n",
    "    ax.text(\n",
    "        region.centroid[1],\n",
    "        region.centroid[0],\n",
    "        f\"{region.label}\",\n",
    "        color=\"black\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get the properties of the connected components\n",
    "gem_mask_properties = regionprops(gem_mask_components)\n",
    "gem_region_with_largest_area = gem_mask_properties[0]\n",
    "for index, region in enumerate(gem_mask_properties):\n",
    "    # print(f\"Region: {index}, Area: {region.area}\")\n",
    "    if region.area > gem_region_with_largest_area.area:\n",
    "        gem_region_with_largest_area = region\n",
    "\n",
    "print(f\"Region with largest area: {gem_region_with_largest_area.label}\")\n",
    "\n",
    "# Delete all regions except the largest\n",
    "# Actually collect the smaller ones for later\n",
    "smaller_gem_mask_components = np.copy(gem_mask_components)\n",
    "smaller_gem_mask_components[smaller_gem_mask_components == gem_region_with_largest_area.label] = 0\n",
    "# Dilate the smaller gem mask components using binary dilation\n",
    "smaller_gem_component_dilation_iterations = 10\n",
    "for i in range(smaller_gem_component_dilation_iterations):\n",
    "    smaller_gem_mask_components = binary_dilation(smaller_gem_mask_components)\n",
    "plt.imshow(smaller_gem_mask_components)\n",
    "plt.title(\"Smaller Gem Mask Components\")\n",
    "plt.show()\n",
    "\n",
    "gem_mask_components[gem_mask_components != gem_region_with_largest_area.label] = 0\n",
    "\n",
    "# Get just the ring mask\n",
    "ring_mask = combined_predicted_mask == 1\n",
    "# Get the connected components\n",
    "ring_mask_components = label(ring_mask)\n",
    "# Get the properties of the connected components\n",
    "ring_mask_properties = regionprops(ring_mask_components)\n",
    "ring_region_with_largest_area = ring_mask_properties[0]\n",
    "for index, region in enumerate(ring_mask_properties):\n",
    "    # print(f\"Region: {index}, Area: {region.area}\")\n",
    "    if region.area > ring_region_with_largest_area.area:\n",
    "        ring_region_with_largest_area = region\n",
    "\n",
    "# Delete all regions except the largest\n",
    "ring_mask_components[ring_mask_components != ring_region_with_largest_area.label] = 0\n",
    "\n",
    "# Combine the gem and ring masks\n",
    "combined_mask = np.zeros_like(gem_mask_components)\n",
    "combined_mask[gem_mask_components > 0] = 2\n",
    "combined_mask[ring_mask_components > 0] = 1\n",
    "\n",
    "# Add the smaller gem mask components if they touch the ring mask\n",
    "for index in np.unique(label(smaller_gem_mask_components)):\n",
    "    # Skip background\n",
    "    if index == 0:\n",
    "        continue\n",
    "\n",
    "    # Check if the region touches the ring mask using logical and\n",
    "    # Get the region\n",
    "    region = label(smaller_gem_mask_components) == index\n",
    "    # Get the ring mask\n",
    "    ring_mask = ring_mask_components > 0\n",
    "\n",
    "    # Overlap\n",
    "    overlap = np.logical_and(region, ring_mask)\n",
    "    if overlap.any():\n",
    "        # If it does, add it to the ring mask part of the combined mask\n",
    "        combined_mask[region] = 1\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(10, 6))\n",
    "    ax[0].imshow(region)\n",
    "    ax[0].set_title(\"Region\")\n",
    "    ax[1].imshow(ring_mask)\n",
    "    ax[1].set_title(\"Ring Mask\")\n",
    "    ax[2].imshow(overlap)\n",
    "    ax[2].set_title(\"Overlap\")\n",
    "    ax[3].imshow(combined_mask)\n",
    "    ax[3].set_title(\"Combined Mask\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot the largest regions\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 12))\n",
    "axs[0].imshow(gem_mask_components)\n",
    "axs[0].set_title(\"Gem largest region\")\n",
    "axs[1].imshow(ring_mask_components)\n",
    "axs[1].set_title(\"Ring largest region\")\n",
    "axs[2].imshow(combined_mask)\n",
    "axs[2].set_title(\"Combined largest regions\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Try to determine the two connected parts of the large blob with the \"gem\" blob. Sometimes there will be more than two distinct points of contact between the two.\n",
    "# Perhaps separate based on the line connecting the centroids of the gem and ring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot combined mask\n",
    "plt.imshow(combined_mask)\n",
    "plt.title(\"Combined Mask\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "ring_mask = combined_mask == 1\n",
    "# Do the dilation multiple times\n",
    "dilation_strength = 10\n",
    "for i in range(dilation_strength):\n",
    "    ring_mask_dilated = binary_dilation(ring_mask)\n",
    "# Apply the dilation to the combined mask\n",
    "combined_mask[ring_mask_dilated] = 1\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20, 20))\n",
    "axs.imshow(combined_mask)\n",
    "axs.set_title(f\"Combined Mask with {dilation_strength} dilations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove small regions of background\n",
    "background_mask = combined_mask == 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(background_mask)\n",
    "ax.set_title(\"Background Mask\")\n",
    "plt.show()\n",
    "\n",
    "# Turn any regions that are smaller than a certain size into 1s\n",
    "background_mask_components = label(background_mask)\n",
    "background_mask_components_coloured = label2rgb(background_mask_components)\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(background_mask_components_coloured)\n",
    "ax.set_title(\"Background Mask Components\")\n",
    "plt.show()\n",
    "\n",
    "# Make a copy of the combined mask\n",
    "combined_mask_ring_expanded = np.copy(combined_mask)\n",
    "\n",
    "background_mask_properties = regionprops(background_mask_components)\n",
    "for index, region in enumerate(background_mask_properties):\n",
    "    # print(f\"Region: {index}, Area: {region.area}\")\n",
    "    if region.area < 200:\n",
    "        # If the region is touching any pixels that are in the ring mask, then set that region to be in the ring mask\n",
    "        # Get the outline of the region by dilating the region and then subtracting the original region\n",
    "        region_mask = background_mask_components == region.label\n",
    "        region_mask_dilated = binary_dilation(region_mask)\n",
    "        region_outline = np.logical_and(region_mask_dilated, np.invert(region_mask))\n",
    "        # Get the pixels in the outline from the combined mask\n",
    "        region_outline_pixel_values = combined_mask[region_outline]\n",
    "        # print(f'region outline pixel values: {region_outline_pixel_values[0:10]}')\n",
    "        # If any of the pixels in the outline are in the ring mask (ie are 1s) then set the region to be in the ring mask\n",
    "        # Check if there are any pixels with value 1 in the outline\n",
    "        if np.any(region_outline_pixel_values == 1):\n",
    "            # Set the region to be in the ring mask\n",
    "            combined_mask_ring_expanded[background_mask_components == region.label] = 1\n",
    "        else:\n",
    "            # Set the region to be in the gem mask\n",
    "            combined_mask_ring_expanded[background_mask_components == region.label] = 2\n",
    "\n",
    "plt.imshow(background_mask)\n",
    "plt.title(\"Background Mask\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(combined_mask_ring_expanded)\n",
    "ax.set_title(\"combined mask ring expanded\")\n",
    "plt.show()\n",
    "\n",
    "ring_only = combined_mask_ring_expanded == 1\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(ring_only)\n",
    "ax.set_title(\"Ring Only\")\n",
    "plt.show()\n",
    "\n",
    "# Get distance transform of the ring only mask\n",
    "distance_transform = distance_transform_edt(ring_only)\n",
    "plt.imshow(distance_transform)\n",
    "plt.colorbar()\n",
    "plt.title(\"Distance Transform\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the gem mask and dilate it\n",
    "gem_mask = combined_mask == 2\n",
    "near_gem_ring_dilation_strength = 5\n",
    "gem_mask_dilated = np.copy(gem_mask)\n",
    "for i in range(near_gem_ring_dilation_strength):\n",
    "    gem_mask_dilated = binary_dilation(gem_mask_dilated)\n",
    "\n",
    "# Find the pixels in the dilation that are also in the ring mask\n",
    "near_gem_and_ring = np.logical_and(gem_mask_dilated, ring_mask)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(60, 20))\n",
    "axs[0].imshow(gem_mask)\n",
    "axs[0].set_title(\"Gem Mask\")\n",
    "axs[1].imshow(gem_mask_dilated)\n",
    "axs[1].set_title(\"Gem Mask Dilated\")\n",
    "axs[2].imshow(near_gem_and_ring)\n",
    "axs[2].set_title(\"Touching Ring Mask\")\n",
    "plt.show()\n",
    "\n",
    "# # Use distance transform from scipy to get distances from the gem mask\n",
    "# from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "# distance_threshold = 5\n",
    "\n",
    "# # Get pixels near the gem mask\n",
    "# gem_mask = combined_mask == 2\n",
    "# distance_transform = distance_transform_edt(np.invert(gem_mask))\n",
    "\n",
    "# plt.imshow(distance_transform)\n",
    "# plt.colorbar()\n",
    "# plt.title(\"Gem Inverted Distance Transform\")\n",
    "# plt.show()\n",
    "\n",
    "# near_gem = np.logical_and(distance_transform < distance_threshold, distance_transform > 0)\n",
    "# plt.imshow(near_gem)\n",
    "# plt.colorbar()\n",
    "# plt.title(f\"Near Gem threshold: {distance_threshold}\")\n",
    "# plt.show()\n",
    "\n",
    "# # Get the pixels near the ring mask\n",
    "# ring_mask = combined_mask == 1\n",
    "# distance_transform = distance_transform_edt(np.invert(ring_mask))\n",
    "\n",
    "# plt.imshow(distance_transform)\n",
    "# plt.colorbar()\n",
    "# plt.title(\"Ring Inverted Distance Transform\")\n",
    "# plt.show()\n",
    "\n",
    "# near_ring = np.logical_and(distance_transform < distance_threshold, distance_transform > 0)\n",
    "# plt.imshow(near_ring)\n",
    "# plt.colorbar()\n",
    "# plt.title(f\"Near Ring threshold: {distance_threshold}\")\n",
    "# plt.show()\n",
    "\n",
    "# # Plot both near the gem and ring\n",
    "# near_gem_or_ring = np.zeros_like(combined_mask)\n",
    "# near_gem_or_ring[near_gem] += 1\n",
    "# near_gem_or_ring[near_ring] += 1\n",
    "# plt.imshow(near_gem_or_ring)\n",
    "# plt.colorbar()\n",
    "# plt.title(f\"Near Gem or Ring. Threshold: {distance_threshold}\")\n",
    "# plt.show()\n",
    "\n",
    "# # Get the pixels both near the gem and ring\n",
    "# near_gem_and_ring = np.logical_and(near_gem, near_ring)\n",
    "# plt.imshow(near_gem_and_ring)\n",
    "# plt.colorbar()\n",
    "# plt.title(f\"Near both Gem and Ring. Threshold: {distance_threshold}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the midpoint of each of the two intersection regions\n",
    "\n",
    "# Cluster the points into two groups, one for each intersection region\n",
    "# Use the k-means algorithm to cluster the points into two groups\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Get the coordinates of the points\n",
    "coordinates = np.argwhere(near_gem_and_ring)\n",
    "# Cluster the points\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(coordinates)\n",
    "# Get mask of each cluster\n",
    "cluster1_mask = kmeans.labels_ == 0\n",
    "cluster2_mask = kmeans.labels_ == 1\n",
    "# Plot the clusters\n",
    "plt.scatter(coordinates[cluster1_mask, 0], coordinates[cluster1_mask, 1], c=\"red\")\n",
    "plt.scatter(coordinates[cluster2_mask, 0], coordinates[cluster2_mask, 1], c=\"blue\")\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.show()\n",
    "\n",
    "# For each cluster:\n",
    "centroid_1 = np.mean(coordinates[cluster1_mask, :], axis=0)\n",
    "centroid_2 = np.mean(coordinates[cluster2_mask, :], axis=0)\n",
    "\n",
    "# Find the closest point in the other cluster to each centroid\n",
    "# Get the coordinates of each cluster\n",
    "cluster1_coordinates = coordinates[cluster1_mask, :]\n",
    "# Get the distance between each point in cluster 1 and the centroid of cluster 1\n",
    "distances_1 = np.linalg.norm(cluster1_coordinates - centroid_1, axis=1)\n",
    "# Get the index of the closest point\n",
    "closest_point_index_1 = np.argmin(distances_1)\n",
    "# Get the coordinates of the closest point\n",
    "closest_point_1 = cluster1_coordinates[closest_point_index_1, :]\n",
    "centroid_1 = closest_point_1\n",
    "\n",
    "# Get the coordinates of each cluster\n",
    "cluster2_coordinates = coordinates[cluster2_mask, :]\n",
    "# Get the distance between each point in cluster 2 and the centroid of cluster 2\n",
    "distances_2 = np.linalg.norm(cluster2_coordinates - centroid_2, axis=1)\n",
    "# Get the index of the closest point\n",
    "closest_point_index_2 = np.argmin(distances_2)\n",
    "# Get the coordinates of the closest point\n",
    "closest_point_2 = cluster2_coordinates[closest_point_index_2, :]\n",
    "centroid_2 = closest_point_2\n",
    "\n",
    "# Plot the centroids with the cluster\n",
    "plt.imshow(near_gem_and_ring)\n",
    "plt.scatter(centroid_1[1], centroid_1[0], c=\"red\")\n",
    "plt.scatter(centroid_2[1], centroid_2[0], c=\"blue\")\n",
    "plt.title(\"Centroid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a distance transform of the ring mask\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "distance_transform = distance_transform_edt(ring_mask)\n",
    "\n",
    "# Overlay the centroids on the distance transform beside the combined mask\n",
    "fig, axs = plt.subplots(1, 2, figsize=(5, 10))\n",
    "axs[0].imshow(distance_transform)\n",
    "axs[0].scatter(centroid_1[1], centroid_1[0], c=\"red\")\n",
    "axs[0].scatter(centroid_2[1], centroid_2[0], c=\"blue\")\n",
    "axs[0].set_title(\"Distance Transform\")\n",
    "axs[1].imshow(combined_mask)\n",
    "axs[1].scatter(centroid_1[1], centroid_1[0], c=\"red\")\n",
    "axs[1].scatter(centroid_2[1], centroid_2[0], c=\"blue\")\n",
    "axs[1].set_title(\"Combined Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the distance transform to be used as a weight map, so that the pathfinding algorithm will prefer paths that are closer to the ring\n",
    "distance_transform_inverted = np.max(distance_transform) - distance_transform\n",
    "plt.imshow(distance_transform_inverted)\n",
    "plt.colorbar()\n",
    "plt.title(\"Inverted Distance Transform\")\n",
    "plt.show()\n",
    "\n",
    "# Use a weighted pathfinding algorithm to find the best path between the two centroids,\n",
    "# with the distance transform as the weight map\n",
    "from skimage.graph import route_through_array\n",
    "\n",
    "# Get the path\n",
    "path, weight = route_through_array(distance_transform_inverted, centroid_1, centroid_2, fully_connected=True)\n",
    "\n",
    "path = np.stack(path, axis=-1)\n",
    "\n",
    "print(f\"weight: {weight}\")\n",
    "\n",
    "# Plot the path\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 8))\n",
    "axs[0].imshow(distance_transform_inverted)\n",
    "axs[0].scatter(centroid_1[1], centroid_1[0], c=\"red\")\n",
    "axs[0].scatter(centroid_2[1], centroid_2[0], c=\"blue\")\n",
    "axs[0].plot(path[1], path[0], linewidth=2, c=\"pink\")\n",
    "axs[0].set_title(\"Distance Transform\")\n",
    "axs[1].imshow(combined_mask)\n",
    "axs[1].scatter(centroid_1[1], centroid_1[0], c=\"red\")\n",
    "axs[1].scatter(centroid_2[1], centroid_2[0], c=\"blue\")\n",
    "axs[1].plot(path[1], path[0], linewidth=2, c=\"pink\")\n",
    "axs[1].set_title(\"Combined Mask\")\n",
    "axs[2].imshow(image)\n",
    "axs[2].plot(path[1], path[0], linewidth=2, c=\"pink\")\n",
    "axs[2].set_title(\"Original Image\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-or-truck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
