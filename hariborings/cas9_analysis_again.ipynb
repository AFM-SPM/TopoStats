{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33031c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import distance_transform_edt, gaussian_filter1d, binary_fill_holes\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.graph import route_through_array\n",
    "from skimage.morphology import binary_dilation, binary_erosion, skeletonize\n",
    "\n",
    "from topostats.plottingfuncs import Colormap\n",
    "from topostats.tracing.splining import resample_points_regular_interval, windowTrace\n",
    "from topostats.measure.feret import get_feret_from_mask\n",
    "from topostats.measure.curvature import discrete_angle_difference_per_nm_linear\n",
    "from topostats.damage.damage import get_defects_and_gaps_from_bool_array, Defect, DefectGap\n",
    "\n",
    "colormap = Colormap()\n",
    "CMAP = colormap.get_cmap()\n",
    "COLOUR_PATH_CMAP = mpl.cm.coolwarm\n",
    "\n",
    "VMIN = 0\n",
    "VMAX = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e69c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAY_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "DATE_TO_READ_FROM = \"2024-05-21\"\n",
    "BASE_DATA_DIR = Path(f\"/Users/sylvi/topo_data/hariborings/extracted-grains-new-names-20250814/\")\n",
    "data_dirs = {\n",
    "    \"ON_SC\": BASE_DATA_DIR / f\"cas9_ON_SC/date_{DATE_TO_READ_FROM}\",\n",
    "    \"OT1_SC\": BASE_DATA_DIR / f\"cas9_OT1_SC/date_{DATE_TO_READ_FROM}\",\n",
    "    \"OT2_SC\": BASE_DATA_DIR / f\"cas9_OT2_SC/date_{DATE_TO_READ_FROM}\",\n",
    "}\n",
    "BASE_SAVE_DIR = Path(f\"/Users/sylvi/topo_data/hariborings/processed_grains/\")\n",
    "EXT_FIG_DATA_SAVE_DIR = Path(\n",
    "    \"/Users/sylvi/topo_data/cas9-paper-our-response-to-reviewers/20250805-quentin-reviewer-response/figure_ext_3_images/high_res_curvature_graphs\"\n",
    ")\n",
    "MAX_PX_TO_NM = 10.0\n",
    "\n",
    "save_dirs = {\n",
    "    \"ON_SC\": BASE_SAVE_DIR / f\"cas9_ON_SC/{TODAY_DATE}\",\n",
    "    \"OT1_SC\": BASE_SAVE_DIR / f\"cas9_OT1_SC/{TODAY_DATE}\",\n",
    "    \"OT2_SC\": BASE_SAVE_DIR / f\"cas9_OT2_SC/{TODAY_DATE}\",\n",
    "}\n",
    "for sample_type in save_dirs.keys():\n",
    "    save_dirs[sample_type].mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "sample_types = [\"ON_SC\", \"OT1_SC\", \"OT2_SC\"]\n",
    "grains_dicts = {}\n",
    "for sample_type in sample_types:\n",
    "    grains_dicts[sample_type] = {}\n",
    "    file_path = data_dirs[sample_type] / \"ferets_dict.pkl\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        sample_grains_dicts = pickle.load(f)\n",
    "        for grain_index, single_grain_dict in sample_grains_dicts.items():\n",
    "            p_to_nm = single_grain_dict[\"p_to_nm\"]\n",
    "            single_grain_dict[\"sample_type\"] = sample_type\n",
    "            single_grain_dict[\"grain_index\"] = grain_index\n",
    "            if p_to_nm > MAX_PX_TO_NM:\n",
    "                print(\n",
    "                    f\"Skipping grain {grain_index} for sample type [{sample_type}] due to p_to_nm too large: {p_to_nm} > {MAX_PX_TO_NM}\"\n",
    "                )\n",
    "            else:\n",
    "                grains_dicts[sample_type][grain_index] = single_grain_dict\n",
    "\n",
    "\n",
    "# print num grains for each sample type\n",
    "for sample_type, grain_dict in grains_dicts.items():\n",
    "    print(f\"Number of grains for sample type [{sample_type}]: {len(grain_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58717f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_set_nm_size(\n",
    "    image: np.ndarray, p_to_nm: float, target_size_nm: float\n",
    ") -> tuple[npt.NDArray[np.float64], tuple[int, int, int, int]]:\n",
    "    \"\"\"Pad an image to a target size in nm.\"\"\"\n",
    "    target_size_px = int(target_size_nm / p_to_nm)\n",
    "    # if the image is smaller than the target size, pad it with zeros\n",
    "    # If either dimension is larger than the target size, crop it to the target size\n",
    "    if image.shape[0] > target_size_px or image.shape[1] > target_size_px:\n",
    "        cropped_image = image[:target_size_px, :target_size_px]\n",
    "        padding = (\n",
    "            -1 * max(0, target_size_px - cropped_image.shape[0]),\n",
    "            -1 * max(0, target_size_px - cropped_image.shape[1]),\n",
    "        )\n",
    "        return cropped_image, padding\n",
    "\n",
    "    # If either dimension is smaller than the target size, pad it with zeros half on each side\n",
    "    if image.shape[0] < target_size_px or image.shape[1] < target_size_px:\n",
    "        pad_height = max(0, target_size_px - image.shape[0])\n",
    "        pad_width = max(0, target_size_px - image.shape[1])\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "        padded_image = np.pad(\n",
    "            image, ((pad_top, pad_bottom), (pad_left, pad_right)), mode=\"constant\", constant_values=0\n",
    "        )\n",
    "        return padded_image, (pad_top, pad_bottom, pad_left, pad_right)\n",
    "    return image, (0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_grains_dictionary(\n",
    "    grain_dict: dict,\n",
    "    num_cols: int = 3,\n",
    "    vmin: float = VMIN,\n",
    "    vmax: float = VMAX,\n",
    "    cmap: mpl.cm = CMAP,\n",
    "    fontsize: int = 12,\n",
    "    image_plot_size_nm: float = 40,\n",
    "    plot_paths: list[str] = None,\n",
    "    plot_defects: bool = False,\n",
    "    plot_colour_paths: list[tuple[str, str]] = None,\n",
    "    plot_colour_norm_bounds: tuple[float, float] = (-0.3, 0.3),\n",
    "    plot_lineplots: list[tuple[str, str, str, str, str, tuple[float, float] | None]] = None,\n",
    "    plot_lineplot_hlines: list[tuple[float, str]] = None,\n",
    "    save_path: Path | None = None,\n",
    "    show_plot: bool = True,\n",
    "    dpi=200,\n",
    "    figsize_multiplier: float = 4,\n",
    "    wspace: float = 0.3,\n",
    "    hspace: float = 0.6,\n",
    "    wspace_inner: float = 0.2,\n",
    "    hspace_inner: float = 0.3,\n",
    "    num_grains_to_limit_to: int | None = None,\n",
    "    stats_to_include_in_title: list[str] = None,\n",
    ") -> None:\n",
    "    \"\"\"plot grains in a grain dictioanry in a grid layout\"\"\"\n",
    "    num_grains = len(grain_dict.keys())\n",
    "    if num_grains_to_limit_to is not None:\n",
    "        num_grains = min(num_grains, num_grains_to_limit_to)\n",
    "    num_rows = num_grains // num_cols + (num_grains % num_cols > 0)\n",
    "    num_inner_rows = 1\n",
    "    if plot_lineplots is not None:\n",
    "        num_inner_rows = 1 + len(plot_lineplots)\n",
    "    num_inner_cols = 2\n",
    "    fig = plt.figure(figsize=(num_cols * figsize_multiplier, num_rows * figsize_multiplier), dpi=dpi)\n",
    "    outer = gridspec.GridSpec(nrows=num_rows, ncols=num_cols, wspace=wspace, hspace=hspace)\n",
    "\n",
    "    for inner_index, (grain_index, grain_data) in enumerate(grain_dict.items()):\n",
    "        if inner_index >= num_grains:\n",
    "            break\n",
    "        grain_image = grain_data[\"image\"]\n",
    "        grain_mask = grain_data[\"predicted_mask\"]\n",
    "        grain_p_to_nm = grain_data[\"p_to_nm\"]\n",
    "\n",
    "        image_padding = (0, 0, 0, 0)\n",
    "        mask_padding = (0, 0, 0, 0)\n",
    "        if image_plot_size_nm is not None:\n",
    "            grain_image, image_padding = pad_image_to_set_nm_size(grain_image, grain_p_to_nm, image_plot_size_nm)\n",
    "            grain_mask, mask_padding = pad_image_to_set_nm_size(grain_mask, grain_p_to_nm, image_plot_size_nm)\n",
    "\n",
    "        outer_coords = np.unravel_index(inner_index, (num_rows, num_cols))\n",
    "\n",
    "        inner = gridspec.GridSpecFromSubplotSpec(\n",
    "            nrows=num_inner_rows,\n",
    "            ncols=num_inner_cols,\n",
    "            subplot_spec=outer[outer_coords],\n",
    "            wspace=wspace_inner,\n",
    "            hspace=hspace_inner,\n",
    "        )\n",
    "\n",
    "        # plot image\n",
    "        image_ax = plt.Subplot(fig, inner[0, 0])\n",
    "        image_ax.imshow(grain_image, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "        title = f\"Grain {grain_index}\\np_to_nm: {grain_p_to_nm:.2f} nm/px\"\n",
    "        if stats_to_include_in_title is not None:\n",
    "            for stat in stats_to_include_in_title:\n",
    "                stat_value = grain_data[stat]\n",
    "                if isinstance(stat_value, float):\n",
    "                    title += f\"\\n{stat}: {stat_value:.2f}\"\n",
    "                else:\n",
    "                    title += f\"\\n{stat}: {stat_value}\"\n",
    "            title += \"\\n\"\n",
    "        image_ax.set_title(title, fontsize=fontsize, pad=2)\n",
    "        image_ax.axis(\"off\")\n",
    "        fig.add_subplot(image_ax)\n",
    "\n",
    "        # plot mask\n",
    "        mask_ax = plt.Subplot(fig, inner[0, 1])\n",
    "        mask_ax.imshow(grain_mask)\n",
    "        # plot paths if present and required\n",
    "        if plot_paths is not None:\n",
    "            for path_name in plot_paths:\n",
    "                if path_name in grain_data:\n",
    "                    path = grain_data[path_name]\n",
    "                    if path is not None:\n",
    "                        if len(path) > 2:\n",
    "                            # add image padding to the path coordinates\n",
    "                            path = path + np.array(mask_padding[:2])\n",
    "                            mask_ax.plot(path[:, 1], path[:, 0], color=\"red\", linewidth=2, label=path_name)\n",
    "        if plot_colour_paths is not None:\n",
    "            for path_name, colour_array in plot_colour_paths:\n",
    "                if path_name in grain_data:\n",
    "                    path = grain_data[path_name]\n",
    "                    cvals = grain_data[colour_array]\n",
    "                    normalised_cvals = (cvals - plot_colour_norm_bounds[0]) / (\n",
    "                        plot_colour_norm_bounds[1] - plot_colour_norm_bounds[0]\n",
    "                    )\n",
    "                    if path is not None:\n",
    "                        if len(path) > 2:\n",
    "                            # add image padding to the path coordinates\n",
    "                            path = path + np.array(mask_padding[:2])\n",
    "                            for point_index, point in enumerate(path):\n",
    "                                colour = COLOUR_PATH_CMAP(normalised_cvals[point_index])\n",
    "                                if point_index > 0:\n",
    "                                    previous_point = path[point_index - 1]\n",
    "                                    mask_ax.plot(\n",
    "                                        [previous_point[1], point[1]],\n",
    "                                        [previous_point[0], point[0]],\n",
    "                                        color=colour,\n",
    "                                        linewidth=2,\n",
    "                                    )\n",
    "\n",
    "        mask_ax.set_title(\"Mask\", fontsize=fontsize, pad=2)\n",
    "        mask_ax.axis(\"off\")\n",
    "        fig.add_subplot(mask_ax)\n",
    "\n",
    "        if plot_defects:\n",
    "            if \"ordered_defect_list\" in grain_data:\n",
    "                ordered_defect_list = grain_data[\"ordered_defect_list\"].defect_gap_list\n",
    "                for defect_or_gap in ordered_defect_list:\n",
    "                    if isinstance(defect_or_gap, Defect):\n",
    "                        defect = defect_or_gap\n",
    "                        defect_start = defect.start_index\n",
    "                        defect_end = defect.end_index\n",
    "                        defect_start_point = grain_data[\"resampled_path_px\"][defect_start] + np.array(mask_padding[:2])\n",
    "                        defect_end_point = grain_data[\"resampled_path_px\"][defect_end] + np.array(mask_padding[:2])\n",
    "                        mask_ax.scatter(\n",
    "                            defect_start_point[1],\n",
    "                            defect_start_point[0],\n",
    "                            color=\"blue\",\n",
    "                            s=100,\n",
    "                        )\n",
    "                        mask_ax.scatter(\n",
    "                            defect_end_point[1],\n",
    "                            defect_end_point[0],\n",
    "                            color=\"red\",\n",
    "                            s=100,\n",
    "                        )\n",
    "\n",
    "        if plot_lineplots is not None:\n",
    "            for lineplot_index, lineplot_x_y_and_titles in enumerate(plot_lineplots):\n",
    "                # bottom row spans all columns\n",
    "                lineplot_ax = plt.Subplot(fig, inner[1 + lineplot_index, :])\n",
    "                # get the data\n",
    "                (\n",
    "                    lineplot_x_name,\n",
    "                    lineplot_y_name,\n",
    "                    lineplot_xlabel,\n",
    "                    lineplot_ylabel,\n",
    "                    lineplot_title,\n",
    "                    lineplot_norm_bounds,\n",
    "                ) = lineplot_x_y_and_titles\n",
    "                lineplot_x_data = grain_data[lineplot_x_name]\n",
    "                lineplot_y_data = grain_data[lineplot_y_name]\n",
    "                lineplot_ax.plot(lineplot_x_data, lineplot_y_data)\n",
    "                lineplot_ax.set_xlabel(lineplot_xlabel, fontsize=fontsize)\n",
    "                lineplot_ax.set_ylabel(lineplot_ylabel, fontsize=fontsize)\n",
    "                lineplot_ax.set_title(lineplot_title, fontsize=fontsize, pad=2)\n",
    "                lineplot_ax.tick_params(labelsize=6)\n",
    "                if lineplot_norm_bounds is not None:\n",
    "                    lineplot_ax.set_ylim(lineplot_norm_bounds)\n",
    "\n",
    "                if plot_lineplot_hlines is not None:\n",
    "                    for hline_value, hline_label in plot_lineplot_hlines:\n",
    "                        lineplot_ax.axhline(y=hline_value, color=\"grey\", linestyle=\"--\", linewidth=0.5)\n",
    "                        # lineplot_ax.text(\n",
    "                        #     0.01, hline_value, hline_label, color=\"grey\", fontsize=6, transform=lineplot_ax.transAxes\n",
    "                        # )\n",
    "\n",
    "                fig.add_subplot(lineplot_ax)\n",
    "\n",
    "    if save_path is not None:\n",
    "        # create the parent directory\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"saving figure to {save_path}\")\n",
    "        fig.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df344210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all grains\n",
    "if False:\n",
    "    for sample_type, grain_dict in grains_dicts.items():\n",
    "        print(f\"Plotting grains for sample type [{sample_type}]\")\n",
    "        plot_all_grains_dictionary(\n",
    "            grain_dict,\n",
    "            vmin=VMIN,\n",
    "            vmax=VMAX,\n",
    "            cmap=CMAP,\n",
    "            show_plot=True,\n",
    "            num_grains_to_limit_to=10,\n",
    "            wspace=0,\n",
    "            hspace=0,\n",
    "            num_cols=5,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove anomalous grains by index\n",
    "grains_to_remove_on_sc = []\n",
    "grains_to_remove_ot1_sc = [21, 22]  # 21 and 22 have the wrong pixel to nm scaling and I don't want to guess, so\n",
    "# just remove them\n",
    "grains_to_remove_ot2_sc = []\n",
    "\n",
    "# remove the grains\n",
    "for sample_type, grains_to_remove in zip(\n",
    "    [\"ON_SC\", \"OT1_SC\", \"OT2_SC\"], [grains_to_remove_on_sc, grains_to_remove_ot1_sc, grains_to_remove_ot2_sc]\n",
    "):\n",
    "    for grain_index in grains_to_remove:\n",
    "        if grain_index in grains_dicts[sample_type]:\n",
    "            print(f\"Removing grain {grain_index} from sample type [{sample_type}]\")\n",
    "            del grains_dicts[sample_type][grain_index]\n",
    "\n",
    "# print new numbers for sample types\n",
    "for sample_type in [\"ON_SC\", \"OT1_SC\", \"OT2_SC\"]:\n",
    "    print(f\"Number of grains in sample type [{sample_type}]: {len(grains_dicts[sample_type])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathfinding\n",
    "grains_dicts_paths = {}\n",
    "bad_grains = []\n",
    "for sample_type, grains_dict_sample in grains_dicts.items():\n",
    "    grains_dicts_paths[sample_type] = {}\n",
    "    for grain_index, grain_data in grains_dict_sample.items():\n",
    "        grain_image = grain_data[\"image\"]\n",
    "        grain_mask = grain_data[\"predicted_mask\"]\n",
    "        intersection_labels = grain_data[\"intersection_labels\"]\n",
    "\n",
    "        # distance transforms\n",
    "        distance_transform = distance_transform_edt(grain_mask > 0)\n",
    "        distance_transform[grain_mask == 2] = 0\n",
    "\n",
    "        # start at point where intersection region 0 has maximum distance transform\n",
    "        intersection_labels = label(intersection_labels)\n",
    "        intersection_regions = regionprops(intersection_labels)\n",
    "        # Get intersection regions\n",
    "        region_0 = intersection_regions[0]\n",
    "        region_1 = intersection_regions[1]\n",
    "        # Create list of distance transform values for each region\n",
    "        region_0_distance_transform_values = []\n",
    "        region_1_distance_transform_values = []\n",
    "        for pixel in region_0.coords:\n",
    "            region_0_distance_transform_values.append(distance_transform[pixel[0], pixel[1]])\n",
    "        for pixel in region_1.coords:\n",
    "            region_1_distance_transform_values.append(distance_transform[pixel[0], pixel[1]])\n",
    "        region_0_distance_transform_values = np.array(region_0_distance_transform_values)\n",
    "        region_1_distance_transform_values = np.array(region_1_distance_transform_values)\n",
    "        # Get the maximum distance transform value for each region\n",
    "        region_0_max_distance_transform_value = np.max(region_0_distance_transform_values)\n",
    "        region_1_max_distance_transform_value = np.max(region_1_distance_transform_values)\n",
    "        region_0_max_distance_transform_value_index = np.argmax(region_0_distance_transform_values)\n",
    "        region_1_max_distance_transform_value_index = np.argmax(region_1_distance_transform_values)\n",
    "        # get the pixel coord of the maximum distance transform value for each region\n",
    "        region_0_max_distance_transform_pixel = region_0.coords[region_0_max_distance_transform_value_index]\n",
    "        region_1_max_distance_transform_pixel = region_1.coords[region_1_max_distance_transform_value_index]\n",
    "\n",
    "        start_point = (region_0_max_distance_transform_pixel[0], region_0_max_distance_transform_pixel[1])\n",
    "        end_point = (region_1_max_distance_transform_pixel[0], region_1_max_distance_transform_pixel[1])\n",
    "\n",
    "        # invert the distance transform to get the cost map\n",
    "        cost_map = np.max(distance_transform) - distance_transform\n",
    "        # set the maximum value to be huge\n",
    "        cost_map[cost_map == np.max(cost_map)] = 1e4\n",
    "\n",
    "        route, weight = route_through_array(array=cost_map, start=start_point, end=end_point)\n",
    "\n",
    "        route = np.array(route)\n",
    "\n",
    "        # if the route is fewer than 4 points, skip it\n",
    "        if len(route) < 5:\n",
    "            print(\n",
    "                f\"Skipping grain {grain_index} for sample type [{sample_type}] due to route being too short: {len(route)} < 4\"\n",
    "            )\n",
    "            bad_grains.append((sample_type, grain_index))\n",
    "            continue\n",
    "\n",
    "        # save the original grain data\n",
    "        grains_dicts_paths[sample_type][grain_index] = grain_data\n",
    "        # add the route to the grain data\n",
    "        grains_dicts_paths[sample_type][grain_index][\"path\"] = route\n",
    "\n",
    "print(f\"Bad grains: {bad_grains}\")\n",
    "\n",
    "# plot all grains with paths\n",
    "if False:\n",
    "    for sample_type, grain_dict in grains_dicts_paths.items():\n",
    "        print(f\"Plotting grains with paths for sample type [{sample_type}]\")\n",
    "        plot_all_grains_dictionary(\n",
    "            grain_dict=grain_dict,\n",
    "            vmin=VMIN,\n",
    "            vmax=VMAX,\n",
    "            cmap=CMAP,\n",
    "            plot_paths=[\"path\"],\n",
    "            save_path=save_dirs[sample_type] / f\"grains_with_paths_{sample_type}.png\",\n",
    "            num_grains_to_limit_to=10,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling the paths\n",
    "trace_resampling_distance_nm = 1.0\n",
    "smoothing_window_size_nm = 3.0\n",
    "verbose = False\n",
    "\n",
    "grains_dicts_resampled_paths = {}\n",
    "for sample_type, grains_dict_sample in grains_dicts_paths.items():\n",
    "    grains_dicts_resampled_paths[sample_type] = {}\n",
    "    for grain_index, grain_data in grains_dict_sample.items():\n",
    "        grain_image = grain_data[\"image\"]\n",
    "        grain_mask = grain_data[\"predicted_mask\"]\n",
    "        intersection_labels = grain_data[\"intersection_labels\"]\n",
    "        p_to_nm = grain_data[\"p_to_nm\"]\n",
    "        path = grain_data[\"path\"]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"grain: {grain_index}\")\n",
    "            print(f\"p2nm: {p_to_nm}\")\n",
    "            print(f\"path shape: {path.shape}\")\n",
    "        # resampled_path_px = resample_points_regular_interval(\n",
    "        #     points=path, interval=trace_resampling_distance_nm / p_to_nm, circular=False\n",
    "        # )\n",
    "        # if verbose:\n",
    "        #     print(f\"resampled path shape: {resampled_path_px.shape}\")\n",
    "        # smooth the path a bit\n",
    "        smoothed_path_px = windowTrace.pool_trace_linear(\n",
    "            pixel_trace=path,\n",
    "            rolling_window_size=smoothing_window_size_nm,\n",
    "            pixel_to_nm_scaling=p_to_nm,\n",
    "        )\n",
    "        if verbose:\n",
    "            print(f\"smoothed path shape: {smoothed_path_px.shape}\")\n",
    "        # re-sample again to ensure the path is regular\n",
    "        resampled_path_px = resample_points_regular_interval(\n",
    "            points=smoothed_path_px, interval=trace_resampling_distance_nm / p_to_nm, circular=False\n",
    "        )\n",
    "        if verbose:\n",
    "            print(f\"final resampled path shape: {resampled_path_px.shape}\")\n",
    "            print()\n",
    "\n",
    "        if len(resampled_path_px) <= 2:\n",
    "            print(\n",
    "                f\"Skipping grain {grain_index} for sample type [{sample_type}] due to resampled path too short: {len(resampled_path_px)}\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        diffs = resampled_path_px[1:, :] - resampled_path_px[:-1, :]\n",
    "        resampled_distances_px = np.linalg.norm(diffs, axis=1)\n",
    "        # prepend a zero to the distances to match the length of the resampled path\n",
    "        resampled_distances_px = np.insert(resampled_distances_px, 0, 0)\n",
    "        resampled_distances_nm = resampled_distances_px * p_to_nm\n",
    "        cumulative_resampled_distances_px = np.cumsum(resampled_distances_px)\n",
    "        cumulative_resampled_distances_nm = np.cumsum(resampled_distances_nm)\n",
    "\n",
    "        # save the original grain data\n",
    "        grains_dicts_resampled_paths[sample_type][grain_index] = grain_data\n",
    "        # add the smoothed path to the grain data\n",
    "        grains_dicts_resampled_paths[sample_type][grain_index][\"resampled_path_px\"] = resampled_path_px\n",
    "        grains_dicts_resampled_paths[sample_type][grain_index][\"resampled_distances_px\"] = resampled_distances_px\n",
    "        grains_dicts_resampled_paths[sample_type][grain_index][\"resampled_distances_nm\"] = resampled_distances_nm\n",
    "        grains_dicts_resampled_paths[sample_type][grain_index][\n",
    "            \"cumulative_resampled_distances_px\"\n",
    "        ] = cumulative_resampled_distances_px\n",
    "        grains_dicts_resampled_paths[sample_type][grain_index][\n",
    "            \"cumulative_resampled_distances_nm\"\n",
    "        ] = cumulative_resampled_distances_nm\n",
    "\n",
    "# plot all grains with smoothed paths\n",
    "if False:\n",
    "    for sample_type, grain_dict in grains_dicts_resampled_paths.items():\n",
    "        print(f\"Plotting grains with smoothed paths for sample type [{sample_type}]\")\n",
    "        plot_all_grains_dictionary(\n",
    "            grain_dict=grain_dict,\n",
    "            vmin=VMIN,\n",
    "            vmax=VMAX,\n",
    "            cmap=CMAP,\n",
    "            plot_paths=[\"resampled_path_px\"],\n",
    "            save_path=save_dirs[sample_type] / f\"grains_with_resampled_paths_{sample_type}.png\",\n",
    "            show_plot=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cefb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the feret diameter for each grain\n",
    "grains_dicts_feret_diameter = {}\n",
    "for sample_type, grains_dict_sample in grains_dicts_resampled_paths.items():\n",
    "    grains_dicts_feret_diameter[sample_type] = {}\n",
    "    for grain_index, grain_data in grains_dict_sample.items():\n",
    "        grain_image = grain_data[\"image\"]\n",
    "        grain_mask = grain_data[\"predicted_mask\"]\n",
    "        intersection_labels = grain_data[\"intersection_labels\"]\n",
    "        p_to_nm = grain_data[\"p_to_nm\"]\n",
    "\n",
    "        grain_mask_dna_only = grain_mask.copy()\n",
    "        grain_mask_dna_only[grain_mask == 2] = 0\n",
    "\n",
    "        # calculate the feret diameter\n",
    "        feret_diameters = get_feret_from_mask(mask_im=grain_mask_dna_only)\n",
    "        min_feret = feret_diameters[\"min_feret\"] * p_to_nm\n",
    "        max_feret = feret_diameters[\"max_feret\"] * p_to_nm\n",
    "\n",
    "        # save the original grain data\n",
    "        grains_dicts_feret_diameter[sample_type][grain_index] = grain_data\n",
    "        # add the feret diameter to the grain data\n",
    "        grains_dicts_feret_diameter[sample_type][grain_index][\"min_feret\"] = min_feret\n",
    "        grains_dicts_feret_diameter[sample_type][grain_index][\"max_feret\"] = max_feret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b898c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcuate curvature of the path\n",
    "\n",
    "curvature_gaussian_sigma_nm = 1.0\n",
    "curvature_gaussian_sigma_points = int(curvature_gaussian_sigma_nm / trace_resampling_distance_nm)\n",
    "\n",
    "grains_dicts_curvature = {}\n",
    "for sample_type, grains_dict_sample in grains_dicts_feret_diameter.items():\n",
    "    grains_dicts_curvature[sample_type] = {}\n",
    "    for grain_index, grain_data in grains_dict_sample.items():\n",
    "        grain_image = grain_data[\"image\"]\n",
    "        grain_mask = grain_data[\"predicted_mask\"]\n",
    "        intersection_labels = grain_data[\"intersection_labels\"]\n",
    "        p_to_nm = grain_data[\"p_to_nm\"]\n",
    "        resampled_path_px = grain_data[\"resampled_path_px\"]\n",
    "\n",
    "        # calculate the curvature\n",
    "        path_curvatures = discrete_angle_difference_per_nm_linear(trace_nm=resampled_path_px * p_to_nm)\n",
    "        # smooth the curvature with a gaussian filter\n",
    "        path_curvatures = gaussian_filter1d(\n",
    "            path_curvatures,\n",
    "            sigma=curvature_gaussian_sigma_points,\n",
    "            mode=\"nearest\",\n",
    "        )\n",
    "        abs_path_curvatures = np.abs(path_curvatures)\n",
    "\n",
    "        # save the original grain data\n",
    "        grains_dicts_curvature[sample_type][grain_index] = grain_data\n",
    "        # add the curvature to the grain data\n",
    "        grains_dicts_curvature[sample_type][grain_index][\"curvature\"] = path_curvatures\n",
    "        grains_dicts_curvature[sample_type][grain_index][\"abs_curvature\"] = abs_path_curvatures\n",
    "\n",
    "\n",
    "# plot all grains with curvature\n",
    "for sample_type, grain_dict in grains_dicts_curvature.items():\n",
    "    print(f\"Plotting grains with curvature for sample type [{sample_type}]\")\n",
    "    plot_all_grains_dictionary(\n",
    "        grain_dict=grain_dict,\n",
    "        vmin=VMIN,\n",
    "        vmax=VMAX,\n",
    "        cmap=CMAP,\n",
    "        plot_colour_paths=[(\"resampled_path_px\", \"curvature\")],\n",
    "        plot_lineplots=[\n",
    "            [\n",
    "                \"cumulative_resampled_distances_nm\",\n",
    "                \"abs_curvature\",\n",
    "                \"distance (nm)\",\n",
    "                \"curvature (rad/nm)\",\n",
    "                \"Curvature\",\n",
    "                (0.0, 0.5),\n",
    "            ]\n",
    "        ],\n",
    "        save_path=save_dirs[sample_type] / f\"grains_with_curvature_{sample_type}.png\",\n",
    "        show_plot=True,\n",
    "        figsize_multiplier=5,\n",
    "        num_grains_to_limit_to=10,\n",
    "        num_cols=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect defects\n",
    "\n",
    "defect_curvature_threshold_radpernm = 0.3\n",
    "\n",
    "grains_dicts_curvature_defects = {}\n",
    "for sample_type, grains_dict_sample in grains_dicts_curvature.items():\n",
    "    grains_dicts_curvature_defects[sample_type] = {}\n",
    "    for grain_index, grain_data in grains_dict_sample.items():\n",
    "        grain_image = grain_data[\"image\"]\n",
    "        grain_mask = grain_data[\"predicted_mask\"]\n",
    "        intersection_labels = grain_data[\"intersection_labels\"]\n",
    "        p_to_nm = grain_data[\"p_to_nm\"]\n",
    "        resampled_path_px = grain_data[\"resampled_path_px\"]\n",
    "        resampled_distances_nm = grain_data[\"resampled_distances_nm\"]\n",
    "        path_curvatures = grain_data[\"curvature\"]\n",
    "\n",
    "        # detect defects based on curvature\n",
    "        defect_mask = np.abs(path_curvatures) > defect_curvature_threshold_radpernm\n",
    "        ordered_defect_list = get_defects_and_gaps_from_bool_array(\n",
    "            defects_bool=defect_mask,\n",
    "            distance_to_previous_points_nm=grain_data[\"resampled_distances_nm\"],\n",
    "            circular=False,\n",
    "        )\n",
    "\n",
    "        # save the original grain data\n",
    "        grains_dicts_curvature_defects[sample_type][grain_index] = grain_data\n",
    "        # add the defects to the grain data\n",
    "        grains_dicts_curvature_defects[sample_type][grain_index][\"ordered_defect_list\"] = ordered_defect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a59afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all grains with defects\n",
    "if False:\n",
    "    for sample_type, grain_dict in grains_dicts_curvature_defects.items():\n",
    "        print(f\"Plotting grains with defects for sample type [{sample_type}]\")\n",
    "        plot_all_grains_dictionary(\n",
    "            grain_dict=grain_dict,\n",
    "            vmin=VMIN,\n",
    "            vmax=VMAX,\n",
    "            cmap=CMAP,\n",
    "            plot_paths=[\"resampled_path_px\"],\n",
    "            plot_defects=True,\n",
    "            plot_colour_paths=[(\"resampled_path_px\", \"curvature\")],\n",
    "            plot_lineplots=[\n",
    "                [\n",
    "                    \"cumulative_resampled_distances_nm\",\n",
    "                    \"abs_curvature\",\n",
    "                    \"distance (nm)\",\n",
    "                    \"curvature (rad/nm)\",\n",
    "                    \"Curvature\",\n",
    "                    (0.0, 0.5),\n",
    "                ]\n",
    "            ],\n",
    "            plot_lineplot_hlines=[\n",
    "                (defect_curvature_threshold_radpernm, \"upper curvature threshold\"),\n",
    "                (-defect_curvature_threshold_radpernm, \"lower curvature threshold\"),\n",
    "            ],\n",
    "            save_path=save_dirs[sample_type] / f\"grains_with_defects_{sample_type}.png\",\n",
    "            show_plot=True,\n",
    "            figsize_multiplier=5,\n",
    "            num_grains_to_limit_to=30,\n",
    "            num_cols=5,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the positions of the defects for each sample type\n",
    "# collect all defect positions first\n",
    "all_defect_positions = {}\n",
    "maximum_defect_position = 0.0\n",
    "for sample_type, grain_dict in grains_dicts_curvature_defects.items():\n",
    "    defect_positions_nm = []\n",
    "    for grain_index, grain_data in grain_dict.items():\n",
    "        for defect_or_gap in grain_data[\"ordered_defect_list\"].defect_gap_list:\n",
    "            if isinstance(defect_or_gap, Defect):\n",
    "                defect_positions_nm.append(defect_or_gap.position_along_trace_nm)\n",
    "                maximum_defect_position = max(maximum_defect_position, defect_or_gap.position_along_trace_nm)\n",
    "    all_defect_positions[sample_type] = defect_positions_nm\n",
    "    print(f\"Number of defects for sample type [{sample_type}]: {len(defect_positions_nm)}\")\n",
    "\n",
    "# create a single figure with subplots for all sample types\n",
    "fig, axes = plt.subplots(1, len(sample_types), figsize=(15, 5), sharey=True)\n",
    "\n",
    "for i, sample_type in enumerate(sample_types):\n",
    "    defect_positions_nm = all_defect_positions[sample_type]\n",
    "\n",
    "    # create stripplot and violinplot on the same axis\n",
    "    sns.stripplot(x=[sample_type] * len(defect_positions_nm), y=defect_positions_nm, color=\"grey\", ax=axes[i])\n",
    "    sns.violinplot(\n",
    "        x=[sample_type] * len(defect_positions_nm),\n",
    "        y=defect_positions_nm,\n",
    "        color=\"lightblue\",\n",
    "        inner=None,\n",
    "        linewidth=0.5,\n",
    "        alpha=0.5,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "\n",
    "    axes[i].set_title(f\"{sample_type}\\n({len(defect_positions_nm)} defects)\")\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Position along trace (nm)\")\n",
    "    else:\n",
    "        axes[i].set_ylabel(\"\")\n",
    "\n",
    "    # remove x-axis tick labels to clean up appearance\n",
    "    axes[i].set_xticklabels([])\n",
    "\n",
    "plt.suptitle(\"Defect Positions by Sample Type\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# histograms of defect positions\n",
    "fig, axes = plt.subplots(1, len(sample_types), figsize=(15, 5), sharey=True)\n",
    "for i, sample_type in enumerate(sample_types):\n",
    "    defect_positions_nm = all_defect_positions[sample_type]\n",
    "\n",
    "    # create histogram\n",
    "    axes[i].hist(defect_positions_nm, bins=\"auto\", color=\"lightblue\", edgecolor=\"black\", alpha=0.7)\n",
    "    axes[i].set_title(f\"{sample_type}\\n({len(defect_positions_nm)} defects)\")\n",
    "    axes[i].set_xlabel(\"Defect position along trace (nm)\")\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Count\")\n",
    "    else:\n",
    "        axes[i].set_ylabel(\"\")\n",
    "    # set x-axis limits to be the same for all plots\n",
    "    axes[i].set_xlim(0, maximum_defect_position * 1.1)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the combined plot\n",
    "combined_save_path = BASE_SAVE_DIR / f\"combined_defect_positions_{TODAY_DATE}.png\"\n",
    "combined_save_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "plt.savefig(combined_save_path, dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32faf404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each sample type, we want to quantify the sharpness of the turn in the middle X% of the traces for each grain\n",
    "middle_distance_nm = 10\n",
    "\n",
    "bad_grains_middle_curvature_analysis = []\n",
    "grains_dicts_middle_curvature_analysis = {}\n",
    "for sample_type, grains_dict_sample in grains_dicts_curvature_defects.items():\n",
    "    grains_dicts_middle_curvature_analysis[sample_type] = {}\n",
    "    for grain_index, grain_data in grains_dict_sample.items():\n",
    "        grain_image = grain_data[\"image\"]\n",
    "        grain_mask = grain_data[\"predicted_mask\"]\n",
    "        intersection_labels = grain_data[\"intersection_labels\"]\n",
    "        p_to_nm = grain_data[\"p_to_nm\"]\n",
    "        resampled_path_px = grain_data[\"resampled_path_px\"]\n",
    "        resampled_distances_nm = grain_data[\"resampled_distances_nm\"]\n",
    "        path_abs_curvatures = grain_data[\"abs_curvature\"]\n",
    "        cumulative_resampled_distances_nm = grain_data[\"cumulative_resampled_distances_nm\"]\n",
    "\n",
    "        # get the middle point index by finding the index of half the distance\n",
    "        trace_total_distance_nm = np.sum(resampled_distances_nm)\n",
    "        # print(f\"trace total distance nm: {trace_total_distance_nm}\")\n",
    "        trace_half_total_distance_nm = trace_total_distance_nm / 2.0\n",
    "        # print(f\"trace half total distance nm: {trace_half_total_distance_nm}\")\n",
    "        # find the index of the entry in cumulative distances that is closest to half the total distance\n",
    "        middle_middle_index = np.searchsorted(cumulative_resampled_distances_nm, trace_half_total_distance_nm)\n",
    "        middle_middle_nm = cumulative_resampled_distances_nm[middle_middle_index]\n",
    "        # print(f\"middle middle index: {middle_middle_index}, middle_middle_nm: {middle_middle_nm}\")\n",
    "        middle_distance_start_nm = middle_middle_nm - middle_distance_nm / 2\n",
    "        middle_distance_end_nm = middle_middle_nm + middle_distance_nm / 2\n",
    "        # print(\n",
    "        #     f\"middle distance start nm: {middle_distance_start_nm}, middle distance end nm: {middle_distance_end_nm}\"\n",
    "        # )\n",
    "        middle_start_index = np.searchsorted(cumulative_resampled_distances_nm, middle_distance_start_nm)\n",
    "        middle_end_index = np.searchsorted(cumulative_resampled_distances_nm, middle_distance_end_nm)\n",
    "        # print(f\"middle start index: {middle_start_index}, middle end index: {middle_end_index}\")\n",
    "\n",
    "        # Grab the middle path pixels\n",
    "        middle_path_px = resampled_path_px[middle_start_index:middle_end_index]\n",
    "        middle_path_curvatures = path_abs_curvatures[middle_start_index:middle_end_index]\n",
    "        middle_cumulative_resampled_distances_nm = cumulative_resampled_distances_nm[\n",
    "            middle_start_index:middle_end_index\n",
    "        ]\n",
    "\n",
    "        # Grab the start and end (not middle) region path pixels\n",
    "        outer_path_px = np.concatenate((resampled_path_px[:middle_start_index], resampled_path_px[middle_end_index:]))\n",
    "        outer_path_curvatures = np.concatenate(\n",
    "            (path_abs_curvatures[:middle_start_index], path_abs_curvatures[middle_end_index:])\n",
    "        )\n",
    "        outer_cumulative_resampled_distances_nm = np.concatenate(\n",
    "            (\n",
    "                cumulative_resampled_distances_nm[:middle_start_index],\n",
    "                cumulative_resampled_distances_nm[middle_end_index:],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if len(middle_path_px) < 5:\n",
    "            bad_grains_middle_curvature_analysis.append(grain_index)\n",
    "            continue\n",
    "\n",
    "        middle_mean_curvature = np.mean(middle_path_curvatures)\n",
    "        middle_std_curvature = np.std(middle_path_curvatures)\n",
    "        middle_sum_curvature = np.sum(middle_path_curvatures)\n",
    "\n",
    "        outer_mean_curvature = np.mean(outer_path_curvatures)\n",
    "        outer_std_curvature = np.std(outer_path_curvatures)\n",
    "        outer_sum_curvature = np.sum(outer_path_curvatures)\n",
    "\n",
    "        # store\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index] = grain_data.copy()\n",
    "\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index][\n",
    "            \"middle_path_mean_curvature\"\n",
    "        ] = middle_mean_curvature\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index][\n",
    "            \"middle_path_std_curvature\"\n",
    "        ] = middle_std_curvature\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index][\"middle_path_px\"] = middle_path_px\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index][\n",
    "            \"middle_path_curvatures\"\n",
    "        ] = middle_path_curvatures\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index][\n",
    "            \"middle_cumulative_resampled_distances_nm\"\n",
    "        ] = middle_cumulative_resampled_distances_nm\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index][\n",
    "            \"middle_path_sum_curvature\"\n",
    "        ] = middle_sum_curvature\n",
    "\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index][\n",
    "            \"outer_path_mean_curvature\"\n",
    "        ] = outer_mean_curvature\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index][\n",
    "            \"outer_path_std_curvature\"\n",
    "        ] = outer_std_curvature\n",
    "        grains_dicts_middle_curvature_analysis[sample_type][grain_index][\n",
    "            \"outer_path_sum_curvature\"\n",
    "        ] = outer_sum_curvature\n",
    "\n",
    "print(f\"Bad grains for middle curvature analysis: {bad_grains_middle_curvature_analysis}\")\n",
    "\n",
    "if False:\n",
    "    # plot the middle curvature analysis\n",
    "    for sample_type, grain_dict in grains_dicts_middle_curvature_analysis.items():\n",
    "        plot_all_grains_dictionary(\n",
    "            grain_dict=grain_dict,\n",
    "            vmin=VMIN,\n",
    "            vmax=VMAX,\n",
    "            cmap=CMAP,\n",
    "            plot_paths=[\"middle_path_px\"],\n",
    "            plot_colour_paths=[(\"middle_path_px\", \"middle_path_curvatures\")],\n",
    "            plot_lineplots=[\n",
    "                [\n",
    "                    \"middle_cumulative_resampled_distances_nm\",\n",
    "                    \"middle_path_curvatures\",\n",
    "                    \"distance (nm)\",\n",
    "                    \"curvature (rad/nm)\",\n",
    "                    \"Curvature\",\n",
    "                    (0.0, 0.5),\n",
    "                ]\n",
    "            ],\n",
    "            plot_lineplot_hlines=[\n",
    "                (defect_curvature_threshold_radpernm, \"upper curvature threshold\"),\n",
    "                (-defect_curvature_threshold_radpernm, \"lower curvature threshold\"),\n",
    "            ],\n",
    "            save_path=save_dirs[sample_type] / f\"grains_middle_path_curvature_{sample_type}.png\",\n",
    "            show_plot=True,\n",
    "            figsize_multiplier=5,\n",
    "            num_grains_to_limit_to=30,\n",
    "            num_cols=5,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats tests functions\n",
    "# test for normality to decide between parametric (ANOVA) vs non-parametric (Kruskal-Wallis) tests\n",
    "from scipy.stats import shapiro, levene, kruskal, f_oneway, ttest_ind\n",
    "import scipy.stats as scipy_stats\n",
    "from pingouin import welch_anova\n",
    "\n",
    "\n",
    "def test_normality_and_homogeneity(data_df: pd.DataFrame, column: str, sample_differentiator_column: str):\n",
    "    unique_samples = data_df[sample_differentiator_column].unique()\n",
    "    print(f\"Normality and Homogeneity Tests for {column} for {unique_samples}\")\n",
    "\n",
    "    # test normality for each column using shaprio-wilk test\n",
    "    normality_results = {}\n",
    "    for sample_type in unique_samples:\n",
    "        sample_data = data_df[data_df[sample_differentiator_column] == sample_type][column].values\n",
    "        # shapiro-wilk test for n<5000\n",
    "        shapiro_stat, shapiro_p_value = shapiro(sample_data)\n",
    "        is_normal = shapiro_p_value > 0.05\n",
    "        normality_results[sample_type] = is_normal\n",
    "        print(f\"{sample_type}: n={len(sample_data)}, Shapiro-Wilk p={shapiro_p_value:.4f}, Normal: {is_normal}\")\n",
    "\n",
    "    # test homogeneity of variances using Levene's test\n",
    "    levene_stat, levene_p_value = levene(\n",
    "        *[\n",
    "            data_df[data_df[sample_differentiator_column] == sample_type][column].values\n",
    "            for sample_type in unique_samples\n",
    "        ]\n",
    "    )\n",
    "    is_homogeneous = levene_p_value > 0.05\n",
    "    print(f\"Levene's test: p={levene_p_value:.4f}, Homogeneous: {is_homogeneous}\")\n",
    "\n",
    "    return normality_results, is_homogeneous\n",
    "\n",
    "\n",
    "def decide_test(normality_results, is_homogeneous):\n",
    "    if all(normality_results.values()) and is_homogeneous:\n",
    "        return \"anova\"\n",
    "    elif all(normality_results.values()) and not is_homogeneous:\n",
    "        return \"welch_anova\"\n",
    "    else:\n",
    "        return \"kruskal_wallis\"\n",
    "\n",
    "\n",
    "def qq_plots_visual_normality_test(data_df: pd.DataFrame, column: str, sample_differentiator_column: str):\n",
    "    unique_samples = data_df[sample_differentiator_column].unique()\n",
    "    fig, axes = plt.subplots(1, len(unique_samples), figsize=(15, 5), sharey=True)\n",
    "    for i, sample_type in enumerate(unique_samples):\n",
    "        scipy_stats.probplot(\n",
    "            data_df[data_df[sample_differentiator_column] == sample_type][column],\n",
    "            dist=\"norm\",\n",
    "            plot=axes[i],\n",
    "        )\n",
    "        axes[i].set_title(f\"Q-Q Plot: {sample_type}\")\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    plt.suptitle(f\"Q-Q Plots for {column} (should be linear if normal)\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_tests(recommended_test: str, data_df: pd.DataFrame, column: str, sample_differentiator_column: str):\n",
    "    if recommended_test == \"anova\":\n",
    "        print(\"Running ANOVA test\")\n",
    "        anova_result = f_oneway(\n",
    "            *[\n",
    "                data_df[data_df[sample_differentiator_column] == sample_type][column].values\n",
    "                for sample_type in data_df[sample_differentiator_column].unique()\n",
    "            ]\n",
    "        )\n",
    "        print(f\"ANOVA result: F={anova_result.statistic:.4f}, p={anova_result.pvalue:.4f}\")\n",
    "        if anova_result.pvalue < 0.05:\n",
    "            print(\n",
    "                \"Significant differences found, can proceed with a post-hoc test like Tukey HSD (used for when assumptions of ANOVA are met)\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"No significant differences found\")\n",
    "    elif recommended_test == \"welch_anova\":\n",
    "        print(\"Running Welch's ANOVA test\")\n",
    "        welch_result = welch_anova(dv=column, between=sample_differentiator_column, data=data_df)\n",
    "        print(f\"Welch's ANOVA result: F={welch_result['F'].values[0]:.4f}, p={welch_result['pval'].values[0]:.4f}\")\n",
    "        if welch_result[\"pval\"].values[0] < 0.05:\n",
    "            print(\n",
    "                \"Significant differences found, can proceed with a post-hoc test like Games-Howell (used for when assumptions of ANOVA are not met)\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"No significant differences found\")\n",
    "    elif recommended_test == \"kruskal_wallis\":\n",
    "        print(\"Running Kruskal-Wallis test\")\n",
    "        kruskal_result = kruskal(\n",
    "            *[\n",
    "                data_df[data_df[sample_differentiator_column] == sample_type][column].values\n",
    "                for sample_type in data_df[sample_differentiator_column].unique()\n",
    "            ]\n",
    "        )\n",
    "        print(f\"Kruskal-Wallis result: H={kruskal_result.statistic:.4f}, p={kruskal_result.pvalue:.4f}\")\n",
    "        if kruskal_result.pvalue < 0.05:\n",
    "            print(\n",
    "                \"Significant differences found, can proceed with a post-hoc test like Dunn's test (used for non-parametric tests)\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"No significant differences found\")\n",
    "\n",
    "\n",
    "def decide_and_run_stats_tests(data_df: pd.DataFrame, column: str, sample_differentiator_column: str):\n",
    "\n",
    "    print(f\"\\n\\n=== running stats tests for column [{column}]\")\n",
    "\n",
    "    normality_results, is_homogeneous = test_normality_and_homogeneity(\n",
    "        data_df=data_df, column=column, sample_differentiator_column=sample_differentiator_column\n",
    "    )\n",
    "\n",
    "    recommended_test = decide_test(normality_results, is_homogeneous)\n",
    "    print(f\"Recommended test: {recommended_test}\")\n",
    "\n",
    "    qq_plots_visual_normality_test(\n",
    "        data_df=data_df, column=column, sample_differentiator_column=sample_differentiator_column\n",
    "    )\n",
    "\n",
    "    run_tests(\n",
    "        recommended_test=recommended_test,\n",
    "        data_df=data_df,\n",
    "        column=column,\n",
    "        sample_differentiator_column=sample_differentiator_column,\n",
    "    )\n",
    "\n",
    "\n",
    "def t_test_between_two_samples(data_df: pd.DataFrame, sample_type_1: str, sample_type_2: str, column: str):\n",
    "    data1 = data_df[data_df[\"sample_type\"] == sample_type_1][column]\n",
    "    data2 = data_df[data_df[\"sample_type\"] == sample_type_2][column]\n",
    "    t_stat, p_value = ttest_ind(data1, data2, equal_var=False)\n",
    "    print(\n",
    "        f\"\\n\\nT-test between [{sample_type_1}] and [{sample_type_2}] for [{column}]: T={t_stat:.4f}, p={p_value:.4f}\"\n",
    "    )\n",
    "    if p_value < 0.05:\n",
    "        print(\"Significant differences found\")\n",
    "    else:\n",
    "        print(\"No significant differences found\")\n",
    "\n",
    "\n",
    "def mann_whitney_u_test_between_two_samples(\n",
    "    data_df: pd.DataFrame, sample_type_1: str, sample_type_2: str, column: str\n",
    "):\n",
    "    data1 = data_df[data_df[\"sample_type\"] == sample_type_1][column]\n",
    "    data2 = data_df[data_df[\"sample_type\"] == sample_type_2][column]\n",
    "    u_stat, p_value = scipy_stats.mannwhitneyu(data1, data2, alternative=\"two-sided\")\n",
    "    print(\n",
    "        f\"\\n\\nMann-Whitney U test between [{sample_type_1}] and [{sample_type_2}] for [{column}]: U={u_stat:.4f}, p={p_value:.4f}\"\n",
    "    )\n",
    "    if p_value < 0.05:\n",
    "        print(\"Significant differences found\")\n",
    "    else:\n",
    "        print(\"No significant differences found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb078d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distributions of middle curvature stats\n",
    "all_middle_curvature_stats = []\n",
    "all_outer_curvature_stats = []\n",
    "for sample_type, grain_dict in grains_dicts_middle_curvature_analysis.items():\n",
    "    for grain_index, grain_data in grain_dict.items():\n",
    "        all_middle_curvature_stats.append(\n",
    "            {\n",
    "                \"sample_type\": sample_type,\n",
    "                \"grain_index\": grain_index,\n",
    "                \"mean_curvature\": grain_data[\"middle_path_mean_curvature\"],\n",
    "                \"std_curvature\": grain_data[\"middle_path_std_curvature\"],\n",
    "                \"sum_curvature\": grain_data[\"middle_path_sum_curvature\"],\n",
    "            }\n",
    "        )\n",
    "        all_outer_curvature_stats.append(\n",
    "            {\n",
    "                \"sample_type\": sample_type,\n",
    "                \"grain_index\": grain_index,\n",
    "                \"mean_curvature\": grain_data[\"outer_path_mean_curvature\"],\n",
    "                \"std_curvature\": grain_data[\"outer_path_std_curvature\"],\n",
    "                \"sum_curvature\": grain_data[\"outer_path_sum_curvature\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "df_all_middle_curvature_stats = pd.DataFrame(all_middle_curvature_stats)\n",
    "df_all_outer_curvature_stats = pd.DataFrame(all_outer_curvature_stats)\n",
    "\n",
    "# middle curvatures\n",
    "# mean\n",
    "print(\"\\n\\n===== middle curvatures plot =====\")\n",
    "sns.stripplot(x=\"sample_type\", y=\"mean_curvature\", data=df_all_middle_curvature_stats, color=\"grey\")\n",
    "sns.violinplot(\n",
    "    x=\"sample_type\",\n",
    "    y=\"mean_curvature\",\n",
    "    data=df_all_middle_curvature_stats,\n",
    "    color=\"lightblue\",\n",
    "    inner=None,\n",
    "    linewidth=0.5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.title(\"Middle mean Curvature by Sample Type\")\n",
    "plt.ylabel(\"Middle mean curvature (rad/nm)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# std\n",
    "sns.stripplot(x=\"sample_type\", y=\"std_curvature\", data=df_all_middle_curvature_stats, color=\"grey\")\n",
    "sns.violinplot(\n",
    "    x=\"sample_type\",\n",
    "    y=\"std_curvature\",\n",
    "    data=df_all_middle_curvature_stats,\n",
    "    color=\"lightblue\",\n",
    "    inner=None,\n",
    "    linewidth=0.5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.title(\"Middle std Curvature by Sample Type\")\n",
    "plt.ylabel(\"Middle std curvature (rad/nm)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# sum\n",
    "sns.stripplot(x=\"sample_type\", y=\"sum_curvature\", data=df_all_middle_curvature_stats, color=\"grey\")\n",
    "sns.violinplot(\n",
    "    x=\"sample_type\",\n",
    "    y=\"sum_curvature\",\n",
    "    data=df_all_middle_curvature_stats,\n",
    "    color=\"lightblue\",\n",
    "    inner=None,\n",
    "    linewidth=0.5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.title(\"Middle sum Curvature by Sample Type\")\n",
    "plt.ylabel(\"Middle sum curvature (rad/nm)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# outer curvatures\n",
    "# mean\n",
    "print(\"\\n\\n===== outer curvatures plot =====\")\n",
    "\n",
    "sns.stripplot(x=\"sample_type\", y=\"mean_curvature\", data=df_all_outer_curvature_stats, color=\"grey\")\n",
    "sns.violinplot(\n",
    "    x=\"sample_type\",\n",
    "    y=\"mean_curvature\",\n",
    "    data=df_all_outer_curvature_stats,\n",
    "    color=\"lightblue\",\n",
    "    inner=None,\n",
    "    linewidth=0.5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.title(\"outer mean Curvature by Sample Type\")\n",
    "plt.ylabel(\"outer mean curvature (rad/nm)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# std\n",
    "sns.stripplot(x=\"sample_type\", y=\"std_curvature\", data=df_all_outer_curvature_stats, color=\"grey\")\n",
    "sns.violinplot(\n",
    "    x=\"sample_type\",\n",
    "    y=\"std_curvature\",\n",
    "    data=df_all_outer_curvature_stats,\n",
    "    color=\"lightblue\",\n",
    "    inner=None,\n",
    "    linewidth=0.5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.title(\"outer std Curvature by Sample Type\")\n",
    "plt.ylabel(\"outer std curvature (rad/nm)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# sum\n",
    "sns.stripplot(x=\"sample_type\", y=\"sum_curvature\", data=df_all_outer_curvature_stats, color=\"grey\")\n",
    "sns.violinplot(\n",
    "    x=\"sample_type\",\n",
    "    y=\"sum_curvature\",\n",
    "    data=df_all_outer_curvature_stats,\n",
    "    color=\"lightblue\",\n",
    "    inner=None,\n",
    "    linewidth=0.5,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.title(\"outer sum Curvature by Sample Type\")\n",
    "plt.ylabel(\"outer sum curvature (rad/nm)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\n===== middle curvatures stats =====\")\n",
    "\n",
    "\n",
    "decide_and_run_stats_tests(\n",
    "    data_df=df_all_middle_curvature_stats, column=\"sum_curvature\", sample_differentiator_column=\"sample_type\"\n",
    ")\n",
    "\n",
    "decide_and_run_stats_tests(\n",
    "    data_df=df_all_middle_curvature_stats, column=\"mean_curvature\", sample_differentiator_column=\"sample_type\"\n",
    ")\n",
    "\n",
    "decide_and_run_stats_tests(\n",
    "    data_df=df_all_middle_curvature_stats, column=\"std_curvature\", sample_differentiator_column=\"sample_type\"\n",
    ")\n",
    "\n",
    "# just run a t-test between OT1 and OT2\n",
    "t_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"OT1_SC\", sample_type_2=\"OT2_SC\", column=\"mean_curvature\"\n",
    ")\n",
    "\n",
    "t_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"OT1_SC\", sample_type_2=\"OT2_SC\", column=\"sum_curvature\"\n",
    ")\n",
    "\n",
    "t_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"ON_SC\", sample_type_2=\"OT1_SC\", column=\"mean_curvature\"\n",
    ")\n",
    "\n",
    "t_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"ON_SC\", sample_type_2=\"OT2_SC\", column=\"mean_curvature\"\n",
    ")\n",
    "\n",
    "mann_whitney_u_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"OT1_SC\", sample_type_2=\"OT2_SC\", column=\"mean_curvature\"\n",
    ")\n",
    "\n",
    "mann_whitney_u_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"ON_SC\", sample_type_2=\"OT2_SC\", column=\"mean_curvature\"\n",
    ")\n",
    "\n",
    "mann_whitney_u_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"ON_SC\", sample_type_2=\"OT2_SC\", column=\"mean_curvature\"\n",
    ")\n",
    "\n",
    "mann_whitney_u_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"OT1_SC\", sample_type_2=\"OT2_SC\", column=\"sum_curvature\"\n",
    ")\n",
    "\n",
    "mann_whitney_u_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"ON_SC\", sample_type_2=\"OT2_SC\", column=\"sum_curvature\"\n",
    ")\n",
    "\n",
    "mann_whitney_u_test_between_two_samples(\n",
    "    data_df=df_all_middle_curvature_stats, sample_type_1=\"ON_SC\", sample_type_2=\"OT2_SC\", column=\"sum_curvature\"\n",
    ")\n",
    "\n",
    "print(\"\\n\\n===== outer curvatures stats =====\")\n",
    "\n",
    "decide_and_run_stats_tests(\n",
    "    data_df=df_all_outer_curvature_stats, column=\"mean_curvature\", sample_differentiator_column=\"sample_type\"\n",
    ")\n",
    "\n",
    "decide_and_run_stats_tests(\n",
    "    data_df=df_all_outer_curvature_stats, column=\"std_curvature\", sample_differentiator_column=\"sample_type\"\n",
    ")\n",
    "\n",
    "# just run a t-test between OT1 and OT2\n",
    "t_test_between_two_samples(\n",
    "    data_df=df_all_outer_curvature_stats, sample_type_1=\"OT1_SC\", sample_type_2=\"OT2_SC\", column=\"mean_curvature\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a436d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show representative molecules of high and low mean curvature in the middle\n",
    "# find the grain indexes of molecuels with high mean curvature in the middle for OT2 & OT1\n",
    "\n",
    "\n",
    "def get_mols_with_high_low_stat(\n",
    "    grains_dict: dict[str, dict], stat_name: str, number: int, highest_lowest: str\n",
    ") -> dict[str, dict]:\n",
    "    \"\"\"Get molecules with the highest or lowest specified statistic.\"\"\"\n",
    "\n",
    "    # get a list of tuples of grain indexes with the corresponding stat\n",
    "    grain_stats = [(grain_index, grain_data[stat_name]) for grain_index, grain_data in grains_dict.items()]\n",
    "\n",
    "    if highest_lowest == \"highest\":\n",
    "        # sort the statistic\n",
    "        grain_stats_sorted = sorted(grain_stats, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    elif highest_lowest == \"lowest\":\n",
    "        # sort the statistic\n",
    "        grain_stats_sorted = sorted(grain_stats, key=lambda x: x[1])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid value for highest_lowest. Use 'highest' or 'lowest'.\")\n",
    "\n",
    "    # get the grains and return them\n",
    "    grains_to_return = {}\n",
    "    for grain_index, _ in grain_stats_sorted[:number]:\n",
    "        grains_to_return[grain_index] = grains_dict[grain_index]\n",
    "\n",
    "    return grains_to_return\n",
    "\n",
    "\n",
    "# OT2\n",
    "\n",
    "highest_middle_curvature_mean_ot2_molecules = get_mols_with_high_low_stat(\n",
    "    grains_dict=grains_dicts_middle_curvature_analysis[\"OT2_SC\"],\n",
    "    stat_name=\"middle_path_mean_curvature\",\n",
    "    number=5,\n",
    "    highest_lowest=\"highest\",\n",
    ")\n",
    "\n",
    "# plot them\n",
    "plot_all_grains_dictionary(\n",
    "    grain_dict=highest_middle_curvature_mean_ot2_molecules,\n",
    "    plot_colour_paths=[(\"resampled_path_px\", \"curvature\")],\n",
    "    plot_lineplots=[\n",
    "        [\n",
    "            \"cumulative_resampled_distances_nm\",\n",
    "            \"abs_curvature\",\n",
    "            \"distance (nm)\",\n",
    "            \"curvature (rad/nm)\",\n",
    "            \"Curvature\",\n",
    "            (0.0, 0.5),\n",
    "        ]\n",
    "    ],\n",
    "    stats_to_include_in_title=[\n",
    "        \"middle_path_mean_curvature\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "lowest_middle_curvature_mean_ot2_molecules = get_mols_with_high_low_stat(\n",
    "    grains_dict=grains_dicts_middle_curvature_analysis[\"OT2_SC\"],\n",
    "    stat_name=\"middle_path_mean_curvature\",\n",
    "    number=5,\n",
    "    highest_lowest=\"lowest\",\n",
    ")\n",
    "\n",
    "plot_all_grains_dictionary(\n",
    "    grain_dict=lowest_middle_curvature_mean_ot2_molecules,\n",
    "    plot_colour_paths=[(\"resampled_path_px\", \"curvature\")],\n",
    "    plot_lineplots=[\n",
    "        [\n",
    "            \"cumulative_resampled_distances_nm\",\n",
    "            \"abs_curvature\",\n",
    "            \"distance (nm)\",\n",
    "            \"curvature (rad/nm)\",\n",
    "            \"Curvature\",\n",
    "            (0.0, 0.5),\n",
    "        ]\n",
    "    ],\n",
    "    stats_to_include_in_title=[\n",
    "        \"middle_path_mean_curvature\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# OT1\n",
    "highest_middle_curvature_mean_ot1_molecules = get_mols_with_high_low_stat(\n",
    "    grains_dict=grains_dicts_middle_curvature_analysis[\"OT1_SC\"],\n",
    "    stat_name=\"middle_path_mean_curvature\",\n",
    "    number=5,\n",
    "    highest_lowest=\"highest\",\n",
    ")\n",
    "\n",
    "# plot them\n",
    "plot_all_grains_dictionary(\n",
    "    grain_dict=highest_middle_curvature_mean_ot1_molecules,\n",
    "    plot_colour_paths=[(\"resampled_path_px\", \"curvature\")],\n",
    "    plot_lineplots=[\n",
    "        [\n",
    "            \"cumulative_resampled_distances_nm\",\n",
    "            \"abs_curvature\",\n",
    "            \"distance (nm)\",\n",
    "            \"curvature (rad/nm)\",\n",
    "            \"Curvature\",\n",
    "            (0.0, 0.5),\n",
    "        ]\n",
    "    ],\n",
    "    stats_to_include_in_title=[\n",
    "        \"middle_path_mean_curvature\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "lowest_middle_curvature_mean_ot1_molecules = get_mols_with_high_low_stat(\n",
    "    grains_dict=grains_dicts_middle_curvature_analysis[\"OT1_SC\"],\n",
    "    stat_name=\"middle_path_mean_curvature\",\n",
    "    number=5,\n",
    "    highest_lowest=\"lowest\",\n",
    ")\n",
    "\n",
    "plot_all_grains_dictionary(\n",
    "    grain_dict=lowest_middle_curvature_mean_ot1_molecules,\n",
    "    plot_colour_paths=[(\"resampled_path_px\", \"curvature\")],\n",
    "    plot_lineplots=[\n",
    "        [\n",
    "            \"cumulative_resampled_distances_nm\",\n",
    "            \"abs_curvature\",\n",
    "            \"distance (nm)\",\n",
    "            \"curvature (rad/nm)\",\n",
    "            \"Curvature\",\n",
    "            (0.0, 0.5),\n",
    "        ]\n",
    "    ],\n",
    "    stats_to_include_in_title=[\n",
    "        \"middle_path_mean_curvature\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf5055",
   "metadata": {},
   "source": [
    "### ext figure for middle curvature\n",
    "\n",
    "- append what we have (in the slides) as a picture to the extended figure\n",
    "\t- two pictures of the afm (34 OT2, 52 OT1) for the sharp images, add scale bars, add a dotted line along the dna to show the middle region \n",
    "\t- show only the OT2 & OT1 violin plots with labels \"OT1\", \"OT2\"\n",
    "\t- grab the N for the caption\n",
    "\t- scale bar or add \"image width\"\n",
    "- call the name \"central mean curvature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot OT2 grain 34 with scale bar and line for the middle region\n",
    "ot2_grain = grains_dicts_middle_curvature_analysis[\"OT2_SC\"][34]\n",
    "ot1_grain = grains_dicts_middle_curvature_analysis[\"OT1_SC\"][32]\n",
    "\n",
    "print(ot2_grain.keys())\n",
    "\n",
    "figsize = (4, 2.5)\n",
    "axlabel_font_size = 14\n",
    "dpi = 500\n",
    "legend_font_size = 8\n",
    "\n",
    "\n",
    "def plot_grain_for_ext_fig(\n",
    "    grain_dict: dict,\n",
    "    coloured_lines_norm_bounds: tuple[int, int] = (0.0, 0.3),\n",
    ") -> None:\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    image = grain_dict[\"image\"]\n",
    "    middle_path_px = grain_dict[\"middle_path_px\"]\n",
    "    middle_path_curvatures = grain_dict[\"middle_path_curvatures\"]\n",
    "    resampled_path_px = grain_dict[\"resampled_path_px\"]\n",
    "    abs_curvature = grain_dict[\"abs_curvature\"]\n",
    "    p_to_nm = grain_dict[\"p_to_nm\"]\n",
    "\n",
    "    plt.imshow(image, cmap=CMAP, vmin=VMIN, vmax=VMAX)\n",
    "\n",
    "    plt.plot(middle_path_px[:, 1], middle_path_px[:, 0], color=\"lightgrey\", linewidth=15, label=\"Middle Path\")\n",
    "\n",
    "    normalised_curvature = (middle_path_curvatures - coloured_lines_norm_bounds[0]) / (\n",
    "        coloured_lines_norm_bounds[1] - coloured_lines_norm_bounds[0]\n",
    "    )\n",
    "    for point_index, point in enumerate(middle_path_px):\n",
    "        colour = mpl.cm.Blues(normalised_curvature[point_index])\n",
    "        if point_index > 0:\n",
    "            previous_point = middle_path_px[point_index - 1]\n",
    "            plt.plot(\n",
    "                [previous_point[1], point[1]],\n",
    "                [previous_point[0], point[0]],\n",
    "                color=colour,\n",
    "                linewidth=5,\n",
    "            )\n",
    "\n",
    "    # render a scale bar of 20 nm\n",
    "\n",
    "    scale_bar_length_nm = 20\n",
    "    scale_bar_length_px = scale_bar_length_nm / p_to_nm\n",
    "    # draw a white line on the image in the bottom right\n",
    "    scale_bar_r = image.shape[1] - image.shape[1] * 0.08\n",
    "    scale_bar_y = image.shape[0] - image.shape[0] * 0.08\n",
    "    scale_bar_l = scale_bar_r - scale_bar_length_px\n",
    "    plt.plot(\n",
    "        [scale_bar_l, scale_bar_r],\n",
    "        [scale_bar_y, scale_bar_y],\n",
    "        color=\"white\",\n",
    "        linewidth=15,\n",
    "        label=f\"Scale Bar: {scale_bar_length_nm} nm\",\n",
    "    )\n",
    "\n",
    "    # turn axes off\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    # save the figure\n",
    "    plt.savefig(\n",
    "        EXT_FIG_DATA_SAVE_DIR\n",
    "        / f\"grain_central_curvature_plot_{grain_dict['sample_type']}_{grain_dict['grain_index']}.png\",\n",
    "        dpi=dpi,\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_grain_for_ext_fig(ot2_grain)\n",
    "plot_grain_for_ext_fig(ot1_grain)\n",
    "\n",
    "# plot the violins of just OT1 & OT2 middle mean curvature\n",
    "df_middle_curvature_stats_ot1_ot2 = df_all_middle_curvature_stats[\n",
    "    df_all_middle_curvature_stats[\"sample_type\"].isin([\"OT1_SC\", \"OT2_SC\"])\n",
    "]\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.stripplot(ax=ax, x=\"sample_type\", y=\"mean_curvature\", data=df_middle_curvature_stats_ot1_ot2, color=\"grey\", s=4)\n",
    "sns.violinplot(\n",
    "    x=\"sample_type\",\n",
    "    y=\"mean_curvature\",\n",
    "    data=df_middle_curvature_stats_ot1_ot2,\n",
    "    # color=\"lightblue\",\n",
    "    hue=\"sample_type\",\n",
    "    # set palette with hex\n",
    "    palette={\"OT1_SC\": \"#3C7FE6\", \"OT2_SC\": \"#0C5ACE\"},\n",
    "    inner=None,\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.ylabel(\"Central mean\\ncurvature (rad/nm)\", fontsize=axlabel_font_size)\n",
    "# set font size of x ticks\n",
    "plt.xticks(fontsize=axlabel_font_size)\n",
    "# rename the xticks\n",
    "plt.xticks(ticks=[0, 1], labels=[\"ot1 sc\", \"ot2 sc\"])\n",
    "# set font size of y ticks\n",
    "plt.yticks(fontsize=axlabel_font_size)\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "# save the figure\n",
    "plt.savefig(EXT_FIG_DATA_SAVE_DIR / f\"ot1_ot2_central_mean_curvature_violin_plot.png\", dpi=dpi)\n",
    "plt.show()\n",
    "\n",
    "# print the Ns\n",
    "samples = df_middle_curvature_stats_ot1_ot2[\"sample_type\"].value_counts()\n",
    "print(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topostats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
