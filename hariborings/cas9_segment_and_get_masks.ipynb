{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union, Dict\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from skimage.morphology import binary_dilation, skeletonize\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "from skimage.graph import route_through_array\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import seaborn as sns\n",
    "from skimage.morphology import binary_erosion\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.feature import canny\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "from topostats.grain_finding_haribo_unet import (\n",
    "    predict_unet,\n",
    "    load_model,\n",
    "    predict_unet_multiclass_and_get_angle,\n",
    "    mean_iou,\n",
    "    iou,\n",
    "    predict_unet_multiclass,\n",
    ")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from topostats.plottingfuncs import Colormap\n",
    "\n",
    "colormap = Colormap()\n",
    "CMAP = colormap.get_cmap()\n",
    "\n",
    "VMIN = 0\n",
    "VMAX = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Get grain crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLATTENED_IMAGE_DIR = Path(\"/Users/sylvi/topo_data/hariborings/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get existing crops from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = \"ON_SC\"\n",
    "MAX_P_TO_NM = 10.0\n",
    "PLOT_RESULTS = True\n",
    "# Sadly needs to be local to the script because of loading times\n",
    "MODEL_PATH = Path(\"./haribonet_multiclass_improved_norm_big_95_bridging_v1_2024-01-17_10-58-46.h5\")\n",
    "model = load_model(model_path=MODEL_PATH, custom_objects={\"iou\": iou, \"mean_iou\": mean_iou})\n",
    "MODEL_CONFIDENCE = 0.5\n",
    "CROPPED_IMAGE_DIR = Path(f\"/Users/sylvi/topo_data/hariborings/cas9_crops_p2nm/{SAMPLE}_p2nm\")\n",
    "assert CROPPED_IMAGE_DIR.exists()\n",
    "\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "IMAGE_SAVE_DIR = Path(f\"/Users/sylvi/topo_data/hariborings/extracted_grains/cas9_{SAMPLE}/{today}/\")\n",
    "IMAGE_SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "image_files = list(CROPPED_IMAGE_DIR.glob(\"*.npy\"))\n",
    "image_files = sorted(image_files, key=lambda x: float(re.findall(r\"\\d+\\.\\d+\", x.name)[0]))\n",
    "print(f\"Found {len(image_files)} images\")\n",
    "\n",
    "grain_dicts = {}\n",
    "\n",
    "for index, image_file in enumerate(image_files):\n",
    "    image = np.load(image_file)\n",
    "    p_to_nm = float(re.findall(r\"\\d+\\.\\d+\", image_file.name)[0])\n",
    "\n",
    "    if p_to_nm > MAX_P_TO_NM:\n",
    "        continue\n",
    "\n",
    "    predicted_mask = predict_unet_multiclass(\n",
    "        image=image,\n",
    "        model=model,\n",
    "        confidence=MODEL_CONFIDENCE,\n",
    "        model_image_size=256,\n",
    "        image_output_dir=IMAGE_SAVE_DIR,\n",
    "        filename=\"test\",\n",
    "        image_index=index,\n",
    "        quiet=True,\n",
    "        IMAGE_SAVE_DIR=IMAGE_SAVE_DIR,\n",
    "        normalisation_set_range=(-1, 8),\n",
    "    )\n",
    "\n",
    "    grain_dicts[index] = {\n",
    "        \"image\": image,\n",
    "        \"predicted_mask\": predicted_mask,\n",
    "        \"p_to_nm\": p_to_nm,\n",
    "    }\n",
    "\n",
    "clear_output()\n",
    "print(f\"Number of images: {len(grain_dicts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(\n",
    "    images: list, masks: list, grain_indexes: list, px_to_nms: list, width=5, VMIN=VMIN, VMAX=VMAX, cmap=CMAP\n",
    "):\n",
    "    num_images = len(images)\n",
    "    num_rows = num_images // width + 1\n",
    "    num_images_in_batch = 2\n",
    "    fig, axes = plt.subplots(num_rows, width * num_images_in_batch, figsize=(width * 4, num_rows * 4))\n",
    "    for i, (image, mask, grain_index, p_to_nm) in enumerate(zip(images, masks, grain_indexes, px_to_nms)):\n",
    "        # Plot image\n",
    "        im_ax = axes[i // width, i % width * num_images_in_batch]\n",
    "        im_ax.imshow(image, cmap=CMAP, vmin=VMIN, vmax=VMAX)\n",
    "        im_ax.set_title(f\"Grain {grain_index} {p_to_nm} p/nm\")\n",
    "        im_ax.axis(\"off\")\n",
    "        # Plot mask\n",
    "        mask_ax = axes[i // width, i % width * num_images_in_batch + 1]\n",
    "        mask_ax.imshow(mask.astype(int))\n",
    "        mask_ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if PLOT_RESULTS:\n",
    "    images = [grain_dicts[i][\"image\"] for i in grain_dicts]\n",
    "    masks = [grain_dicts[i][\"predicted_mask\"] for i in grain_dicts]\n",
    "    grain_indexes = [i for i in grain_dicts]\n",
    "    px_to_nms = [grain_dicts[i][\"p_to_nm\"] for i in grain_dicts]\n",
    "    plot_images(images, masks, grain_indexes, px_to_nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vet based on numbers of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ring_and_mask_exists(combined_predicted_mask: np.ndarray):\n",
    "    # Check if there is a ring and gem larger than n pixels in the predicted mask\n",
    "\n",
    "    min_ring_pixels = 40\n",
    "    min_gem_pixels = 40\n",
    "\n",
    "    ring_mask = combined_predicted_mask == 1\n",
    "    gem_mask = combined_predicted_mask == 2\n",
    "    if np.sum(ring_mask) < min_ring_pixels or np.sum(gem_mask) < min_gem_pixels:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def turn_small_gem_regions_into_ring(combined_predicted_mask: np.ndarray):\n",
    "    gem_mask = combined_predicted_mask == 2\n",
    "\n",
    "    # Find largest gem region\n",
    "    gem_labels = label(gem_mask)\n",
    "    gem_regions = regionprops(gem_labels)\n",
    "    gem_areas = [region.area for region in gem_regions]\n",
    "    largest_gem_region = gem_regions[np.argmax(gem_areas)]\n",
    "\n",
    "    # For all other regions, check if they touch a ring region\n",
    "    for region in gem_regions:\n",
    "        if region.label == largest_gem_region.label:\n",
    "            continue\n",
    "        # Get only the pixels in the region\n",
    "        region_mask = gem_labels == region.label\n",
    "        # Dilate the region\n",
    "        small_gem_dilation_strength = 5\n",
    "        dilated_region_mask = region_mask\n",
    "        for i in range(small_gem_dilation_strength):\n",
    "            dilated_region_mask = binary_dilation(dilated_region_mask)\n",
    "        # Get the intersection with the ring mask\n",
    "        intersection = dilated_region_mask & (combined_predicted_mask == 1)\n",
    "        # If there is any intersection, turn the region into a ring\n",
    "        if np.any(intersection):\n",
    "            combined_predicted_mask[dilated_region_mask] = 1\n",
    "\n",
    "    return combined_predicted_mask\n",
    "\n",
    "\n",
    "def remove_all_but_largest_ring_region(combined_predicted_mask: np.ndarray):\n",
    "    ring_mask = combined_predicted_mask == 1\n",
    "    # Find largest region\n",
    "    ring_labels = label(ring_mask)\n",
    "    ring_regions = regionprops(ring_labels)\n",
    "    ring_areas = [region.area for region in ring_regions]\n",
    "    largest_ring_region = ring_regions[np.argmax(ring_areas)]\n",
    "    # For all others, turn to background\n",
    "    for region in ring_regions:\n",
    "        if region.label == largest_ring_region.label:\n",
    "            continue\n",
    "        combined_predicted_mask[ring_labels == region.label] = 0\n",
    "\n",
    "    return combined_predicted_mask\n",
    "\n",
    "\n",
    "def get_number_of_connection_points(combined_predicted_mask: np.ndarray):\n",
    "    ring_mask = combined_predicted_mask == 1\n",
    "    gem_mask = combined_predicted_mask == 2\n",
    "    # Dilate the gem mask\n",
    "    gem_dilation_strength = 1\n",
    "    dilated_gem_mask = gem_mask\n",
    "    for i in range(gem_dilation_strength):\n",
    "        dilated_gem_mask = binary_dilation(dilated_gem_mask)\n",
    "    # Get the intersection with the ring mask\n",
    "    intersection = dilated_gem_mask & ring_mask\n",
    "\n",
    "    # Get number of separate intersection regions\n",
    "    intersection_labels = label(intersection)\n",
    "    intersection_regions = regionprops(intersection_labels)\n",
    "    num_connection_regions = len(intersection_regions)\n",
    "\n",
    "    return num_connection_regions, intersection_labels\n",
    "\n",
    "\n",
    "vetted_grain_dict = {}\n",
    "failed_indexes = []\n",
    "for index, grain_dict in grain_dicts.items():\n",
    "    image = grain_dict[\"image\"]\n",
    "    predicted_mask = grain_dict[\"predicted_mask\"]\n",
    "    p_to_nm = grain_dict[\"p_to_nm\"]\n",
    "\n",
    "    if not check_ring_and_mask_exists(predicted_mask):\n",
    "        failed_indexes.append(index)\n",
    "        continue\n",
    "\n",
    "    predicted_mask = turn_small_gem_regions_into_ring(predicted_mask)\n",
    "\n",
    "    predicted_mask = remove_all_but_largest_ring_region(predicted_mask)\n",
    "\n",
    "    num_connection_regions, intersection_labels = get_number_of_connection_points(predicted_mask)\n",
    "\n",
    "    if num_connection_regions != 2:\n",
    "        failed_indexes.append(index)\n",
    "        continue\n",
    "\n",
    "    vetted_grain_dict[index] = {\n",
    "        \"image\": image,\n",
    "        \"predicted_mask\": predicted_mask,\n",
    "        \"p_to_nm\": p_to_nm,\n",
    "        \"intersection_labels\": intersection_labels,\n",
    "    }\n",
    "\n",
    "print(f\"Number of vetted grains: {len(vetted_grain_dict)}\")\n",
    "\n",
    "if PLOT_RESULTS:\n",
    "    print(f\"Failed indexes: {failed_indexes}\")\n",
    "    failed_images = [grain_dicts[i][\"image\"] for i in failed_indexes]\n",
    "    failed_masks = [grain_dicts[i][\"predicted_mask\"] for i in failed_indexes]\n",
    "    failed_grain_indexes = [i for i in failed_indexes]\n",
    "    failed_px_to_nms = [grain_dicts[i][\"p_to_nm\"] for i in failed_indexes]\n",
    "    plot_images(failed_images, failed_masks, failed_grain_indexes, failed_px_to_nms)\n",
    "\n",
    "if PLOT_RESULTS:\n",
    "    images = [vetted_grain_dict[i][\"image\"] for i in vetted_grain_dict]\n",
    "    masks = [vetted_grain_dict[i][\"predicted_mask\"] for i in vetted_grain_dict]\n",
    "    grain_indexes = [i for i in vetted_grain_dict]\n",
    "    px_to_nms = [vetted_grain_dict[i][\"p_to_nm\"] for i in vetted_grain_dict]\n",
    "    plot_images(images, masks, grain_indexes, px_to_nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(IMAGE_SAVE_DIR / \"grain_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vetted_grain_dict, f)\n",
    "    print(f\"saved grain_dict.pkl to {IMAGE_SAVE_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-or-truck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
