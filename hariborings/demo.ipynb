{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from topostats.grain_finding_haribo_unet import predict_unet, predict_unet_multiclass, load_model, mean_iou, iou\n",
    "from topostats.plottingfuncs import Colormap\n",
    "\n",
    "colormap = Colormap()\n",
    "CMAP = colormap.get_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cas9 Bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_TYPE = \"ON_SC\"\n",
    "CAS9_DATA_DIR = Path(\n",
    "    f\"/Volumes/shared/pyne_group/Shared/AFM_Data/Cas9_Minicircles/Analysis_all/DNA_Cas9/output_justboundcas9/{SAMPLE_TYPE}/processed/\"\n",
    ")\n",
    "assert CAS9_DATA_DIR.exists()\n",
    "\n",
    "MODEL_PATH = Path(\n",
    "    f\"/Volumes/shared/pyne_group/Shared/AFM_Data/Cas9_Minicircles/deep_learning/saved_models/haribonet_multiclass_improved_norm_big_95_bridging_v1_2024-01-17_10-58-46.h5\"\n",
    ")\n",
    "assert MODEL_PATH.exists()\n",
    "# Load the model\n",
    "cas9_model = load_model(model_path=MODEL_PATH, custom_objects={\"mean_iou\": mean_iou})\n",
    "\n",
    "files = list(CAS9_DATA_DIR.glob(\"*.topostats\"))\n",
    "print(f\"Num images: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INDEX = 3\n",
    "file = files[IMAGE_INDEX]\n",
    "\n",
    "# Load the image via hdf5\n",
    "with h5py.File(file, \"r\") as f:\n",
    "    image = f[\"image\"][:]\n",
    "\n",
    "plt.imshow(image, cmap=CMAP)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the image\n",
    "crop_size = 150\n",
    "crop_x = 10\n",
    "crop_y = 260\n",
    "\n",
    "image_cropped = image[crop_y : crop_y + crop_size, crop_x : crop_x + crop_size]\n",
    "print(f\"max: {np.max(image_cropped)}, min: {np.min(image_cropped)}\")\n",
    "plt.imshow(image_cropped, cmap=CMAP, vmin=-1, vmax=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to segment the image with a height threshold\n",
    "threshold_start = 0.0\n",
    "threshold_end = 5.0\n",
    "threshold_step = 0.2\n",
    "\n",
    "thresholds = np.arange(threshold_start, threshold_end, threshold_step)\n",
    "thresholded_images = []\n",
    "for threshold in thresholds:\n",
    "    thresholded_image = image_cropped > threshold\n",
    "    thresholded_images.append(thresholded_image)\n",
    "\n",
    "# Plot the thresholded images\n",
    "cols = 5\n",
    "rows = len(thresholded_images) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(thresholded_images[i], cmap=\"gray\")\n",
    "    ax.set_title(f\"Threshold: {thresholds[i]:.2f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the mask\n",
    "mask = predict_unet_multiclass(\n",
    "    image=image_cropped,\n",
    "    model=cas9_model,\n",
    "    confidence=0.5,\n",
    "    model_image_size=256,\n",
    "    image_output_dir=None,\n",
    "    filename=None,\n",
    "    IMAGE_SAVE_DIR=None,\n",
    "    image_index=0,\n",
    ")\n",
    "\n",
    "plt.imshow(mask, cmap=\"inferno\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbound DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_TYPE = \"OT1_SC\"\n",
    "UNBOUND_DATA_DIR = Path(\n",
    "    f\"/Volumes/shared/pyne_group/Shared/AFM_Data/Cas9_Minicircles/Analysis_all/DNA_only/output_noCas9_reprocessed/output_noCas9/{SAMPLE_TYPE}/processed/processed/\"\n",
    ")\n",
    "assert UNBOUND_DATA_DIR.exists()\n",
    "\n",
    "UNBOUND_MODEL_PATH = Path(\n",
    "    f\"/Volumes/shared/pyne_group/Shared/AFM_Data/Cas9_Minicircles/deep_learning/saved_models/haribonet_dna_only_single_class_extra_doritos_2024-02-26_23-51-29_image-size-256x256_epochs-45_batch-size-25_learning-rate-0.001.h5\"\n",
    ")\n",
    "assert UNBOUND_MODEL_PATH.exists()\n",
    "# Load the model\n",
    "unbound_model = load_model(model_path=UNBOUND_MODEL_PATH, custom_objects={\"iou\": iou})\n",
    "\n",
    "unbound_files = list(UNBOUND_DATA_DIR.glob(\"*.topostats\"))\n",
    "print(f\"Num images: {len(unbound_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for UNBOUND_IMAGE_INDEX in range(35, 54):\n",
    "#     unbound_file = unbound_files[UNBOUND_IMAGE_INDEX]\n",
    "\n",
    "#     # Load the image via hdf5\n",
    "#     with h5py.File(unbound_file, \"r\") as f:\n",
    "#         unbound_image = f[\"image\"][:]\n",
    "\n",
    "#     plt.imshow(unbound_image, cmap=CMAP, vmin=-3, vmax=4)\n",
    "#     plt.title(f\"Image index: {UNBOUND_IMAGE_INDEX}\")\n",
    "#     plt.show()\n",
    "\n",
    "UNBOUND_IMAGE_INDEX = 48\n",
    "unbound_file = unbound_files[UNBOUND_IMAGE_INDEX]\n",
    "\n",
    "# Load the image via hdf5\n",
    "with h5py.File(unbound_file, \"r\") as f:\n",
    "    unbound_image = f[\"image\"][:]\n",
    "\n",
    "plt.imshow(unbound_image, cmap=CMAP, vmin=-3, vmax=4)\n",
    "plt.show()\n",
    "\n",
    "# Images of interest:\n",
    "# ON_SC: 68: good zoom in with gap\n",
    "# OT1_SC: 7: good close edges of dna\n",
    "# OT1_SC: 48: good close images with helix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the image\n",
    "unbound_crop_size = 130\n",
    "unbound_crop_x = 190\n",
    "unbound_crop_y = 160\n",
    "\n",
    "unbound_image_cropped = unbound_image[\n",
    "    unbound_crop_y : unbound_crop_y + unbound_crop_size, unbound_crop_x : unbound_crop_x + unbound_crop_size\n",
    "]\n",
    "plt.imshow(unbound_image_cropped, cmap=CMAP, vmin=None, vmax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to segment the image with a height threshold\n",
    "threshold_start = 0.0\n",
    "threshold_end = 3.0\n",
    "threshold_step = 0.2\n",
    "\n",
    "thresholds = np.arange(threshold_start, threshold_end, threshold_step)\n",
    "thresholded_images = []\n",
    "for threshold in thresholds:\n",
    "    thresholded_image = unbound_image_cropped > threshold\n",
    "    thresholded_images.append(thresholded_image)\n",
    "\n",
    "# Plot the thresholded images\n",
    "cols = 5\n",
    "rows = len(thresholded_images) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(thresholded_images[i], cmap=\"gray\")\n",
    "    ax.set_title(f\"Threshold: {thresholds[i]:.2f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the mask\n",
    "unbound_mask = predict_unet(\n",
    "    image=unbound_image_cropped,\n",
    "    model=unbound_model,\n",
    "    model_image_size=256,\n",
    "    confidence=0.5,\n",
    "    image_output_dir=None,\n",
    "    filename=None,\n",
    "    normalisation_set_range=[None, None],\n",
    ")\n",
    "\n",
    "plt.imshow(unbound_mask, cmap=\"inferno\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
