{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "\n",
    "from topostats.plottingfuncs import Colormap\n",
    "\n",
    "colormap = Colormap()\n",
    "cmap = colormap.get_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    image: np.ndarray, title: str = None, vmin: float = -8, vmax: float = 8, cmap=cmap, figsize=(10, 10), cbar=False\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    im = ax.imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    if cbar:\n",
    "        fig.colorbar(im, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PX_TO_NM = 0.59\n",
    "BBOX_PAD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images: list, masks: list, px_to_nms: list, grain_indexes: list, width=5, cmap=cmap, vmin=-8, vmax=8):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 3, figsize=(30, 30))\n",
    "    for i, (image, mask, grain_index) in enumerate(zip(images, masks, grain_indexes)):\n",
    "        ax[i // width, i % width * 3].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width * 3].axis(\"off\")\n",
    "        ax[i // width, i % width * 3 + 1].imshow(mask, cmap=\"binary\")\n",
    "        ax[i // width, i % width * 3].set_title(f\"grain: {grain_index} p_to_nm: {px_to_nms[i]}\")\n",
    "        ax[i // width, i % width * 3 + 2].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width * 3 + 2].imshow(mask, cmap=\"viridis\", alpha=0.2)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "SAMPLE_TYPE = \"OT1_REL\"\n",
    "on_rel = Path(f\"/Users/sylvi/topo_data/hariborings/testing_all_unbound_data/output_{SAMPLE_TYPE}/processed/\")\n",
    "SAVE_DIR = Path(f\"/Users/sylvi/topo_data/hariborings/processed_grains/unbound_{SAMPLE_TYPE}/date_{today}\")\n",
    "SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "assert SAVE_DIR.exists()\n",
    "assert on_rel.exists()\n",
    "# Grab all .topostats files\n",
    "on_files = list(on_rel.glob(\"*.topostats\"))\n",
    "\n",
    "# file = on_files[1]\n",
    "\n",
    "grains_processed = 0\n",
    "stop_at_grain = 200\n",
    "plotting = False\n",
    "\n",
    "grain_dict = {}\n",
    "\n",
    "for file in on_files:\n",
    "    print(file)\n",
    "    # Load file\n",
    "    with h5py.File(file, \"r\") as f:\n",
    "        print(f.keys())\n",
    "        image = f[\"image\"][:]\n",
    "        grain_masks = f[\"grain_masks\"][\"above\"][:]\n",
    "        p_to_nm = f[\"pixel_to_nm_scaling\"][()]\n",
    "\n",
    "    if p_to_nm > MAX_PX_TO_NM:\n",
    "        continue\n",
    "\n",
    "    # Plot image and mask side by side\n",
    "    if plotting:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        ax[0].imshow(image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        ax[0].set_title(\"image\")\n",
    "        ax[1].imshow(grain_masks, cmap=\"gray\")\n",
    "        ax[1].set_title(\"grain_masks\")\n",
    "        plt.suptitle(f\"pixel to nm scaling: {p_to_nm}\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Process the grains\n",
    "    for grain in range(1, grain_masks.max() + 1):\n",
    "        if grains_processed == stop_at_grain:\n",
    "            break\n",
    "        # Get the bounding box of the grain\n",
    "        grain_mask_fullsize = grain_masks == grain\n",
    "        grain_bbox = np.argwhere(grain_mask_fullsize)\n",
    "        minr, minc = grain_bbox.min(axis=0)\n",
    "        maxr, maxc = grain_bbox.max(axis=0)\n",
    "        # Add padding to the bounding box\n",
    "        minr = max(0, minr - BBOX_PAD)\n",
    "        minc = max(0, minc - BBOX_PAD)\n",
    "        maxr = min(grain_mask_fullsize.shape[0], maxr + BBOX_PAD)\n",
    "        maxc = min(grain_mask_fullsize.shape[1], maxc + BBOX_PAD)\n",
    "\n",
    "        # Get the crop of grain image\n",
    "        grain_image = image[minr:maxr, minc:maxc]\n",
    "        grain_mask = grain_mask_fullsize[minr:maxr, minc:maxc]\n",
    "\n",
    "        if plotting:\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "            ax[0].imshow(grain_mask, cmap=\"gray\")\n",
    "            ax[0].set_title(\"grain mask\")\n",
    "            ax[1].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "            ax[1].set_title(\"grain image\")\n",
    "            ax[2].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "            ax[2].imshow(grain_mask, cmap=\"gray\", alpha=0.2)\n",
    "            plt.show()\n",
    "\n",
    "        grain_dict[grains_processed] = {\n",
    "            \"image\": grain_image,\n",
    "            \"mask\": grain_mask,\n",
    "            \"p_to_nm\": p_to_nm,\n",
    "        }\n",
    "\n",
    "        grains_processed += 1\n",
    "\n",
    "    if grains_processed == stop_at_grain:\n",
    "        break\n",
    "\n",
    "# Plot the grains\n",
    "images = [grain_dict[i][\"image\"] for i in range(grains_processed)]\n",
    "masks = [grain_dict[i][\"mask\"] for i in range(grains_processed)]\n",
    "px_to_nms = [grain_dict[i][\"p_to_nm\"] for i in range(grains_processed)]\n",
    "grain_indexes = list(range(grains_processed))\n",
    "plot_images(\n",
    "    images,\n",
    "    masks,\n",
    "    px_to_nms,\n",
    "    grain_indexes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the masks\n",
    "from skimage.morphology import binary_dilation, binary_erosion\n",
    "\n",
    "DILATION_PASS = 2\n",
    "ERODE_PASS = 2\n",
    "\n",
    "dilated_grain_dict = {}\n",
    "\n",
    "for index, grain_data in grain_dict.items():\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "\n",
    "    # Dilation\n",
    "    for _ in range(DILATION_PASS):\n",
    "        grain_mask = binary_dilation(grain_mask)\n",
    "    # Erosion\n",
    "    for _ in range(ERODE_PASS):\n",
    "        grain_mask = binary_erosion(grain_mask)\n",
    "\n",
    "    dilated_grain_dict[index] = {\n",
    "        \"image\": grain_image,\n",
    "        \"mask\": grain_mask,\n",
    "        \"p_to_nm\": p_to_nm,\n",
    "    }\n",
    "\n",
    "plot_images(\n",
    "    [dilated_grain_dict[i][\"image\"] for i in range(grains_processed)],\n",
    "    [dilated_grain_dict[i][\"mask\"] for i in range(grains_processed)],\n",
    "    [dilated_grain_dict[i][\"p_to_nm\"] for i in range(grains_processed)],\n",
    "    [i for i in range(grains_processed)],\n",
    ")\n",
    "\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "LOWER_AREA_BOUND = 100\n",
    "UPPER_AREA_BOUND = 10000\n",
    "\n",
    "removed_anomaly_grain_dict = {}\n",
    "for index, grain_data in dilated_grain_dict.items():\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "\n",
    "    # Label the grains\n",
    "    labelled_background = label(grain_mask == 0)\n",
    "    background_props = regionprops(labelled_background)\n",
    "\n",
    "    if len(background_props) < 2:\n",
    "        print(f\"Grain {index} has too few background regions\")\n",
    "        # plt.imshow(labelled_background)\n",
    "        # print(len(background_props))\n",
    "        # plt.show()\n",
    "    elif len(background_props) >= 3:\n",
    "        print(f\"Grain {index} has too many background regions\")\n",
    "        # plt.imshow(labelled_background)\n",
    "        # print(len(background_props))\n",
    "        # plt.show()\n",
    "    else:\n",
    "        # Check the size of the foreground\n",
    "        foreground_area = grain_mask.sum()\n",
    "        if foreground_area < LOWER_AREA_BOUND:\n",
    "            print(f\"Grain {index} has too small foreground area\")\n",
    "        elif foreground_area > UPPER_AREA_BOUND:\n",
    "            print(f\"Grain {index} has too large foreground area\")\n",
    "        else:\n",
    "            removed_anomaly_grain_dict[index] = grain_data\n",
    "\n",
    "plot_images(\n",
    "    [removed_anomaly_grain_dict[i][\"image\"] for i in removed_anomaly_grain_dict],\n",
    "    [removed_anomaly_grain_dict[i][\"mask\"] for i in removed_anomaly_grain_dict],\n",
    "    [removed_anomaly_grain_dict[i][\"p_to_nm\"] for i in removed_anomaly_grain_dict],\n",
    "    [i for i in removed_anomaly_grain_dict],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeletonise using standard skeletonise\n",
    "from skimage.morphology import skeletonize\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "\n",
    "def plot_images(images: list, masks: list, px_to_nms: list, skeletons: list, width=5, cmap=cmap, vmin=-8, vmax=8):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 3, figsize=(30, 30))\n",
    "    for i, (image, mask, skeleton) in enumerate(zip(images, masks, skeletons)):\n",
    "        ax[i // width, i % width * 3].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width * 3].axis(\"off\")\n",
    "        ax[i // width, i % width * 3 + 1].imshow(skeleton, cmap=\"binary\")\n",
    "        ax[i // width, i % width * 3].set_title(f\"p_to_nm: {px_to_nms[i]}\")\n",
    "        ax[i // width, i % width * 3 + 2].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width * 3 + 2].imshow(skeleton, cmap=\"viridis\", alpha=0.2)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convolve_skelly(skeleton) -> np.ndarray:\n",
    "    \"\"\"Convolves the skeleton with a 3x3 ones kernel to produce an array\n",
    "    of the skeleton as 1, endpoints as 2, and nodes as 3.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    skeleton: np.ndarray\n",
    "        Single pixel thick binary trace(s) within an array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The skeleton (=1) with endpoints (=2), and crossings (=3) highlighted.\n",
    "    \"\"\"\n",
    "    conv = convolve(skeleton.astype(np.int32), np.ones((3, 3)))\n",
    "    conv[skeleton == 0] = 0  # remove non-skeleton points\n",
    "    conv[conv == 3] = 1  # skelly = 1\n",
    "    conv[conv > 3] = 3  # nodes = 3\n",
    "    return conv\n",
    "\n",
    "\n",
    "plotting = False\n",
    "paths_grain_dict = {}\n",
    "# Method for finding the optimal path in the molecule mask\n",
    "# Options: skeletonize, distance transform, height\n",
    "path_method = \"distance transform\"\n",
    "\n",
    "for index, grain_data in removed_anomaly_grain_dict.items():\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "\n",
    "    # Skeletonise\n",
    "    skeleton = skeletonize(grain_mask)\n",
    "\n",
    "    if plotting:\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        ax[0].imshow(grain_mask, cmap=\"gray\")\n",
    "        ax[0].set_title(\"grain mask\")\n",
    "        ax[1].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        ax[1].set_title(\"grain image\")\n",
    "        ax[2].imshow(skeleton, cmap=\"gray\")\n",
    "        ax[2].set_title(\"skeleton\")\n",
    "        ax[3].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        ax[3].imshow(skeleton, cmap=\"viridis\", alpha=0.2)\n",
    "        plt.show()\n",
    "\n",
    "    # Ignore any grains that have a branch, ie a pixel with more than 2 neighbours\n",
    "    convolved_skelly = convolve_skelly(skeleton)\n",
    "\n",
    "    if np.max(convolved_skelly) > 1:\n",
    "        print(f\"Grain {index} has a branch\")\n",
    "        continue\n",
    "\n",
    "    paths_grain_dict[index] = {\n",
    "        \"image\": grain_image,\n",
    "        \"mask\": grain_mask,\n",
    "        \"skeleton\": skeleton,\n",
    "        \"p_to_nm\": p_to_nm,\n",
    "    }\n",
    "\n",
    "plot_images(\n",
    "    [paths_grain_dict[i][\"image\"] for i in paths_grain_dict],\n",
    "    [paths_grain_dict[i][\"mask\"] for i in paths_grain_dict],\n",
    "    [paths_grain_dict[i][\"p_to_nm\"] for i in paths_grain_dict],\n",
    "    [paths_grain_dict[i][\"skeleton\"] for i in paths_grain_dict],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace the skeleton\n",
    "\n",
    "\n",
    "def plot_images(\n",
    "    images: list, masks: list, px_to_nms: list, skeletons: list, traces: list, width=5, cmap=cmap, vmin=-8, vmax=8\n",
    "):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 3, figsize=(30, 30))\n",
    "    for i, (image, mask, skeleton) in enumerate(zip(images, masks, skeletons)):\n",
    "        ax[i // width, i % width * 3].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width * 3].axis(\"off\")\n",
    "        ax[i // width, i % width * 3 + 1].imshow(skeleton, cmap=\"binary\")\n",
    "        ax[i // width, i % width * 3].set_title(f\"p_to_nm: {px_to_nms[i]}\")\n",
    "        ax[i // width, i % width * 3 + 2].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width * 3 + 2].imshow(skeleton, cmap=\"viridis\", alpha=0.2)\n",
    "        ax[i // width, i % width * 3 + 2].plot(traces[i][:, 1], traces[i][:, 0], \"r\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotting = False\n",
    "trace_grain_dict = {}\n",
    "\n",
    "for index, grain_data in paths_grain_dict.items():\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    skeleton = grain_data[\"skeleton\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "\n",
    "    # Trace the skeleton\n",
    "    skeleton_points = np.argwhere(skeleton)\n",
    "    # Find the start point\n",
    "    start_point = skeleton_points[0]\n",
    "    # Each point should not have more than 2 neighbours so we can trace by finding the next point\n",
    "    # and removing the current point from the skeleton\n",
    "\n",
    "    skeleton_history = skeleton.copy()\n",
    "    trace = [start_point]\n",
    "    current_point = start_point\n",
    "    skeleton_history[current_point[0], current_point[1]] = 0\n",
    "\n",
    "    # print(f\"len of skeleton points: {len(skeleton_points)}\")\n",
    "    for iteration in range(len(skeleton_points) - 1):\n",
    "        neighbourhood = skeleton_history[\n",
    "            current_point[0] - 1 : current_point[0] + 2, current_point[1] - 1 : current_point[1] + 2\n",
    "        ]\n",
    "        if iteration > 0 and np.sum(neighbourhood) > 1:\n",
    "            raise ValueError(f\"More than 1 neighbour for iteration {iteration}\")\n",
    "        if np.sum(neighbourhood) == 0:\n",
    "            raise ValueError(f\"No neighbours for iteration {iteration}\")\n",
    "        next_point = np.argwhere(neighbourhood)[0]\n",
    "        next_point_coords = current_point + next_point - 1\n",
    "        trace.append(next_point_coords)\n",
    "        current_point = next_point_coords\n",
    "        skeleton_history[current_point[0], current_point[1]] = 0\n",
    "    trace = np.array(trace)\n",
    "\n",
    "    ordered_skeleton = np.zeros_like(skeleton).astype(int)\n",
    "    for point_index, point in enumerate(trace):\n",
    "        ordered_skeleton[point[0], point[1]] = point_index + 20\n",
    "\n",
    "    if plotting:\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "        ax[0].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        ax[0].set_title(\"grain image\")\n",
    "        ax[1].imshow(ordered_skeleton, cmap=\"viridis\")\n",
    "        ax[1].set_title(\"ordered skeleton\")\n",
    "        ax[2].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        ax[2].imshow(ordered_skeleton, cmap=\"viridis\", alpha=0.2)\n",
    "        ax[2].plot(trace[:, 1], trace[:, 0], \"r\")\n",
    "        plt.show()\n",
    "\n",
    "    # Calculate pixel trace length in nm\n",
    "    pixel_trace_length = np.sum(np.linalg.norm(np.diff(trace, axis=0), axis=1)) * p_to_nm\n",
    "\n",
    "    trace_grain_dict[index] = {\n",
    "        \"image\": grain_image,\n",
    "        \"mask\": grain_mask,\n",
    "        \"skeleton\": ordered_skeleton,\n",
    "        \"trace\": trace,\n",
    "        \"p_to_nm\": p_to_nm,\n",
    "        \"pixel_trace_length\": pixel_trace_length,\n",
    "    }\n",
    "\n",
    "\n",
    "plot_images(\n",
    "    [trace_grain_dict[i][\"image\"] for i in trace_grain_dict],\n",
    "    [trace_grain_dict[i][\"mask\"] for i in trace_grain_dict],\n",
    "    [trace_grain_dict[i][\"p_to_nm\"] for i in trace_grain_dict],\n",
    "    [trace_grain_dict[i][\"skeleton\"] for i in trace_grain_dict],\n",
    "    [trace_grain_dict[i][\"trace\"] for i in trace_grain_dict],\n",
    ")\n",
    "\n",
    "# Plot kde of trace lengths\n",
    "import seaborn as sns\n",
    "\n",
    "trace_lengths = [trace_grain_dict[i][\"pixel_trace_length\"] for i in trace_grain_dict]\n",
    "sns.kdeplot(trace_lengths)\n",
    "plt.xlim(0, 60)\n",
    "plt.xlabel(\"Trace length (nm)\")\n",
    "plt.title(f\"Length of pixel traces in nm for {len(trace_lengths)} grains\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_polygon(polygon: np.ndarray, point: np.ndarray) -> bool:\n",
    "    \"\"\"Check if a point is in a polygon using the ray casting algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    polygon: np.ndarray\n",
    "        The polygon to check if the point is in.\n",
    "    point: np.ndarray\n",
    "        The point to check if it is in the polygon.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if the point is in the polygon, False otherwise.\n",
    "    \"\"\"\n",
    "    x, y = point\n",
    "    n = len(polygon)\n",
    "    inside = False\n",
    "    p1x, p1y = polygon[0]\n",
    "    for i in range(n + 1):\n",
    "        p2x, p2y = polygon[i % n]\n",
    "        if y > min(p1y, p2y):\n",
    "            if y <= max(p1y, p2y):\n",
    "                if x <= max(p1x, p2x):\n",
    "                    if p1y != p2y:\n",
    "                        xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x\n",
    "                    if p1x == p2x or x <= xinters:\n",
    "                        inside = not inside\n",
    "        p1x, p1y = p2x, p2y\n",
    "    return inside\n",
    "\n",
    "\n",
    "def fill_polygon(array: np.ndarray, polygon: np.ndarray, fill_value: float):\n",
    "    \"\"\"Fills a polygon within an array with a fill value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        The array to fill the polygon within.\n",
    "    polygon: np.ndarray\n",
    "        The polygon to fill within the array.\n",
    "    fill_value: float\n",
    "        The value to fill the polygon with.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The array with the polygon filled.\n",
    "    \"\"\"\n",
    "    minx, miny = np.min(polygon, axis=0)\n",
    "    maxx, maxy = np.max(polygon, axis=0)\n",
    "    for y in range(miny, maxy + 1):\n",
    "        for x in range(minx, maxx + 1):\n",
    "            if is_in_polygon(polygon, np.array([x, y])):\n",
    "                array[y, x] = fill_value\n",
    "    return array\n",
    "\n",
    "\n",
    "# # Test the polygon filling\n",
    "# polygon = np.array([[0, 10], [3, 25], [28, 15], [10, 0]])\n",
    "# array = np.zeros((30, 30))\n",
    "# filled_array = fill_polygon(array, polygon, 1)\n",
    "# plt.imshow(filled_array)\n",
    "# plt.plot(np.append(polygon[:, 0], polygon[0, 0]), np.append(polygon[:, 1], polygon[0, 1]), \"r\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Improve the tracing using pathfinding\n",
    "# from scipy.ndimage import distance_transform_edt\n",
    "# from skimage.graph import route_through_array\n",
    "\n",
    "# # Options: height, distance_transform\n",
    "# method = \"distance_transform\"\n",
    "\n",
    "# plotting = True\n",
    "# improved_path_grain_dict = {}\n",
    "\n",
    "# for index, grain_data in trace_grain_dict.items():\n",
    "#     grain_image = grain_data[\"image\"]\n",
    "#     grain_mask = grain_data[\"mask\"]\n",
    "#     skeleton = grain_data[\"skeleton\"]\n",
    "#     trace = grain_data[\"trace\"]\n",
    "#     p_to_nm = grain_data[\"p_to_nm\"]\n",
    "\n",
    "#     if method == \"distance_transform\":\n",
    "#         # Get the distance transform of the grain mask\n",
    "#         distance_transform = distance_transform_edt(grain_mask)\n",
    "#         # Invert the distance transform\n",
    "#         distance_transform_inverted_show = np.max(distance_transform) - distance_transform\n",
    "#         distance_transform_inverted = np.max(distance_transform) - distance_transform\n",
    "#         # Find the minimum value pixel in the inverted distance transform\n",
    "#         min_point = np.unravel_index(np.argmin(distance_transform_inverted), distance_transform_inverted.shape)\n",
    "\n",
    "#         # Closest trace point to the minimum value pixel\n",
    "#         p0_index = np.argmin(np.linalg.norm(trace - min_point, axis=1))\n",
    "#         p0 = trace[p0_index]\n",
    "\n",
    "#         # Get the next point\n",
    "#         if p0_index == len(trace) - 1:\n",
    "#             p1 = trace[0]\n",
    "#         else:\n",
    "#             p1 = trace[p0_index + 1]\n",
    "\n",
    "#         v1 = p1 - p0\n",
    "#         v2 = np.array([v1[1], -v1[0]])\n",
    "\n",
    "#         # Find the rectangle points to fill in\n",
    "#         # Follow the vector v2 from p0 until the grain mask stops being 1\n",
    "\n",
    "#         # Get r0\n",
    "#         grain_mask_intersecting = True\n",
    "#         r00 = p0\n",
    "#         while grain_mask_intersecting:\n",
    "#             r00 = r00 + v2\n",
    "#             if grain_mask[int(r00[0]), int(r00[1])] == 0:\n",
    "#                 grain_mask_intersecting = False\n",
    "#         grain_mask_intersecting = True\n",
    "#         r01 = p0\n",
    "#         while grain_mask_intersecting:\n",
    "#             r01 = r01 - v2\n",
    "#             if grain_mask[int(r01[0]), int(r01[1])] == 0:\n",
    "#                 grain_mask_intersecting = False\n",
    "#         grain_mask_intersecting = True\n",
    "#         r10 = p1\n",
    "#         while grain_mask_intersecting:\n",
    "#             r10 = r10 + v2\n",
    "#             if grain_mask[int(r10[0]), int(r10[1])] == 0:\n",
    "#                 grain_mask_intersecting = False\n",
    "#         grain_mask_intersecting = True\n",
    "#         r11 = p1\n",
    "#         while grain_mask_intersecting:\n",
    "#             r11 = r11 - v2\n",
    "#             if grain_mask[int(r11[0]), int(r11[1])] == 0:\n",
    "#                 grain_mask_intersecting = False\n",
    "\n",
    "#         # Fill in the rectangle\n",
    "#         polygon = np.array([r00, r01, r11, r10])\n",
    "#         # Flip x and y in polygon\n",
    "#         polygon = np.array([polygon[:, 1], polygon[:, 0]]).T\n",
    "#         filled_array = fill_polygon(distance_transform_inverted, polygon, np.max(distance_transform_inverted))\n",
    "#         filled_array_show = fill_polygon(\n",
    "#             distance_transform_inverted_show, polygon, np.max(distance_transform_inverted_show)\n",
    "#         )\n",
    "\n",
    "#         # Find the points in the distance transform that should be set to really high\n",
    "#         # to prevent pathfinding through the grain\n",
    "#         # plt.imshow(filled_array)\n",
    "#         # plt.colorbar()\n",
    "#         # plt.show()\n",
    "\n",
    "#         filled_array[filled_array == np.max(filled_array)] = 1000\n",
    "\n",
    "#         # plt.imshow(filled_array)\n",
    "#         # plt.colorbar()\n",
    "#         # plt.show()\n",
    "\n",
    "#         # Get the targets for pathfinding, one skeleton point ahead of p1 and one skeleton point behind p0\n",
    "#         t0_index = p0_index - 1\n",
    "#         t0 = trace[t0_index]\n",
    "#         # Ensure the index is within the trace\n",
    "#         if p0_index + 2 >= len(trace):\n",
    "#             t1_index = p0_index + 2 - len(trace)\n",
    "#         else:\n",
    "#             t1_index = p0_index + 2\n",
    "#         t1 = trace[t1_index]\n",
    "\n",
    "#         # Now pathfind between t0 and t1 using the inverted distance transform\n",
    "#         improved_path, cost = route_through_array(filled_array, t0, t1)\n",
    "\n",
    "#         improved_path = np.array(improved_path)\n",
    "\n",
    "#         # Create a visualisation of the improved path\n",
    "#         improved_path_array = np.zeros_like(distance_transform_inverted)\n",
    "#         for point in improved_path:\n",
    "#             improved_path_array[point[0], point[1]] = 1\n",
    "\n",
    "#         if plotting:\n",
    "#             fig, ax = plt.subplots(1, 7, figsize=(30, 10))\n",
    "#             ax[0].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "#             ax[0].set_title(\"grain image\")\n",
    "#             ax[1].imshow(grain_mask, cmap=\"gray\")\n",
    "#             ax[1].set_title(\"grain mask\")\n",
    "#             ax[2].imshow(distance_transform_inverted_show, cmap=cmap)\n",
    "#             ax[2].scatter(min_point[1], min_point[0], c=\"r\", s=10)\n",
    "#             ax[2].set_title(\"distance transform\")\n",
    "#             ax[3].imshow(skeleton, cmap=\"gray\")\n",
    "#             ax[3].plot([p0[1], p1[1]], [p0[0], p1[0]], \"r\")\n",
    "#             ax[3].plot([r00[1], r01[1], r11[1], r10[1], r00[1]], [r00[0], r01[0], r11[0], r10[0], r00[0]], \"r\")\n",
    "#             ax[3].scatter(t0[1], t0[0], c=\"g\", s=10)\n",
    "#             ax[3].scatter(t1[1], t1[0], c=\"b\", s=10)\n",
    "#             ax[3].set_title(\"traced skeleton\")\n",
    "#             ax[4].imshow(grain_mask, cmap=\"gray\")\n",
    "#             ax[4].imshow(improved_path_array, cmap=\"viridis\", alpha=0.2)\n",
    "#             ax[4].plot(improved_path[:, 1], improved_path[:, 0], \"r\")\n",
    "#             ax[4].set_title(\"improved path\")\n",
    "#             ax[5].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "#             ax[5].plot(improved_path[:, 1], improved_path[:, 0], \"r\")\n",
    "#             ax[5].set_title(\"distance transform trace\")\n",
    "#             ax[6].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "#             ax[6].plot(trace[:, 1], trace[:, 0], \"r\")\n",
    "#             ax[6].set_title(\"skeleton trace\")\n",
    "#             plt.show()\n",
    "\n",
    "#     if index > 50:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get height traces from the skeletons\n",
    "\n",
    "\n",
    "def plot_images(\n",
    "    images: list, masks: list, px_to_nms: list, traces: list, height_traces: list, width=5, cmap=cmap, vmin=-8, vmax=8\n",
    "):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 3, figsize=(30, 30))\n",
    "    for i, (image, mask, height_trace) in enumerate(zip(images, masks, height_traces)):\n",
    "        ax[i // width, i % width * 3].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width * 3].axis(\"off\")\n",
    "        ax[i // width, i % width * 3].set_title(f\"p_to_nm: {px_to_nms[i]:.2f}\")\n",
    "        ax[i // width, i % width * 3 + 1].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width * 3 + 1].plot(traces[i][:, 1], traces[i][:, 0], \"r\")\n",
    "        ax[i // width, i % width * 3 + 2].plot(height_trace)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotting = False\n",
    "height_trace_grain_dict = {}\n",
    "\n",
    "\n",
    "for index, grain_data in trace_grain_dict.items():\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "    trace = grain_data[\"trace\"]\n",
    "\n",
    "    # Get the height trace\n",
    "    height_trace = grain_image[trace[:, 0], trace[:, 1]]\n",
    "\n",
    "    if plotting:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(40, 10))\n",
    "        ax[0].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        colours = np.linspace(0, 1, len(trace))\n",
    "        for i in range(len(height_trace) - 1):\n",
    "            ax[0].plot(trace[i : i + 2, 1], trace[i : i + 2, 0], color=plt.cm.viridis(colours[i]))\n",
    "        ax[0].set_title(\"grain image\")\n",
    "        colours = np.linspace(0, 1, len(height_trace))\n",
    "        xs = np.arange(len(height_trace))\n",
    "        for i in range(len(height_trace) - 1):\n",
    "            # Include +2 to get the next point since python slicing is exclusive\n",
    "            ax[1].plot(xs[i : i + 2], height_trace[i : i + 2], color=plt.cm.viridis(colours[i]))\n",
    "        ax[1].set_ylim(1, 3.5)\n",
    "        plt.show()\n",
    "\n",
    "    height_trace_grain_dict[index] = {\n",
    "        \"image\": grain_image,\n",
    "        \"mask\": grain_mask,\n",
    "        \"trace\": trace,\n",
    "        \"height_trace\": height_trace,\n",
    "        \"p_to_nm\": p_to_nm,\n",
    "    }\n",
    "\n",
    "plot_images(\n",
    "    [height_trace_grain_dict[i][\"image\"] for i in height_trace_grain_dict],\n",
    "    [height_trace_grain_dict[i][\"mask\"] for i in height_trace_grain_dict],\n",
    "    [height_trace_grain_dict[i][\"p_to_nm\"] for i in height_trace_grain_dict],\n",
    "    [height_trace_grain_dict[i][\"trace\"] for i in height_trace_grain_dict],\n",
    "    [height_trace_grain_dict[i][\"height_trace\"] for i in height_trace_grain_dict],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each trace, pool sets of n pixels\n",
    "\n",
    "\n",
    "def plot_images(\n",
    "    images: list, original_traces: list, pooled_traces: list, px_to_nms: list, width=5, cmap=cmap, vmin=-8, vmax=8\n",
    "):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width, figsize=(20, 50))\n",
    "    for i, (image, original_trace, pooled_trace) in enumerate(zip(images, original_traces, pooled_traces)):\n",
    "        ax[i // width, i % width].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width].plot(original_trace[:, 1], original_trace[:, 0], \"r\")\n",
    "        ax[i // width, i % width].plot(pooled_trace[:, 1], pooled_trace[:, 0], \"b\")\n",
    "        ax[i // width, i % width].axis(\"off\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotting = False\n",
    "\n",
    "pooled_curvature_grain_dict = {}\n",
    "\n",
    "# Binning size\n",
    "n = 6\n",
    "\n",
    "for index, grain_data in height_trace_grain_dict.items():\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "    trace = grain_data[\"trace\"]\n",
    "    height_trace = grain_data[\"height_trace\"]\n",
    "\n",
    "    # Pool the trace points\n",
    "    pooled_trace = []\n",
    "\n",
    "    for i in range(len(trace)):\n",
    "        binned_points = []\n",
    "        for j in range(n):\n",
    "            if i + j < len(trace):\n",
    "                binned_points.append(trace[i + j])\n",
    "            else:\n",
    "                # If the index is out of range, sample from the start\n",
    "                binned_points.append(trace[i + j - len(trace)])\n",
    "\n",
    "        # Get the mean of the binned points\n",
    "        pooled_trace.append(np.mean(binned_points, axis=0))\n",
    "\n",
    "    pooled_trace = np.array(pooled_trace)\n",
    "\n",
    "    if plotting:\n",
    "        # Plot overlaid on image\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "        ax.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        ax.plot(trace[:, 1], trace[:, 0], \"r\")\n",
    "        ax.plot(pooled_trace[:, 1], pooled_trace[:, 0], \"b\")\n",
    "        ax.set_title(\"Trace and pooled trace\")\n",
    "\n",
    "    pooled_curvature_grain_dict[index] = {\n",
    "        \"image\": grain_image,\n",
    "        \"mask\": grain_mask,\n",
    "        \"trace\": trace,\n",
    "        \"pooled_trace\": pooled_trace,\n",
    "        \"height_trace\": height_trace,\n",
    "        \"p_to_nm\": p_to_nm,\n",
    "    }\n",
    "\n",
    "plot_images(\n",
    "    [pooled_curvature_grain_dict[i][\"image\"] for i in pooled_curvature_grain_dict],\n",
    "    [pooled_curvature_grain_dict[i][\"trace\"] for i in pooled_curvature_grain_dict],\n",
    "    [pooled_curvature_grain_dict[i][\"pooled_trace\"] for i in pooled_curvature_grain_dict],\n",
    "    [pooled_curvature_grain_dict[i][\"p_to_nm\"] for i in pooled_curvature_grain_dict],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_erosion\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "\n",
    "\n",
    "def calculate_edges(grain_mask: np.ndarray):\n",
    "    \"\"\"Class method that takes a 2D boolean numpy array image of a grain and returns a python list of the\n",
    "    coordinates of the edges of the grain.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    grain_mask : np.ndarray\n",
    "        A 2D numpy array image of a grain. Data in the array must be boolean.\n",
    "    edge_detection_method : str\n",
    "        Method used for detecting the edges of grain masks before calculating statistics on them.\n",
    "        Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    edges : list\n",
    "        List containing the coordinates of the edges of the grain.\n",
    "    \"\"\"\n",
    "    # Fill any holes\n",
    "    filled_grain_mask = binary_fill_holes(grain_mask)\n",
    "\n",
    "    # Add padding (needed for erosion)\n",
    "    padded = np.pad(filled_grain_mask, 1)\n",
    "    # Erode by 1 pixel\n",
    "    eroded = binary_erosion(padded)\n",
    "    # Remove padding\n",
    "    eroded = eroded[1:-1, 1:-1]\n",
    "\n",
    "    # Edges is equal to the difference between the\n",
    "    # original image and the eroded image.\n",
    "    edges = filled_grain_mask.astype(int) - eroded.astype(int)\n",
    "\n",
    "    nonzero_coordinates = edges.nonzero()\n",
    "    # Get vector representation of the points\n",
    "    # FIXME : Switched to list comprehension but should be unnecessary to create this as a list as we can use\n",
    "    # np.stack() to combine the arrays and use that...\n",
    "    # return np.stack(nonzero_coordinates, axis=1)\n",
    "    # edges = []\n",
    "    # for vector in np.transpose(nonzero_coordinates):\n",
    "    #     edges.append(list(vector))\n",
    "    # return edges\n",
    "    return [list(vector) for vector in np.transpose(nonzero_coordinates)]\n",
    "\n",
    "\n",
    "def is_clockwise(p_1: tuple, p_2: tuple, p_3: tuple) -> bool:\n",
    "    \"\"\"Function to determine if three points make a clockwise or counter-clockwise turn.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_1: tuple\n",
    "        First point to be used to calculate turn.\n",
    "    p_2: tuple\n",
    "        Second point to be used to calculate turn.\n",
    "    p_3: tuple\n",
    "        Third point to be used to calculate turn.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "        Indicator of whether turn is clockwise.\n",
    "    \"\"\"\n",
    "    # Determine if three points form a clockwise or counter-clockwise turn.\n",
    "    # I use the method of calculating the determinant of the following rotation matrix here. If the determinant\n",
    "    # is > 0 then the rotation is counter-clockwise.\n",
    "    rotation_matrix = np.array(((p_1[0], p_1[1], 1), (p_2[0], p_2[1], 1), (p_3[0], p_3[1], 1)))\n",
    "    return not np.linalg.det(rotation_matrix) > 0\n",
    "\n",
    "\n",
    "def get_triangle_height(base_point_1: np.array, base_point_2: np.array, top_point: np.array) -> float:\n",
    "    \"\"\"Returns the height of a triangle defined by the input point vectors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_point_1: np.ndarray\n",
    "        a base point of the triangle, eg: [5, 3].\n",
    "\n",
    "    base_point_2: np.ndarray\n",
    "        a base point of the triangle, eg: [8, 3].\n",
    "\n",
    "    top_point: np.ndarray\n",
    "        the top point of the triangle, defining the height from the line between the two base points, eg: [6,10].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        The height of the triangle - ie the shortest distance between the top point and the line between the two\n",
    "    base points.\n",
    "    \"\"\"\n",
    "\n",
    "    # Height of triangle = A/b = ||AB X AC|| / ||AB||\n",
    "    a_b = base_point_1 - base_point_2\n",
    "    a_c = base_point_1 - top_point\n",
    "    return np.linalg.norm(np.cross(a_b, a_c)) / np.linalg.norm(a_b)\n",
    "\n",
    "\n",
    "def get_max_min_ferets(edge_points: list):\n",
    "    \"\"\"Returns the minimum and maximum feret diameters for a grain.\n",
    "    These are defined as the smallest and greatest distances between\n",
    "    a pair of callipers that are rotating around a 2d object, maintaining\n",
    "    contact at all times.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_points: list\n",
    "        a list of the vector positions of the pixels comprising the edge of the\n",
    "        grain. Eg: [[0, 0], [1, 0], [2, 1]]\n",
    "    Returns\n",
    "    -------\n",
    "    min_feret: float\n",
    "        the minimum feret diameter of the grain\n",
    "    max_feret: float\n",
    "        the maximum feret diameter of the grain\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The method starts out by calculating the upper and lower convex hulls using\n",
    "    an algorithm based on the Graham Scan Algorithm [1]. Using these upper and\n",
    "    lower hulls, the callipers are simulated as rotating clockwise around the grain.\n",
    "    We determine the order in which vertices are encountered by comparing the\n",
    "    gradients of the slopes between vertices. An array of pairs of points that\n",
    "    are in contact with either calliper at a given time is created in order to\n",
    "    be able to calculate the maximum feret diameter. The minimum diameter is a\n",
    "    little tricky, since it won't simply be the shortest distance between two\n",
    "    contact points, but it will occur somewhere during the rotation around a\n",
    "    pair of contact points. It turns out that the point will always be such\n",
    "    that two points are in contact with one calliper while the other calliper\n",
    "    is in contact with another point. We can use this fact to be sure of finding\n",
    "    the smallest feret diameter, simply by testing each triangle of 3 contact points\n",
    "    as we iterate, finding the height of the triangle that is formed between the\n",
    "    three aforementioned points, as this will be the perpendicular distance between\n",
    "    the callipers.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] Graham, R.L. (1972).\n",
    "        \"An Efficient Algorithm for Determining the Convex Hull of a Finite Planar Set\".\n",
    "        Information Processing Letters. 1 (4): 132-133.\n",
    "        doi:10.1016/0020-0190(72)90045-2.\n",
    "    \"\"\"\n",
    "\n",
    "    min_feret_triangle = None\n",
    "\n",
    "    # Sort the vectors by their x coordinate and then by their y coordinate.\n",
    "    # The conversion between list and numpy array can be removed, though it would be harder\n",
    "    # to read.\n",
    "    edge_points.sort()\n",
    "    edge_points = np.array(edge_points)\n",
    "\n",
    "    # Construct upper and lower hulls for the edge points. Sadly we can't just use the standard hull\n",
    "    # that graham_scan() returns, since we need to separate the upper and lower hulls. I might streamline\n",
    "    # these two into one method later.\n",
    "    upper_hull = []\n",
    "    lower_hull = []\n",
    "    for point in edge_points:\n",
    "        while len(lower_hull) > 1 and is_clockwise(lower_hull[-2], lower_hull[-1], point):\n",
    "            lower_hull.pop()\n",
    "        lower_hull.append(point)\n",
    "        while len(upper_hull) > 1 and not is_clockwise(upper_hull[-2], upper_hull[-1], point):\n",
    "            upper_hull.pop()\n",
    "        upper_hull.append(point)\n",
    "\n",
    "    upper_hull = np.array(upper_hull)\n",
    "    lower_hull = np.array(lower_hull)\n",
    "\n",
    "    # Create list of contact vertices for calipers on the antipodal hulls\n",
    "    contact_points = []\n",
    "    upper_index = 0\n",
    "    lower_index = len(lower_hull) - 1\n",
    "    min_feret = None\n",
    "    while upper_index < len(upper_hull) - 1 or lower_index > 0:\n",
    "        contact_points.append([lower_hull[lower_index, :], upper_hull[upper_index, :]])\n",
    "        # If we have reached the end of the upper hull, continute iterating over the lower hull\n",
    "        if upper_index == len(upper_hull) - 1:\n",
    "            lower_index -= 1\n",
    "            small_feret = get_triangle_height(\n",
    "                np.array(lower_hull[lower_index + 1, :]),\n",
    "                np.array(lower_hull[lower_index, :]),\n",
    "                np.array(upper_hull[upper_index, :]),\n",
    "            )\n",
    "            if min_feret is None or small_feret < min_feret:\n",
    "                min_feret = small_feret\n",
    "                min_feret_triangle = [\n",
    "                    lower_hull[lower_index + 1, :],\n",
    "                    lower_hull[lower_index, :],\n",
    "                    upper_hull[upper_index, :],\n",
    "                ]\n",
    "        # If we have reached the end of the lower hull, continue iterating over the upper hull\n",
    "        elif lower_index == 0:\n",
    "            upper_index += 1\n",
    "            small_feret = get_triangle_height(\n",
    "                np.array(upper_hull[upper_index - 1, :]),\n",
    "                np.array(upper_hull[upper_index, :]),\n",
    "                np.array(lower_hull[lower_index, :]),\n",
    "            )\n",
    "            if min_feret is None or small_feret < min_feret:\n",
    "                min_feret = small_feret\n",
    "                min_feret_triangle = [\n",
    "                    lower_hull[lower_index + 1, :],\n",
    "                    lower_hull[lower_index, :],\n",
    "                    upper_hull[upper_index, :],\n",
    "                ]\n",
    "        # Check if the gradient of the last point and the proposed next point in the upper hull is greater than the gradient\n",
    "        # of the two corresponding points in the lower hull, if so, this means that the next point in the upper hull\n",
    "        # will be encountered before the next point in the lower hull and vice versa.\n",
    "        # Note that the calculation here for gradients is the simple delta upper_y / delta upper_x > delta lower_y / delta lower_x\n",
    "        # however I have multiplied through the denominators such that there are no instances of division by zero. The\n",
    "        # inequality still holds and provides what is needed.\n",
    "        elif (upper_hull[upper_index + 1, 1] - upper_hull[upper_index, 1]) * (\n",
    "            lower_hull[lower_index, 0] - lower_hull[lower_index - 1, 0]\n",
    "        ) > (lower_hull[lower_index, 1] - lower_hull[lower_index - 1, 1]) * (\n",
    "            upper_hull[upper_index + 1, 0] - upper_hull[upper_index, 0]\n",
    "        ):\n",
    "            # If the upper hull is encoutnered first, increment the iteration index for the upper hull\n",
    "            # Also consider the triangle that is made as the two upper hull vertices are colinear with the caliper\n",
    "            upper_index += 1\n",
    "            small_feret = get_triangle_height(\n",
    "                np.array(upper_hull[upper_index - 1, :]),\n",
    "                np.array(upper_hull[upper_index, :]),\n",
    "                np.array(lower_hull[lower_index, :]),\n",
    "            )\n",
    "            if min_feret is None or small_feret < min_feret:\n",
    "                min_feret = small_feret\n",
    "        else:\n",
    "            # The next point in the lower hull will be encountered first, so increment the lower hull iteration index.\n",
    "            lower_index -= 1\n",
    "            small_feret = get_triangle_height(\n",
    "                np.array(lower_hull[lower_index + 1, :]),\n",
    "                np.array(lower_hull[lower_index, :]),\n",
    "                np.array(upper_hull[upper_index, :]),\n",
    "            )\n",
    "\n",
    "            if min_feret is None or small_feret < min_feret:\n",
    "                min_feret = small_feret\n",
    "                min_feret_triangle = [\n",
    "                    lower_hull[lower_index + 1, :],\n",
    "                    lower_hull[lower_index, :],\n",
    "                    upper_hull[upper_index, :],\n",
    "                ]\n",
    "\n",
    "    contact_points = np.array(contact_points)\n",
    "\n",
    "    # Find the minimum and maximum distance in the contact points\n",
    "    max_feret = None\n",
    "    for point_pair in contact_points:\n",
    "        dist = np.sqrt((point_pair[0, 0] - point_pair[1, 0]) ** 2 + (point_pair[0, 1] - point_pair[1, 1]) ** 2)\n",
    "        if max_feret is None or max_feret < dist:\n",
    "            max_feret = dist\n",
    "\n",
    "    return min_feret, max_feret, min_feret_triangle\n",
    "\n",
    "\n",
    "def shoelace(points: np.ndarray):\n",
    "    \"\"\"Use shoelace method to calculate area of polygon\"\"\"\n",
    "\n",
    "    # Add the first point to the end of the array\n",
    "    points = np.vstack([points, points[0]])\n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openness_grain_dict = {}\n",
    "\n",
    "for index, grain_data in pooled_curvature_grain_dict.items():\n",
    "    # print(f\"grain index: {index}\")\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "    pooled_trace = grain_data[\"pooled_trace\"]\n",
    "\n",
    "    # Calculate the minimum and maximum feret diameters\n",
    "    min_feret, max_feret, min_feret_triangle = get_max_min_ferets(edge_points=np.copy(pooled_trace).tolist())\n",
    "\n",
    "    # An open molecule will have a feret ratio of 1, a squished molecule will have a lower feret ratio\n",
    "    feret_ratio = min_feret / max_feret\n",
    "    # feret_ratio = max_feret / min_feret\n",
    "\n",
    "    if plotting:\n",
    "        plt.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        plt.scatter(pooled_trace[:, 1], pooled_trace[:, 0], c=\"k\", s=20)\n",
    "        plt.scatter(min_feret_triangle[0][1], min_feret_triangle[0][0], c=\"red\", s=60)\n",
    "        plt.scatter(min_feret_triangle[1][1], min_feret_triangle[1][0], c=\"red\", s=60)\n",
    "        plt.scatter(min_feret_triangle[2][1], min_feret_triangle[2][0], c=\"red\", s=60)\n",
    "        plt.title(f\"grain index: {index}, feret ratio: {feret_ratio:.2f}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(grain_mask, cmap=cmap, vmin=-8, vmax=8)\n",
    "        plt.scatter(pooled_trace[:, 1], pooled_trace[:, 0], c=\"k\", s=20)\n",
    "        plt.scatter(min_feret_triangle[0][1], min_feret_triangle[0][0], c=\"red\", s=60)\n",
    "        plt.scatter(min_feret_triangle[1][1], min_feret_triangle[1][0], c=\"red\", s=60)\n",
    "        plt.scatter(min_feret_triangle[2][1], min_feret_triangle[2][0], c=\"red\", s=60)\n",
    "        plt.title(f\"grain index: {index}, feret ratio: {feret_ratio:.2f}\")\n",
    "        plt.show()\n",
    "\n",
    "    # Calculate area divided by perimeter\n",
    "    # Calculate the area of the tace\n",
    "    area = shoelace(pooled_trace) * p_to_nm**2\n",
    "    # Calculate the perimeter of the trace\n",
    "    perimeter = np.sum(np.linalg.norm(np.diff(pooled_trace, axis=0), axis=1)) * p_to_nm\n",
    "\n",
    "    perimeter_area_ratio = area / perimeter\n",
    "    # larger\n",
    "\n",
    "    # copy all the data to the openness_grain_dict and add the feret ratio and perimeter area ratio\n",
    "    openness_grain_dict[index] = grain_data\n",
    "    openness_grain_dict[index][\"min_feret\"] = min_feret\n",
    "    openness_grain_dict[index][\"max_feret\"] = max_feret\n",
    "    openness_grain_dict[index][\"feret_ratio\"] = feret_ratio\n",
    "    openness_grain_dict[index][\"perimeter_area_ratio\"] = perimeter_area_ratio\n",
    "\n",
    "# Plot openness as a kde\n",
    "openness_values = [openness_grain_dict[i][\"feret_ratio\"] for i in openness_grain_dict]\n",
    "sns.kdeplot(openness_values)\n",
    "plt.title(f\"Feret ratio (min / max) {SAMPLE_TYPE}\")\n",
    "plt.show()\n",
    "\n",
    "# Plot perimeter area ratio\n",
    "perimeter_area_ratio_values = [openness_grain_dict[i][\"perimeter_area_ratio\"] for i in openness_grain_dict]\n",
    "sns.kdeplot(perimeter_area_ratio_values)\n",
    "plt.title(f\"Area / perimeter {SAMPLE_TYPE}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the pooled points, calculate an allegory for curvature, the change in angle per nm of trace length.\n",
    "\n",
    "\n",
    "def angle_diff_signed(v1: np.ndarray, v2: np.ndarray):\n",
    "    \"\"\"Calculate the signed angle difference between two vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    v1: np.ndarray\n",
    "        The first vector.\n",
    "    v2: np.ndarray\n",
    "        The second vector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The signed angle difference between the two vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate if the new vector is clockwise or anticlockwise from the old vector\n",
    "\n",
    "    # Calculate the angle between the vectors\n",
    "    angle = np.arccos(np.clip(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)), -1.0, 1.0))\n",
    "\n",
    "    # Calculate the cross product\n",
    "    cross = np.cross(v1, v2)\n",
    "\n",
    "    # If the cross product is positive, the new vector is clockwise from the old vector\n",
    "    if cross > 0:\n",
    "        angle = -angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "    # \"\"\"Calculate the angle difference between two vectors.\n",
    "\n",
    "    # Parameters\n",
    "    # ----------\n",
    "    # v1: np.ndarray\n",
    "    #     The first vector.\n",
    "    # v2: np.ndarray\n",
    "    #     The second vector.\n",
    "\n",
    "    # Returns\n",
    "    # -------\n",
    "    # float\n",
    "    #     The angle difference between the two vectors.\n",
    "    # \"\"\"\n",
    "    # v1_u = v1 / np.linalg.norm(v1)\n",
    "    # v2_u = v2 / np.linalg.norm(v2)\n",
    "    # return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "\n",
    "# Test the angle diff function\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([0, 1])\n",
    "print(np.degrees(angle_diff_signed(v1, v2)))\n",
    "\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([1, 1])\n",
    "print(np.degrees(angle_diff_signed(v1, v2)))\n",
    "\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([1, -1])\n",
    "print(np.degrees(angle_diff_signed(v1, v2)))\n",
    "\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([-1, 0])\n",
    "print(np.degrees(angle_diff_signed(v1, v2)))\n",
    "\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([-1, 1])\n",
    "print(np.degrees(angle_diff_signed(v1, v2)))\n",
    "\n",
    "\n",
    "def angle_per_nm(trace: np.ndarray, p_to_nm: float, plot: bool = False) -> np.ndarray:\n",
    "    \"\"\"Calculate the angle per nm of a trace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trace: np.ndarray\n",
    "        The trace to calculate the angle per nm of.\n",
    "    p_to_nm: float\n",
    "        The pixel to nm scaling factor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The angle change per nm for each point in the trace\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the first point is the same as the last point\n",
    "    if np.all(trace[0] == trace[-1]):\n",
    "        raise ValueError(\"The first and last points are the same\")\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    angles_per_nm = np.zeros(len(trace))\n",
    "    angle_diffs = np.zeros(len(trace))\n",
    "\n",
    "    for index, point in enumerate(trace):\n",
    "        # print(f\"index: {index}\")\n",
    "        if plot:\n",
    "            ax.scatter(point[1], point[0], c=\"purple\", s=20)\n",
    "\n",
    "        # Get the vectors to the previous and next points\n",
    "        if index == 0:\n",
    "            v_prev = point - trace[-1]\n",
    "            v_next = trace[index + 1] - point\n",
    "        if index == len(trace) - 1:\n",
    "            v_prev = point - trace[index - 1]\n",
    "            v_next = trace[0] - point\n",
    "        else:\n",
    "            v_prev = point - trace[index - 1]\n",
    "            v_next = trace[index + 1] - point\n",
    "\n",
    "        # print(f\"vprev: {v_prev} vnext: {v_next}\")\n",
    "\n",
    "        # Normalise the vectors to unit length\n",
    "        norm_v_prev = v_prev / np.linalg.norm(v_prev) * 0.1\n",
    "        norm_v_next = v_next / np.linalg.norm(v_next) * 0.1\n",
    "\n",
    "        angle = angle_diff_signed(v_prev, v_next)\n",
    "\n",
    "        if plot:\n",
    "            # Plot the vectors\n",
    "            ax.arrow(\n",
    "                point[1], point[0], norm_v_prev[1], norm_v_prev[0], head_width=0.01, head_length=0.2, fc=\"r\", ec=\"r\"\n",
    "            )\n",
    "            ax.arrow(\n",
    "                point[1], point[0], norm_v_next[1], norm_v_next[0], head_width=0.01, head_length=0.2, fc=\"b\", ec=\"b\"\n",
    "            )\n",
    "            # Write text for the angle\n",
    "            ax.text(point[1], point[0], f\"{np.degrees(angle):.2f}\", fontsize=12, color=\"black\")\n",
    "\n",
    "        distance = np.linalg.norm(v_prev) * p_to_nm\n",
    "\n",
    "        # print(f\"distance: {distance:.4f} angle: {angle:.4f} angle per nm: {angle / distance:.4f}\")\n",
    "\n",
    "        angles_per_nm[index] = angle / distance\n",
    "        angle_diffs[index] = angle\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(trace[:, 1], trace[:, 0], \"k\")\n",
    "        plt.show()\n",
    "\n",
    "    return angles_per_nm, angle_diffs\n",
    "\n",
    "\n",
    "# # Test the angle per nm function\n",
    "\n",
    "# trace = np.array(\n",
    "#     [\n",
    "#         [0, 0],\n",
    "#         [1, 0],\n",
    "#         [1, 1],\n",
    "#         [2, 1],\n",
    "#         [4, 5],\n",
    "#         [6, 2],\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# px_to_nm = 1\n",
    "\n",
    "# # Create an ellipse of points\n",
    "# n = 100\n",
    "# theta = np.linspace(0, 2 * np.pi, n)\n",
    "# a = 3\n",
    "# b = 2\n",
    "# x = a * np.cos(theta)\n",
    "# y = b * np.sin(theta)\n",
    "# ellipse = np.array([x, y]).T\n",
    "# # Remove the last point as it is the same as the first\n",
    "# ellipse = ellipse[:-1]\n",
    "# # Reverse the order of the points\n",
    "# ellipse = ellipse[::-1]\n",
    "\n",
    "# plt.plot(ellipse[:, 0], ellipse[:, 1], \".\")\n",
    "# plt.show()\n",
    "\n",
    "# angles_per_nm, angle_diffs = angle_per_nm(ellipse, px_to_nm, plot=True)\n",
    "\n",
    "# plt.plot(angles_per_nm, \"-o\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Generate a set of points on a circle\n",
    "# n = 10\n",
    "# theta = np.linspace(0, 2 * np.pi, n)\n",
    "# # remove the last point as it is the same as the first\n",
    "# theta = theta[:-1]\n",
    "# r = 1\n",
    "# x = r * np.cos(theta)\n",
    "# y = r * np.sin(theta)\n",
    "# circle = np.array([x, y]).T\n",
    "\n",
    "# # Test the angle per nm function on a circle\n",
    "# px_to_nm = 1\n",
    "# angles_per_nm, angle_diffs = angle_per_nm(circle, px_to_nm, plot=True)\n",
    "\n",
    "# plt.plot(angles_per_nm)\n",
    "# plt.title(f\"angle per unit length for a circle of {n} points\")\n",
    "\n",
    "# print(angles_per_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_if_anticlockwise(trace: np.ndarray):\n",
    "    # Check if the trace is clockwise or anticlockwise by summing the cross products of the vectors\n",
    "    # If the sum is positive, the trace is clockwise\n",
    "    # If the sum is negative, the trace is anticlockwise\n",
    "    # If the sum is 0, the trace is a straight line\n",
    "    cross_sum = 0\n",
    "    for i in range(len(trace) - 1):\n",
    "        cross_sum += np.cross(trace[i], trace[i + 1])\n",
    "    if cross_sum > 0:\n",
    "        # print(\"clockwise\")\n",
    "        # Reverse the trace\n",
    "        trace = np.flip(trace, axis=0)\n",
    "    elif cross_sum < 0:\n",
    "        # print(\"anticlockwise\")\n",
    "        pass\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defect_stats(array: np.ndarray, threshold: float):\n",
    "    regions = []\n",
    "    in_region = False\n",
    "    # Find the largest continuous region below the threshold\n",
    "    for index, value in enumerate(array):\n",
    "        if value > threshold:\n",
    "            if not in_region:\n",
    "                # Start region\n",
    "                region_start = index\n",
    "                area = 0\n",
    "                highest_point = value\n",
    "                highest_point_index = index\n",
    "                in_region = True\n",
    "            else:\n",
    "                area += threshold - value\n",
    "                if value > highest_point:\n",
    "                    highest_point = value\n",
    "                    highest_point_index = index\n",
    "        elif in_region:\n",
    "            regions.append(\n",
    "                {\n",
    "                    \"start\": region_start,\n",
    "                    \"end\": index,\n",
    "                    \"area\": area,\n",
    "                    \"highest_point_index\": highest_point_index,\n",
    "                    \"highest_point\": highest_point,\n",
    "                    \"defect_threshold\": threshold,\n",
    "                }\n",
    "            )\n",
    "            in_region = False\n",
    "    if in_region:\n",
    "        regions.append(\n",
    "            {\n",
    "                \"start\": region_start,\n",
    "                \"end\": index,\n",
    "                \"area\": area,\n",
    "                \"highest_point_index\": highest_point_index,\n",
    "                \"highest_point\": highest_point,\n",
    "                \"defect_threshold\": threshold,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Check if there are defects at the start and end of the array\n",
    "    if len(regions) > 0:\n",
    "        # Check if the first region starts at the start of the array\n",
    "        if regions[0][\"start\"] == 0:\n",
    "            # And if the last region ends at the end of the array\n",
    "            if regions[-1][\"end\"] == len(array) - 1:\n",
    "                # Combine the first and last regions\n",
    "                regions[0][\"start\"] = regions[-1][\"start\"]\n",
    "                regions[0][\"area\"] += regions[-1][\"area\"]\n",
    "                if regions[-1][\"highest_point\"] > regions[0][\"highest_point\"]:\n",
    "                    regions[0][\"highest_point\"] = regions[-1][\"highest_point\"]\n",
    "                    regions[0][\"highest_point_index\"] = regions[-1][\"highest_point_index\"]\n",
    "                regions.pop(-1)\n",
    "\n",
    "    # Number of defects\n",
    "    number_of_defects = len(regions)\n",
    "\n",
    "    # Find the largest region\n",
    "    largest_region_below_threshold = None\n",
    "    largest_area = 0\n",
    "    for region in regions:\n",
    "        if region[\"area\"] > largest_area:\n",
    "            largest_area = region[\"area\"]\n",
    "            largest_region_below_threshold = region\n",
    "\n",
    "    # Find the midpoint of each region\n",
    "    for region in regions:\n",
    "        if region[\"start\"] < region[\"end\"]:\n",
    "            region[\"midpoint\"] = int(np.round((region[\"start\"] + region[\"end\"]) / 2))\n",
    "        else:\n",
    "            # Get the negative index to be able to take the average of the two indexes\n",
    "            temp_startpoint = region[\"start\"] - len(array)\n",
    "            region[\"midpoint\"] = int(np.round((temp_startpoint + region[\"end\"]) / 2)) % len(array)\n",
    "\n",
    "    return {\n",
    "        \"defect_number\": number_of_defects,\n",
    "        \"defect_largest_region\": largest_region_below_threshold,\n",
    "        \"defect_regions\": regions,\n",
    "    }\n",
    "\n",
    "\n",
    "testarr1 = np.array(\n",
    "    [\n",
    "        0.4002,\n",
    "        0.4014,\n",
    "        0.4005,\n",
    "        0.3933,\n",
    "        0.3781,\n",
    "        0.3564,\n",
    "        0.3328,\n",
    "        0.3114,\n",
    "        0.2939,\n",
    "        0.2791,\n",
    "        0.2641,\n",
    "        0.2461,\n",
    "        0.2239,\n",
    "        0.1980,\n",
    "        0.1692,\n",
    "        0.1383,\n",
    "        0.1057,\n",
    "        0.0717,\n",
    "        0.0374,\n",
    "        0.0052,\n",
    "        -0.0221,\n",
    "        -0.0417,\n",
    "        -0.0518,\n",
    "        -0.0514,\n",
    "        -0.0408,\n",
    "        -0.0202,\n",
    "        0.0093,\n",
    "        0.0460,\n",
    "        0.0866,\n",
    "        0.1267,\n",
    "        0.1617,\n",
    "        0.1886,\n",
    "        0.2069,\n",
    "        0.2191,\n",
    "        0.2295,\n",
    "        0.2429,\n",
    "        0.2617,\n",
    "        0.2853,\n",
    "        0.3099,\n",
    "        0.3295,\n",
    "        0.3387,\n",
    "        0.3341,\n",
    "        0.3153,\n",
    "        0.2847,\n",
    "        0.2462,\n",
    "        0.2042,\n",
    "        0.1627,\n",
    "        0.1248,\n",
    "        0.0924,\n",
    "        0.0666,\n",
    "        0.0479,\n",
    "        0.0362,\n",
    "        0.0310,\n",
    "        0.0310,\n",
    "        0.0343,\n",
    "        0.0384,\n",
    "        0.0406,\n",
    "        0.0390,\n",
    "        0.0330,\n",
    "        0.0239,\n",
    "        0.0135,\n",
    "        0.0034,\n",
    "        -0.0058,\n",
    "        -0.0142,\n",
    "        -0.0220,\n",
    "        -0.0283,\n",
    "        -0.0320,\n",
    "    ]\n",
    ")\n",
    "\n",
    "testarr2 = np.array(\n",
    "    [\n",
    "        0.2799,\n",
    "        0.2818,\n",
    "        0.2845,\n",
    "        0.2852,\n",
    "        0.2805,\n",
    "        0.2674,\n",
    "        0.2448,\n",
    "        0.2136,\n",
    "        0.1773,\n",
    "        0.1394,\n",
    "        0.1027,\n",
    "        0.0681,\n",
    "        0.0355,\n",
    "        0.0055,\n",
    "        -0.0203,\n",
    "        -0.0392,\n",
    "        -0.0485,\n",
    "        -0.0475,\n",
    "        -0.0378,\n",
    "        -0.0221,\n",
    "        -0.0037,\n",
    "        0.0148,\n",
    "        0.0320,\n",
    "        0.0478,\n",
    "        0.0636,\n",
    "        0.0819,\n",
    "        0.1056,\n",
    "        0.1373,\n",
    "        0.1780,\n",
    "        0.2270,\n",
    "        0.2812,\n",
    "        0.3358,\n",
    "        0.3848,\n",
    "        0.4217,\n",
    "        0.4408,\n",
    "        0.4378,\n",
    "        0.4110,\n",
    "        0.3628,\n",
    "        0.2999,\n",
    "        0.2319,\n",
    "        0.1692,\n",
    "        0.1192,\n",
    "        0.0848,\n",
    "        0.0643,\n",
    "        0.0529,\n",
    "        0.0457,\n",
    "        0.0390,\n",
    "        0.0309,\n",
    "        0.0212,\n",
    "        0.0113,\n",
    "        0.0028,\n",
    "        -0.0025,\n",
    "        -0.0031,\n",
    "        0.0015,\n",
    "        0.0115,\n",
    "        0.0266,\n",
    "        0.0459,\n",
    "        0.0688,\n",
    "        0.0949,\n",
    "        0.1244,\n",
    "        0.1571,\n",
    "        0.1928,\n",
    "        0.2301,\n",
    "        0.2668,\n",
    "        0.3003,\n",
    "        0.3282,\n",
    "        0.3482,\n",
    "        0.3587,\n",
    "    ]\n",
    ")\n",
    "\n",
    "threshold = 0.2\n",
    "\n",
    "test_defect_stats_1 = defect_stats(testarr1, threshold)\n",
    "print(test_defect_stats_1)\n",
    "\n",
    "test_defect_stats_2 = defect_stats(testarr2, threshold)\n",
    "print(test_defect_stats_2)\n",
    "\n",
    "\n",
    "for testarr, test_defect_stats in zip([testarr1, testarr2], [test_defect_stats_1, test_defect_stats_2]):\n",
    "    plt.plot(testarr)\n",
    "    plt.ylim(-0.5, 0.5)\n",
    "    plt.axhline(threshold, color=\"k\", linestyle=\"--\")\n",
    "    plt.axhline(0, color=\"k\", linestyle=\"-\")\n",
    "    for region in test_defect_stats[\"defect_regions\"]:\n",
    "        if region[\"start\"] < region[\"end\"]:\n",
    "            plt.axvspan(region[\"start\"], region[\"end\"], color=\"red\", alpha=0.3)\n",
    "        else:\n",
    "            plt.axvspan(region[\"start\"], len(testarr1), color=\"red\", alpha=0.3)\n",
    "            plt.axvspan(0, region[\"end\"], color=\"red\", alpha=0.3)\n",
    "        # Identify the deepest point\n",
    "        plt.scatter(region[\"highest_point_index\"], testarr[region[\"highest_point_index\"]], c=\"r\")\n",
    "        # Plot the midpoint\n",
    "        plt.axvline(region[\"midpoint\"], color=\"b\", linestyle=\"--\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_real_distance_between_points_in_array(\n",
    "    array: np.ndarray, indexes_to_calculate_distance_between: np.ndarray, p_to_nm: float\n",
    "):\n",
    "    # Calculate the distances between each defect along the trace\n",
    "    to_find = np.copy(indexes_to_calculate_distance_between)\n",
    "    original = to_find[0]\n",
    "    current_index = original\n",
    "    current_position = array[current_index]\n",
    "    previous_position = current_position\n",
    "    distances = []\n",
    "    distance = 0\n",
    "    while len(to_find) > 0:\n",
    "        # Update old position\n",
    "        previous_position = current_position\n",
    "        # Increment the current position along the trace\n",
    "        current_index += 1\n",
    "        if current_index >= len(array):\n",
    "            current_index -= len(array)\n",
    "        current_position = array[current_index]\n",
    "\n",
    "        # Increment the distance\n",
    "        distance += np.linalg.norm(current_position - previous_position) * p_to_nm\n",
    "\n",
    "        # Check if the current index is in the to_find list\n",
    "        if current_index in to_find:\n",
    "            # Get rid of the current index from the to_find list\n",
    "            to_find = to_find[to_find != current_index]\n",
    "            # Store the distance\n",
    "            distances.append(distance)\n",
    "            # Reset the distance\n",
    "            distance = 0\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "# # Test the distance calculation\n",
    "# array = np.array(\n",
    "#     [\n",
    "#         [5, 5],\n",
    "#         [5, 6],\n",
    "#         [6, 7],\n",
    "#         [7, 7],\n",
    "#         [8, 6],\n",
    "#         [8, 5],\n",
    "#         [7, 4],\n",
    "#         [6, 4],\n",
    "#         [5, 5],\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# indexes_to_calculate_distance_between = np.array([0, 3, 7])\n",
    "# p_to_nm = 1\n",
    "\n",
    "# distances = calculate_real_distance_between_points_in_array(array, indexes_to_calculate_distance_between, p_to_nm)\n",
    "\n",
    "# print(distances)\n",
    "\n",
    "# plt.plot(array[:, 0], array[:, 1], \"o-\")\n",
    "# # Mark the start point with a star\n",
    "# plt.scatter(\n",
    "#     array[indexes_to_calculate_distance_between[0], 0],\n",
    "#     array[indexes_to_calculate_distance_between[0], 1],\n",
    "#     c=\"k\",\n",
    "#     s=400,\n",
    "#     marker=\"*\",\n",
    "# )\n",
    "# # Mark the points to calculate the distance between\n",
    "# plt.scatter(\n",
    "#     array[indexes_to_calculate_distance_between, 0], array[indexes_to_calculate_distance_between, 1], c=\"r\", s=100\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE calculate rate of change of vector angle per nm\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "angle_change_rate_grain_dict = {}\n",
    "plotting = False\n",
    "\n",
    "for index, grain_data in openness_grain_dict.items():\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    pooled_trace = grain_data[\"pooled_trace\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "\n",
    "    # if index != 49:\n",
    "    #     continue\n",
    "\n",
    "    # Degrees per nm threshold\n",
    "    degrees_per_nm_threshold = 12\n",
    "    radians_per_nm_threshld = np.radians(degrees_per_nm_threshold)\n",
    "    if plotting:\n",
    "        print(f\"radians per nm threshold: {radians_per_nm_threshld}\")\n",
    "\n",
    "    pooled_trace = flip_if_anticlockwise(pooled_trace)\n",
    "\n",
    "    # Sample points once every n nm\n",
    "    nm_sample_distance = 0.5\n",
    "    # Sample pooled trace every 2 nm\n",
    "    nm_sampled_trace = []\n",
    "    pixel_sample_distance = nm_sample_distance / p_to_nm\n",
    "    # Starting at zero, for each point in pooled trace, see if the distance from the last point is greater than the sample distance and if not skip until it is\n",
    "    for i in range(len(pooled_trace)):\n",
    "        if i == 0:\n",
    "            nm_sampled_trace.append(pooled_trace[i])\n",
    "        else:\n",
    "            # If the distance between the current point and the last point in the sampled trace is greater than the sample distance, add the current point to the sampled trace\n",
    "            if np.linalg.norm(pooled_trace[i] - nm_sampled_trace[-1]) > pixel_sample_distance:\n",
    "                nm_sampled_trace.append(pooled_trace[i])\n",
    "\n",
    "    nm_sampled_trace = np.array(nm_sampled_trace)\n",
    "\n",
    "    angles_per_nm, angle_diffs = angle_per_nm(nm_sampled_trace, p_to_nm, plot=False)\n",
    "\n",
    "    # Smooth the angles per nm\n",
    "    angles_per_nm = gaussian_filter1d(angles_per_nm, 3)\n",
    "\n",
    "    # Get the defect stats\n",
    "    defect_stats_dict = defect_stats(angles_per_nm, radians_per_nm_threshld)\n",
    "\n",
    "    # Print angles per nm with commas between so it can be copied into a spreadsheet\n",
    "    # print(\",\".join([f\"{angle:.4f}\" for angle in angles_per_nm]))\n",
    "\n",
    "    # Calculate the real distance between the defects\n",
    "    defect_indexes = np.array([region[\"midpoint\"] for region in defect_stats_dict[\"defect_regions\"]])\n",
    "    defect_distances = None\n",
    "    if len(defect_indexes) > 1:\n",
    "        defect_distances = calculate_real_distance_between_points_in_array(nm_sampled_trace, defect_indexes, p_to_nm)\n",
    "        if plotting:\n",
    "            print(f\"defect distances: {defect_distances}\")\n",
    "\n",
    "    # Tag the molecules\n",
    "    # If 3 defects, then dorito\n",
    "    # If 2 defects, then churro or pasty\n",
    "    if defect_stats_dict[\"defect_number\"] == 3:\n",
    "        tag = \"dorito\"\n",
    "    elif defect_stats_dict[\"defect_number\"] == 2:\n",
    "        # If the two defect distances are similar then churro, else pasty\n",
    "        # Threshold as % of the total length of the trace\n",
    "        pasty_defect_difference_percentage = 0.1\n",
    "        if np.abs(defect_distances[0] - defect_distances[1]) < pasty_defect_difference_percentage * np.sum(\n",
    "            defect_distances\n",
    "        ):\n",
    "            tag = \"churro\"\n",
    "        else:\n",
    "            tag = \"pasty\"\n",
    "    elif defect_stats_dict[\"defect_number\"] == 1:\n",
    "        tag = \"teardrop\"\n",
    "    else:\n",
    "        tag = \"open\"\n",
    "\n",
    "    if plotting:\n",
    "        plt.plot(angles_per_nm)\n",
    "        plt.ylim(-0.5, 0.5)\n",
    "        plt.axhline(radians_per_nm_threshld, color=\"k\", linestyle=\"--\")\n",
    "        plt.axhline(0, color=\"k\", linestyle=\"-\")\n",
    "        for region in defect_stats_dict[\"defect_regions\"]:\n",
    "            if region[\"start\"] < region[\"end\"]:\n",
    "                plt.axvspan(region[\"start\"], region[\"end\"], color=\"red\", alpha=0.3)\n",
    "            else:\n",
    "                plt.axvspan(region[\"start\"], len(angles_per_nm), color=\"red\", alpha=0.3)\n",
    "                plt.axvspan(0, region[\"end\"], color=\"red\", alpha=0.3)\n",
    "            # Identify the deepest point\n",
    "            # plt.scatter(region[\"highest_point_index\"], angles_per_nm[region[\"highest_point_index\"]], c=\"lime\")\n",
    "            # Plot the midpoint\n",
    "            plt.scatter(region[\"midpoint\"], angles_per_nm[region[\"midpoint\"]], c=\"lime\")\n",
    "        plt.show()\n",
    "\n",
    "        assert len(angles_per_nm) == len(nm_sampled_trace)\n",
    "\n",
    "        plt.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        plt.plot(pooled_trace[:, 1], pooled_trace[:, 0], \"r\")\n",
    "        plt.plot(nm_sampled_trace[:, 1], nm_sampled_trace[:, 0], \"b\")\n",
    "        # # For each defect, mark its highest point\n",
    "        # for region in defect_stats_dict[\"defect_regions\"]:\n",
    "        #     plt.scatter(nm_sampled_trace[region[\"highest_point_index\"]][1], nm_sampled_trace[region[\"highest_point_index\"]][0], c=\"lime\")\n",
    "        # For each defect mark its midpoint\n",
    "        for region in defect_stats_dict[\"defect_regions\"]:\n",
    "            plt.scatter(nm_sampled_trace[region[\"midpoint\"]][1], nm_sampled_trace[region[\"midpoint\"]][0], c=\"lime\")\n",
    "        plt.title(f\"tag: {tag}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    angle_change_rate_grain_dict[index] = grain_data\n",
    "    angle_change_rate_grain_dict[index][\"angles_per_nm\"] = angles_per_nm\n",
    "    angle_change_rate_grain_dict[index][\"simple_defect_stats\"] = defect_stats_dict\n",
    "    angle_change_rate_grain_dict[index][\"simple_defect_distances\"] = defect_distances\n",
    "    angle_change_rate_grain_dict[index][\"simple_nm_sampled_trace\"] = nm_sampled_trace\n",
    "    angle_change_rate_grain_dict[index][\"simple_tag\"] = tag\n",
    "\n",
    "    # angle_change_rate_grain_dict[index] = {\n",
    "    #     \"image\": grain_image,\n",
    "    #     \"mask\": grain_mask,\n",
    "    #     \"pooled_trace\": pooled_trace,\n",
    "    #     \"angles_per_nm\": angles_per_nm,\n",
    "    #     \"p_to_nm\": p_to_nm,\n",
    "    #     \"defect_stats\": defect_stats_dict,\n",
    "    #     \"defect_distances\": defect_distances,\n",
    "    #     \"nm_sampled_trace\": nm_sampled_trace,\n",
    "    #     \"tag\": tag,\n",
    "    # }\n",
    "\n",
    "\n",
    "def plot_images(\n",
    "    images: list,\n",
    "    tags: list,\n",
    "    grain_indexes: list,\n",
    "    nm_sampled_traces: np.ndarray,\n",
    "    defect_stats: list,\n",
    "    px_to_nms: list,\n",
    "    width=5,\n",
    "    cmap=cmap,\n",
    "    vmin=-8,\n",
    "    vmax=8,\n",
    "    title: str = \"\",\n",
    "):\n",
    "    num_images = len(images)\n",
    "    rows = np.ceil(num_images / width).astype(int)\n",
    "    if rows == 1:\n",
    "        rows = 2\n",
    "    fig, ax = plt.subplots(rows, width, figsize=(30, 10 + 10 * rows))\n",
    "    for i, (image, tag, grain_index, single_defect_stats, nm_sampled_trace) in enumerate(\n",
    "        zip(images, tags, grain_indexes, defect_stats, nm_sampled_traces)\n",
    "    ):\n",
    "        ax[i // width, i % width].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        # Plot the trace\n",
    "        ax[i // width, i % width].plot(nm_sampled_trace[:, 1], nm_sampled_trace[:, 0], \"b\")\n",
    "        ax[i // width, i % width].axis(\"off\")\n",
    "        ax[i // width, i % width].set_title(f\"grain index: {grain_index} tag: {tag}\")\n",
    "\n",
    "        # Plot midpoints\n",
    "        for region in single_defect_stats[\"defect_regions\"]:\n",
    "            ax[i // width, i % width].scatter(\n",
    "                nm_sampled_trace[region[\"midpoint\"]][1], nm_sampled_trace[region[\"midpoint\"]][0], c=\"lime\"\n",
    "            )\n",
    "\n",
    "    plt.suptitle(title, fontsize=30)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_images(\n",
    "    [angle_change_rate_grain_dict[i][\"image\"] for i in angle_change_rate_grain_dict],\n",
    "    [angle_change_rate_grain_dict[i][\"simple_tag\"] for i in angle_change_rate_grain_dict],\n",
    "    [i for i in angle_change_rate_grain_dict],\n",
    "    [angle_change_rate_grain_dict[i][\"simple_nm_sampled_trace\"] for i in angle_change_rate_grain_dict],\n",
    "    [angle_change_rate_grain_dict[i][\"simple_defect_stats\"] for i in angle_change_rate_grain_dict],\n",
    "    [angle_change_rate_grain_dict[i][\"p_to_nm\"] for i in angle_change_rate_grain_dict],\n",
    ")\n",
    "\n",
    "# Plot just the churros\n",
    "# tag_to_plot = \"unclassified\"\n",
    "# indexes = [i for i in angle_change_rate_grain_dict if angle_change_rate_grain_dict[i][\"tag\"] == tag_to_plot]\n",
    "# print(tag_to_plot, indexes)\n",
    "# plot_images(\n",
    "#     [angle_change_rate_grain_dict[i][\"image\"] for i in indexes],\n",
    "#     [angle_change_rate_grain_dict[i][\"tag\"] for i in indexes],\n",
    "#     [i for i in indexes],\n",
    "#     [angle_change_rate_grain_dict[i][\"nm_sampled_trace\"] for i in indexes],\n",
    "#     [angle_change_rate_grain_dict[i][\"defect_stats\"] for i in indexes],\n",
    "#     [angle_change_rate_grain_dict[i][\"p_to_nm\"] for i in indexes],\n",
    "#     title=tag_to_plot,\n",
    "# )\n",
    "\n",
    "# Bar chart of tags\n",
    "tags = [angle_change_rate_grain_dict[i][\"simple_tag\"] for i in angle_change_rate_grain_dict]\n",
    "unique_tags, counts = np.unique(tags, return_counts=True)\n",
    "# sort by alphabetical order\n",
    "unique_tags, counts = zip(*sorted(zip(unique_tags, counts)))\n",
    "plt.bar(unique_tags, counts)\n",
    "plt.title(f\"(Angle per nm based) distribution for {SAMPLE_TYPE}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average_position(array: np.ndarray, clip_min: float) -> float:\n",
    "    \"\"\"Calculate the weighted average position in an array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array: np.ndarray\n",
    "        The array to calculate the weighted average position of.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The weighted average position in the array.\n",
    "    \"\"\"\n",
    "    positions = np.arange(len(array))\n",
    "    weights = np.copy(array)\n",
    "    weights[weights < clip_min] = clip_min\n",
    "    weighted_average = np.average(positions, weights=array)\n",
    "    return weighted_average\n",
    "\n",
    "\n",
    "testarr = np.array([0, 1, 3, 5, 10, 10000000, 2, 12, 0])\n",
    "\n",
    "print(weighted_average_position(testarr, clip_min=0))\n",
    "\n",
    "\n",
    "def weighted_mean_defect_position(\n",
    "    defect_angle_shifts: np.ndarray, defect_start_index: int, max_index: int, clip_min: float = 0.0\n",
    "):\n",
    "    weighted_mean_angle_shift_index = (\n",
    "        weighted_average_position(defect_angle_shifts, clip_min=clip_min) + defect_start_index\n",
    "    )\n",
    "    weighted_mean_angle_shift_index_int = int(np.round(weighted_mean_angle_shift_index))\n",
    "    if weighted_mean_angle_shift_index >= len(angles_per_nm):\n",
    "        weighted_mean_angle_shift_index -= len(angles_per_nm)\n",
    "    if weighted_mean_angle_shift_index_int >= len(angles_per_nm):\n",
    "        weighted_mean_angle_shift_index_int -= len(angles_per_nm)\n",
    "\n",
    "    return weighted_mean_angle_shift_index, weighted_mean_angle_shift_index_int\n",
    "\n",
    "\n",
    "def find_distance_window_looped(distances: np.ndarray, window_distance: float, start_index: int):\n",
    "    \"\"\"Find a window that covers a certain distance in a set of points in a loop (but the start point is not repeated at the end)\n",
    "    where the distances between the points are known including the distance between the end point and the start point.\n",
    "    \"\"\"\n",
    "\n",
    "    distances = np.copy(distances)\n",
    "\n",
    "    window_current_distance = 0\n",
    "    window_start_index = start_index\n",
    "    proposed_end_index = start_index\n",
    "    found_end = False\n",
    "    max_iterations = len(distances)\n",
    "    iterations = 0\n",
    "    while not found_end:\n",
    "        # print(f\"start index: {window_start_index}, proposed end index: {proposed_end_index}, distance so far: {window_current_distance}\")\n",
    "        # Check if distance is greater than the requested distance\n",
    "        if window_current_distance > window_distance:\n",
    "            # print(f\"found end at index: {proposed_end_index}\")\n",
    "            found_end = True\n",
    "            window_end_index = proposed_end_index\n",
    "            return window_start_index, window_end_index, window_current_distance\n",
    "        else:\n",
    "            # Increment the window distance\n",
    "            # print(f\"adding distance: {distances[proposed_end_index]}\")\n",
    "            window_current_distance += distances[proposed_end_index]\n",
    "            # Increment the proposed end index\n",
    "            if proposed_end_index < len(distances) - 1:\n",
    "                proposed_end_index += 1\n",
    "            else:\n",
    "                proposed_end_index = 0\n",
    "\n",
    "        # Safety for infinite loop\n",
    "        if iterations > max_iterations:\n",
    "            raise ValueError(\"Max iterations reached\")\n",
    "        iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_two_defects(\n",
    "    defect_0: dict,\n",
    "    defect_1: dict,\n",
    "    max_trace_index: int,\n",
    "    angle_diffs: np.ndarray,\n",
    "):\n",
    "    \"\"\"Combine two defects into one defect.\"\"\"\n",
    "\n",
    "    # Combine the defects\n",
    "    combined_indexes = np.unique(np.append(defect_0[\"indexes\"], defect_1[\"indexes\"]))\n",
    "\n",
    "    # Find the start and end points of the combined indexes\n",
    "    # Check if the combined indexes span the end of the array\n",
    "    if len(angles_per_nm) - 1 in combined_indexes and 0 in combined_indexes:\n",
    "        # If so, the starting index will be the index without a number preceding it and the end index will be the index without a number following it\n",
    "        # To find end index, count forward from 0 until there is a number missing\n",
    "        for candidate_end_index in range(len(angles_per_nm)):\n",
    "            if candidate_end_index + 1 not in combined_indexes:\n",
    "                end_index = candidate_end_index\n",
    "                break\n",
    "        # To find start index, count backward from the end until there is a number missing\n",
    "        for candidate_start_index in range(len(angles_per_nm) - 1, 0, -1):\n",
    "            if candidate_start_index - 1 not in combined_indexes:\n",
    "                start_index = candidate_start_index\n",
    "                break\n",
    "    else:\n",
    "        start_index = np.min(combined_indexes)\n",
    "        end_index = np.max(combined_indexes)\n",
    "\n",
    "    # Calculate the total angle shift over the defect\n",
    "    if end_index > start_index:\n",
    "        total_angle_shift = np.sum(angle_diffs[start_index:end_index])\n",
    "    else:\n",
    "        total_angle_shift = np.sum(np.append(angle_diffs[start_index:], angle_diffs[:end_index]))\n",
    "\n",
    "    # Calculate the maximum angle shift and the index of the point with maximum shift\n",
    "    if end_index > start_index:\n",
    "        local_angle_shifts = angle_diffs[start_index:end_index]\n",
    "        local_maximum_angle_shift_index = np.argmax(local_angle_shifts)\n",
    "        maximum_angle_shift = local_angle_shifts[local_maximum_angle_shift_index]\n",
    "        maximum_angle_shift_index = start_index + local_maximum_angle_shift_index\n",
    "    else:\n",
    "        local_angle_shifts = np.append(angle_diffs[start_index:], angle_diffs[:end_index])\n",
    "        local_maximum_angle_shift_index = np.argmax(local_angle_shifts)\n",
    "        maximum_angle_shift = local_angle_shifts[local_maximum_angle_shift_index]\n",
    "        maximum_angle_shift_index = start_index + local_maximum_angle_shift_index\n",
    "        if maximum_angle_shift_index >= len(angles_per_nm):\n",
    "            maximum_angle_shift_index -= len(angles_per_nm)\n",
    "\n",
    "    # Calculate the weighted mean angle shift index\n",
    "    # Get the angle diffs for the combined indexes\n",
    "    if end_index > start_index:\n",
    "        defect_angle_shifts = angle_diffs[start_index:end_index]\n",
    "    else:\n",
    "        defect_angle_shifts = np.append(angle_diffs[start_index:], angle_diffs[:end_index])\n",
    "\n",
    "    (\n",
    "        weighted_mean_angle_shift_index,\n",
    "        weighted_mean_angle_shift_index_int,\n",
    "    ) = weighted_mean_defect_position(\n",
    "        defect_angle_shifts=defect_angle_shifts,\n",
    "        defect_start_index=start_index,\n",
    "        max_index=len(angles_per_nm),\n",
    "    )\n",
    "\n",
    "    combined_defect = {\n",
    "        \"start_index\": start_index,\n",
    "        \"end_index\": end_index,\n",
    "        \"maximum_total_angle_shift\": total_angle_shift,\n",
    "        \"maximum_angle_shift\": maximum_angle_shift,\n",
    "        \"maximum_angle_shift_index\": maximum_angle_shift_index,\n",
    "        \"indexes\": combined_indexes,\n",
    "        \"weighted_mean_angle_shift_index\": weighted_mean_angle_shift_index,\n",
    "        \"weighted_mean_angle_shift_index_int\": weighted_mean_angle_shift_index_int,\n",
    "    }\n",
    "\n",
    "    return combined_defect\n",
    "\n",
    "\n",
    "def combine_overlapping_defects(defects: list):\n",
    "    \"\"\"Combine any overlapping defects in a list of defects where each defect is a dictionary of statistics for the defect.\n",
    "\n",
    "    Defects start at at starting point and end at an ending point. If two defects share any points then they are overlapping\n",
    "    and should be combined. Defects can span the start and end of the array, which makes combination difficult.\n",
    "    \"\"\"\n",
    "\n",
    "    # Flag to check if any defects have been combined\n",
    "    defects_were_combined = True\n",
    "    while defects_were_combined:\n",
    "        # Reset the flag\n",
    "        defects_were_combined = False\n",
    "        # For each defect, check if it overlaps with any other defect\n",
    "        for i, defect_0 in enumerate(defects):\n",
    "            for j, defect_1 in enumerate(defects):\n",
    "                if i != j:\n",
    "                    # Check if the defects overlap\n",
    "                    if len(np.intersect1d(defect_0[\"indexes\"], defect_1[\"indexes\"])) > 0:\n",
    "                        # Combine the defects\n",
    "                        combined_defect = combine_two_defects(defect_0, defect_1, len(angles_per_nm), angle_diffs)\n",
    "                        # Remove the old defects\n",
    "                        defects.pop(i)\n",
    "                        defects.pop(j - 1)\n",
    "                        # Add the new defect\n",
    "                        defects.append(combined_defect)\n",
    "                        # Set the flag\n",
    "                        defects_were_combined = True\n",
    "                        break\n",
    "            if defects_were_combined:\n",
    "                break\n",
    "\n",
    "    return defects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex defect detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting = True\n",
    "plot_results = False\n",
    "\n",
    "# Define what a defect is by any section that turns d degrees in n nm\n",
    "defect_degrees_value = 80\n",
    "defect_nm_value = 5.0\n",
    "# pasty_distance_deviation_threshold_nm = 3.0\n",
    "pasty_distance_deviation_threshold_percentage = 0.08\n",
    "\n",
    "turn_in_distance_grain_dict = {}\n",
    "\n",
    "for index, grain_data in angle_change_rate_grain_dict.items():\n",
    "    if index != 74:\n",
    "        continue\n",
    "\n",
    "    # print(f\"grain index: {index}\")\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "    trace = grain_data[\"trace\"]\n",
    "    pooled_trace = grain_data[\"pooled_trace\"]\n",
    "\n",
    "    # Check if the trace is clockwise or anticlockwise by summing the cross products of the vectors\n",
    "    pooled_trace = flip_if_anticlockwise(pooled_trace)\n",
    "\n",
    "    n = 1\n",
    "    pooled_trace_every_nth_point = pooled_trace[::n]\n",
    "    # Create a copy where the first point is appended to the end to calculate the distances between the last and first point\n",
    "    if np.array_equal(pooled_trace_every_nth_point[0], pooled_trace_every_nth_point[-1]):\n",
    "        pooled_trace_every_nth_point_extra_start = np.copy(pooled_trace_every_nth_point)\n",
    "        pooled_trace_every_nth_point = pooled_trace_every_nth_point[:-1]\n",
    "    else:\n",
    "        pooled_trace_every_nth_point_extra_start = np.copy(pooled_trace_every_nth_point)\n",
    "        pooled_trace_every_nth_point_extra_start = np.append(\n",
    "            pooled_trace_every_nth_point_extra_start, [pooled_trace_every_nth_point[0]], axis=0\n",
    "        )\n",
    "\n",
    "    distances_between_points = np.linalg.norm(np.diff(pooled_trace_every_nth_point_extra_start, axis=0), axis=1)\n",
    "    total_distance = np.sum(distances_between_points)\n",
    "\n",
    "    distances_between_points_nm = distances_between_points * p_to_nm\n",
    "    total_distance_nm = total_distance * p_to_nm\n",
    "\n",
    "    # print(f\"len of distances ends included: {len(distances_between_points)}, total distance: {total_distance_nm} nm\")\n",
    "\n",
    "    # print(f\"len of points: {len(pooled_trace_every_nth_point)}\")\n",
    "\n",
    "    # plt.plot(distances_between_points)\n",
    "    # plt.title(f\"Distances between pooled points for grain {index}\")\n",
    "    # plt.show()\n",
    "\n",
    "    angles_per_nm, angle_diffs = angle_per_nm(pooled_trace_every_nth_point, p_to_nm)\n",
    "\n",
    "    print(f\"total angle change: {np.degrees(np.sum(angle_diffs))}\")\n",
    "\n",
    "    # plt.plot(angle_diffs)\n",
    "    # plt.show()\n",
    "\n",
    "    # print(f\"angle diffs: {angle_diffs}\")\n",
    "\n",
    "    # Detect if at any point more than curve_degrees_value is turned in curve_nm_value\n",
    "    assert len(angles_per_nm) == len(distances_between_points)\n",
    "    assert len(angles_per_nm) == len(pooled_trace_every_nth_point)\n",
    "\n",
    "    in_defect = False\n",
    "    defects = []\n",
    "    maximum_total_angle_shift = 0\n",
    "    maximum_angle_shift_index = 0\n",
    "    for point_index, (point, angle_shift, distance) in enumerate(\n",
    "        zip(pooled_trace_every_nth_point, angles_per_nm, distances_between_points)\n",
    "    ):\n",
    "        print(f\"point index: {point_index}, angle shift: {angle_shift}, distance: {distance}\")\n",
    "\n",
    "        if plotting:\n",
    "            plt.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "            plt.scatter(pooled_trace_every_nth_point[:, 1], pooled_trace_every_nth_point[:, 0], c=\"k\", s=20)\n",
    "            plt.scatter(\n",
    "                pooled_trace_every_nth_point[point_index, 1],\n",
    "                pooled_trace_every_nth_point[point_index, 0],\n",
    "                c=\"white\",\n",
    "                s=40,\n",
    "            )\n",
    "\n",
    "        # Get window\n",
    "        window_start_index, window_end_index, window_distance = find_distance_window_looped(\n",
    "            distances_between_points_nm, defect_nm_value, point_index\n",
    "        )\n",
    "        # print(\n",
    "        #     f\"  window start index: {window_start_index}, window end index: {window_end_index}, window distance: {window_distance}\"\n",
    "        # )\n",
    "\n",
    "        if plotting:\n",
    "            plt.scatter(\n",
    "                pooled_trace_every_nth_point[window_start_index, 1],\n",
    "                pooled_trace_every_nth_point[window_start_index, 0],\n",
    "                c=\"b\",\n",
    "                s=20,\n",
    "            )\n",
    "            plt.scatter(\n",
    "                pooled_trace_every_nth_point[window_end_index, 1],\n",
    "                pooled_trace_every_nth_point[window_end_index, 0],\n",
    "                c=\"r\",\n",
    "                s=20,\n",
    "            )\n",
    "\n",
    "        # See if the angle shift is greater than the defect_degrees_value\n",
    "        # Calculate total angle change by summing the angle shifts in the window\n",
    "        total_angle_shift = 0\n",
    "        # End index might be lower than start index if the window wraps around\n",
    "        if window_end_index > window_start_index:\n",
    "            window_angle_shifts = angle_diffs[window_start_index : window_end_index + 1]\n",
    "        else:\n",
    "            window_angle_shifts = np.append(angle_diffs[window_start_index:], angle_diffs[: window_end_index + 1])\n",
    "            # print(f\"window end index: {window_end_index}, window start index: {window_start_index}, angle_diffs: {angle_diffs}\")\n",
    "\n",
    "        total_angle_shift = np.sum(window_angle_shifts)\n",
    "        # print(f\"total angle shift: {total_angle_shift} ({np.degrees(total_angle_shift)} degrees)\")\n",
    "\n",
    "        if np.abs(total_angle_shift) > np.radians(defect_degrees_value):\n",
    "            # print(\"window angle > defect_degrees_value\")\n",
    "            # print(f\"currently in defect: {in_defect}\")\n",
    "            if not in_defect:\n",
    "                # print(f\"@@@ DEFECT START at index: {point_index} window end index: {window_end_index}\")\n",
    "                if plotting:\n",
    "                    # Plot between start and end index following the pooled trace\n",
    "                    if window_end_index > window_start_index:\n",
    "                        plt.plot(\n",
    "                            pooled_trace_every_nth_point[window_start_index : window_end_index + 1, 1],\n",
    "                            pooled_trace_every_nth_point[window_start_index : window_end_index + 1, 0],\n",
    "                            \"g\",\n",
    "                        )\n",
    "                    else:\n",
    "                        plt.plot(\n",
    "                            np.append(\n",
    "                                pooled_trace_every_nth_point[window_start_index:, 1],\n",
    "                                pooled_trace_every_nth_point[: window_end_index + 1, 1],\n",
    "                            ),\n",
    "                            np.append(\n",
    "                                pooled_trace_every_nth_point[window_start_index:, 0],\n",
    "                                pooled_trace_every_nth_point[: window_end_index + 1, 0],\n",
    "                            ),\n",
    "                            \"g\",\n",
    "                        )\n",
    "                    plt.title(\n",
    "                        f\"defect start index: {point_index}, end index: {window_end_index}, window angle shifts: {window_angle_shifts} total angle shift: {total_angle_shift} ({np.degrees(total_angle_shift)} degrees)\"\n",
    "                    )\n",
    "                in_defect = True\n",
    "                defect_start_index = point_index\n",
    "                if window_end_index > window_start_index:\n",
    "                    defect_indexes = np.arange(window_start_index, window_end_index + 1)\n",
    "                else:\n",
    "                    defect_indexes = np.append(\n",
    "                        np.arange(window_start_index, len(angles_per_nm)), np.arange(0, window_end_index + 1)\n",
    "                    )\n",
    "                defect_shifts = window_angle_shifts\n",
    "                maximum_total_angle_shift = total_angle_shift\n",
    "\n",
    "                # print(f\"defect indexes: {defect_indexes}\")\n",
    "                # print(f\"defect shifts: {defect_shifts}\")\n",
    "                # print(\n",
    "                #     f\"initial total angle shift: {maximum_total_angle_shift} ({np.degrees(maximum_total_angle_shift)} degrees)\"\n",
    "                # )\n",
    "                maximum_angle_shift = np.max(window_angle_shifts)\n",
    "                maximum_angle_shift_index = window_start_index + np.argmax(window_angle_shifts)\n",
    "                if maximum_angle_shift_index >= len(angles_per_nm):\n",
    "                    maximum_angle_shift_index -= len(angles_per_nm)\n",
    "                # print(f\"starting defect, max shift: {maximum_angle_shift}, index: {maximum_angle_shift_index}\")\n",
    "            else:\n",
    "                # Add the new point(s) to the defect indexes. Note there may be more than one point added due to a high density of points in the window since we are sampling every n nm rather than n points\n",
    "                # Careful of the case where the window wraps around\n",
    "                if window_end_index > window_start_index:\n",
    "                    defect_indexes = np.append(defect_indexes, np.arange(window_start_index, window_end_index + 1))\n",
    "                else:\n",
    "                    defect_indexes = np.append(\n",
    "                        defect_indexes,\n",
    "                        np.append(\n",
    "                            np.arange(window_start_index, len(angles_per_nm)), np.arange(0, window_end_index + 1)\n",
    "                        ),\n",
    "                    )\n",
    "                # Ensure each index is unique\n",
    "                defect_indexes = np.unique(defect_indexes)\n",
    "                # Add the new angle shift to the defect shifts\n",
    "                defect_shifts = np.append(defect_shifts, angle_diffs[window_end_index])\n",
    "                # Check if the maximum angle shift is a new maximum\n",
    "                window_maximum = np.max(window_angle_shifts)\n",
    "                if window_maximum > maximum_angle_shift:\n",
    "                    maximum_angle_shift = window_maximum\n",
    "                    window_maximum_angle_shift_index = np.argmax(window_angle_shifts)\n",
    "                    maximum_angle_shift_index = window_start_index + window_maximum_angle_shift_index\n",
    "                    if maximum_angle_shift_index >= len(angles_per_nm):\n",
    "                        maximum_angle_shift_index -= len(angles_per_nm)\n",
    "                    # print(f\"window maximum is new maximum: {maximum_angle_shift} at index: {maximum_angle_shift_index}\")\n",
    "                # Check if the total angle shift is greater than the current maximum\n",
    "                if np.abs(total_angle_shift) > np.abs(maximum_total_angle_shift):\n",
    "                    maximum_total_angle_shift = total_angle_shift\n",
    "                    # Store the index of the maximum angle shift\n",
    "                    if window_end_index > window_start_index:\n",
    "                        maximum_total_angle_shift_index = window_start_index + np.argmax(window_angle_shifts)\n",
    "                    else:\n",
    "                        maximum_total_angle_shift_index = np.argmax(window_angle_shifts)\n",
    "                # Plot between start and end index following the pooled trace\n",
    "                if plotting:\n",
    "                    if window_end_index > window_start_index:\n",
    "                        plt.plot(\n",
    "                            pooled_trace_every_nth_point[window_start_index : window_end_index + 1, 1],\n",
    "                            pooled_trace_every_nth_point[window_start_index : window_end_index + 1, 0],\n",
    "                            \"g\",\n",
    "                        )\n",
    "                    else:\n",
    "                        plt.plot(\n",
    "                            np.append(\n",
    "                                pooled_trace_every_nth_point[window_start_index:, 1],\n",
    "                                pooled_trace_every_nth_point[: window_end_index + 1, 1],\n",
    "                            ),\n",
    "                            np.append(\n",
    "                                pooled_trace_every_nth_point[window_start_index:, 0],\n",
    "                                pooled_trace_every_nth_point[: window_end_index + 1, 0],\n",
    "                            ),\n",
    "                            \"g\",\n",
    "                        )\n",
    "                    plt.title(\n",
    "                        f\"defect start index: {defect_start_index}, end index: {window_end_index}, window angle shifts: {window_angle_shifts} max shift: {maximum_angle_shift}, index: {maximum_angle_shift_index} total angle shift: {total_angle_shift} ({np.degrees(total_angle_shift)} degrees)\"\n",
    "                    )\n",
    "            # print(f\"defect indexes: {defect_indexes}\")\n",
    "\n",
    "        else:\n",
    "            if plotting:\n",
    "                plt.title(\n",
    "                    f\"no defect at index: {point_index} window end index: {window_end_index} window angle shifts: {window_angle_shifts} total angle shift: {total_angle_shift} ({np.degrees(total_angle_shift)} degrees)\"\n",
    "                )\n",
    "            if in_defect:\n",
    "                in_defect = False\n",
    "                defect_end_index = window_end_index\n",
    "                # print(\n",
    "                #     f\"@@@ DEFECT DONE: start index: {defect_start_index}, end index: {defect_end_index}, window angle shifts: {window_angle_shifts} max shift: {maximum_angle_shift}, index: {maximum_angle_shift_index}\"\n",
    "                # )\n",
    "                # print(f\"defect indexes: {defect_indexes}\")\n",
    "                # print(f\"defect shifts: {defect_shifts}\")\n",
    "\n",
    "                weighted_mean_angle_shift_index, weighted_mean_angle_shift_index_int = weighted_mean_defect_position(\n",
    "                    defect_angle_shifts=defect_shifts,\n",
    "                    defect_start_index=defect_start_index,\n",
    "                    max_index=len(angles_per_nm),\n",
    "                )\n",
    "\n",
    "                defects.append(\n",
    "                    {\n",
    "                        \"start_index\": defect_start_index,\n",
    "                        \"end_index\": defect_end_index,\n",
    "                        \"maximum_total_angle_shift\": maximum_total_angle_shift,\n",
    "                        \"maximum_angle_shift\": maximum_angle_shift,\n",
    "                        \"maximum_angle_shift_index\": maximum_angle_shift_index,\n",
    "                        \"indexes\": defect_indexes,\n",
    "                        \"weighted_mean_angle_shift_index\": weighted_mean_angle_shift_index,\n",
    "                        \"weighted_mean_angle_shift_index_int\": weighted_mean_angle_shift_index_int,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    if in_defect:\n",
    "        in_defect = False\n",
    "        defect_end_index = window_end_index\n",
    "        # print(f\"@@@ DEFECT DONE: start index: {defect_start_index}, end index: {defect_end_index} max shift: {maximum_angle_shift}, index: {maximum_angle_shift_index}\")\n",
    "\n",
    "        weighted_mean_angle_shift_index, weighted_mean_angle_shift_index_int = weighted_mean_defect_position(\n",
    "            defect_angle_shifts=defect_shifts,\n",
    "            defect_start_index=defect_start_index,\n",
    "            max_index=len(angles_per_nm),\n",
    "        )\n",
    "        defects.append(\n",
    "            {\n",
    "                \"start_index\": defect_start_index,\n",
    "                \"end_index\": defect_end_index,\n",
    "                \"maximum_total_angle_shift\": maximum_total_angle_shift,\n",
    "                \"maximum_angle_shift\": maximum_angle_shift,\n",
    "                \"maximum_angle_shift_index\": maximum_angle_shift_index,\n",
    "                \"indexes\": defect_indexes,\n",
    "                \"weighted_mean_angle_shift_index\": weighted_mean_angle_shift_index,\n",
    "                \"weighted_mean_angle_shift_index_int\": weighted_mean_angle_shift_index_int,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Combine any overlapping regions\n",
    "    # for i, defect in enumerate(defects):\n",
    "    #     print(f\"defect {i}: {defect}\")\n",
    "\n",
    "    combined_defects = combine_overlapping_defects(defects)\n",
    "\n",
    "    # for i, defect in enumerate(combined_defects):\n",
    "    #     print(f\"combined defect {i}: {defect}\")\n",
    "\n",
    "    defects = combined_defects\n",
    "\n",
    "    if len(defects) > 0:\n",
    "        # For each defect's weighted mean angle shift index int, calculate the distance to the next defect's weighted mean angle shift index int\n",
    "        # Get a list of each defect's weighted mean angle shift index int\n",
    "        weighted_mean_angle_shift_indexes_int = [defect[\"weighted_mean_angle_shift_index_int\"] for defect in defects]\n",
    "        # Sort the list\n",
    "        weighted_mean_angle_shift_indexes_int.sort()\n",
    "        # print(f\"sorted weighted mean angle shift indexes int: {weighted_mean_angle_shift_indexes_int}\")\n",
    "        # Calculate the distances between each defect along the trace\n",
    "        to_find = np.copy(weighted_mean_angle_shift_indexes_int)\n",
    "        found_original = False\n",
    "        original = to_find[0]\n",
    "        current_index = original\n",
    "        current_position = pooled_trace_every_nth_point[current_index]\n",
    "        previous_position = current_position\n",
    "        distances = []\n",
    "        distance = 0\n",
    "        while len(to_find) > 0:\n",
    "            # Update old position\n",
    "            previous_position = current_position\n",
    "            # Increment the current position along the trace\n",
    "            current_index += 1\n",
    "            if current_index >= len(pooled_trace_every_nth_point):\n",
    "                current_index -= len(pooled_trace_every_nth_point)\n",
    "            current_position = pooled_trace_every_nth_point[current_index]\n",
    "\n",
    "            # Increment the distance\n",
    "            distance += np.linalg.norm(current_position - previous_position) * p_to_nm\n",
    "\n",
    "            # Check if the current index is in the to_find list\n",
    "            if current_index in to_find:\n",
    "                # Get rid of the current index from the to_find list\n",
    "                to_find = to_find[to_find != current_index]\n",
    "                # Store the distance\n",
    "                distances.append(distance)\n",
    "                # Reset the distance\n",
    "                distance = 0\n",
    "    else:\n",
    "        distances = []\n",
    "\n",
    "    # print(f\"distances between defects: {distances}\")\n",
    "\n",
    "    if plot_results:\n",
    "        fig, ax = plt.subplots(1, len(defects), figsize=(10 * len(defects), 10))\n",
    "        for defect_index, defect in enumerate(defects):\n",
    "            thisax = ax[defect_index]\n",
    "            # Plot the defect\n",
    "            thisax.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "            # Plot a horizontal line at the top left of the image starting at 10, 10 with a length equal to the nm distance threshold for defect\n",
    "            thisax.plot([2, 2 + defect_nm_value / p_to_nm], [2, 2], \"r\")\n",
    "            # Plot the points\n",
    "            thisax.scatter(pooled_trace_every_nth_point[:, 1], pooled_trace_every_nth_point[:, 0], c=\"k\", s=20)\n",
    "            # Plot the start point of the entire trace\n",
    "            thisax.scatter(pooled_trace_every_nth_point[0, 1], pooled_trace_every_nth_point[0, 0], c=\"pink\", s=60)\n",
    "            # Write the angle shift at each point\n",
    "            for i, point in enumerate(pooled_trace_every_nth_point):\n",
    "                thisax.text(\n",
    "                    point[1], point[0], f\"{int(np.round(np.degrees(angle_diffs[i])))}\", fontsize=14, color=\"white\"\n",
    "                )\n",
    "            # Plot the start and end index\n",
    "            thisax.scatter(\n",
    "                pooled_trace_every_nth_point[defect[\"start_index\"], 1],\n",
    "                pooled_trace_every_nth_point[defect[\"start_index\"], 0],\n",
    "                c=\"blue\",\n",
    "                s=60,\n",
    "                alpha=1,\n",
    "            )\n",
    "            thisax.scatter(\n",
    "                pooled_trace_every_nth_point[defect[\"end_index\"], 1],\n",
    "                pooled_trace_every_nth_point[defect[\"end_index\"], 0],\n",
    "                c=\"red\",\n",
    "                s=60,\n",
    "                alpha=1,\n",
    "            )\n",
    "            # Plot the maximum angle shift index\n",
    "            thisax.scatter(\n",
    "                pooled_trace_every_nth_point[defect[\"maximum_angle_shift_index\"], 1],\n",
    "                pooled_trace_every_nth_point[defect[\"maximum_angle_shift_index\"], 0],\n",
    "                c=\"green\",\n",
    "                s=100,\n",
    "                alpha=1,\n",
    "            )\n",
    "            # Plot the weighted mean angle shift index\n",
    "            thisax.scatter(\n",
    "                pooled_trace_every_nth_point[defect[\"weighted_mean_angle_shift_index_int\"], 1],\n",
    "                pooled_trace_every_nth_point[defect[\"weighted_mean_angle_shift_index_int\"], 0],\n",
    "                c=\"yellow\",\n",
    "                s=100,\n",
    "                alpha=1,\n",
    "            )\n",
    "\n",
    "            # Plot a line between the start and end index following the pooled trace\n",
    "            if defect[\"end_index\"] > defect[\"start_index\"]:\n",
    "                thisax.plot(\n",
    "                    pooled_trace_every_nth_point[defect[\"start_index\"] : defect[\"end_index\"] + 1, 1],\n",
    "                    pooled_trace_every_nth_point[defect[\"start_index\"] : defect[\"end_index\"] + 1, 0],\n",
    "                    \"b\",\n",
    "                )\n",
    "            else:\n",
    "                thisax.plot(\n",
    "                    np.append(\n",
    "                        pooled_trace_every_nth_point[defect[\"start_index\"] :, 1],\n",
    "                        pooled_trace_every_nth_point[: defect[\"end_index\"] + 1, 1],\n",
    "                    ),\n",
    "                    np.append(\n",
    "                        pooled_trace_every_nth_point[defect[\"start_index\"] :, 0],\n",
    "                        pooled_trace_every_nth_point[: defect[\"end_index\"] + 1, 0],\n",
    "                    ),\n",
    "                    \"b\",\n",
    "                )\n",
    "\n",
    "        plt.suptitle(\n",
    "            f\"Defects {len(defects)} for grain {index}, total distance: {total_distance_nm:.2f} nm, defect degrees: {defect_degrees_value}, defect nm: {defect_nm_value}, p_to_nm: {p_to_nm:.2f}\"\n",
    "        )\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Classification\n",
    "    # If there are 3 defects then it is a dorito\n",
    "    # If there are 2 defects then it is either a churro or pasty\n",
    "    # If the two defects have significantly different distances then it's a pasty, else it's a churro\n",
    "    # If it has fewer than 2 or more than 3, then it is unclassified\n",
    "\n",
    "    if len(defects) == 3:\n",
    "        tag = \"dorito\"\n",
    "    elif len(defects) == 2:\n",
    "        abs_diff_distance = np.abs(distances[0] - distances[1])\n",
    "        # print(f\"index : {index} abs diff distance: {abs_diff_distance} total distance: {total_distance_nm} pasty threshold: {pasty_distance_deviation_threshold_percentage * total_distance_nm}\")\n",
    "        if abs_diff_distance > pasty_distance_deviation_threshold_percentage * total_distance_nm:\n",
    "            tag = \"pasty\"\n",
    "        else:\n",
    "            tag = \"churro\"\n",
    "    elif len(defects) == 1:\n",
    "        tag = \"teardrop\"\n",
    "    else:\n",
    "        tag = \"open\"\n",
    "\n",
    "    turn_in_distance_grain_dict[index] = grain_data\n",
    "    turn_in_distance_grain_dict[index][\"complex_defects\"] = defects\n",
    "    turn_in_distance_grain_dict[index][\"complex_distances_between_defects\"] = distances\n",
    "    turn_in_distance_grain_dict[index][\"complex_tag\"] = tag\n",
    "    turn_in_distance_grain_dict[index][\"total_distance\"] = total_distance_nm\n",
    "    turn_in_distance_grain_dict[index][\"complex_num_defects\"] = len(defects)\n",
    "    turn_in_distance_grain_dict[index][\"distances_between_points\"] = distances_between_points\n",
    "    turn_in_distance_grain_dict[index][\"complex_angles_per_nm\"] = angles_per_nm\n",
    "\n",
    "\n",
    "def plot_images(\n",
    "    images: list,\n",
    "    tags: list,\n",
    "    traces: list,\n",
    "    grain_indexes: list,\n",
    "    defects: list,\n",
    "    distances_between_defects: list,\n",
    "    feret_ratios: list,\n",
    "    area_perimeter_ratios: list,\n",
    "    px_to_nms: list,\n",
    "    width=5,\n",
    "    cmap=cmap,\n",
    "    vmin=-8,\n",
    "    vmax=8,\n",
    "):\n",
    "    num_images = len(images)\n",
    "    rows = np.ceil(num_images / width).astype(int)\n",
    "    fig, ax = plt.subplots(rows, width, figsize=(30, 50))\n",
    "    for i, (\n",
    "        image,\n",
    "        tag,\n",
    "        grain_index,\n",
    "        trace,\n",
    "        defect_dict,\n",
    "        defect_distances,\n",
    "        feret_ratio,\n",
    "        area_perimeter_ratio,\n",
    "    ) in enumerate(\n",
    "        zip(\n",
    "            images, tags, grain_indexes, traces, defects, distances_between_defects, feret_ratios, area_perimeter_ratios\n",
    "        )\n",
    "    ):\n",
    "        if rows == 1:\n",
    "            thisax = ax[i]\n",
    "        else:\n",
    "            thisax = ax[i // width, i % width]\n",
    "        thisax.imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        thisax.axis(\"off\")\n",
    "        distances_between_defects_string = \", \".join([f\"{distance:.2f}\" for distance in defect_distances])\n",
    "        thisax.set_title(\n",
    "            f\"index: {grain_index} tag: {tag} p_to_nm: {px_to_nms[i]:.2f}\\n defect distances: {distances_between_defects_string} total distance: {np.sum(defect_distances):.2f} nm \\n feret ratio: {feret_ratio:.2f} area perimeter ratio: {area_perimeter_ratio:.2f}\"\n",
    "        )\n",
    "        thisax.plot(trace[:, 1], trace[:, 0], \"green\")\n",
    "        for defect_index, defect in enumerate(defect_dict):\n",
    "            thisax.scatter(\n",
    "                trace[defect[\"weighted_mean_angle_shift_index_int\"]][1],\n",
    "                trace[defect[\"weighted_mean_angle_shift_index_int\"]][0],\n",
    "                c=\"white\",\n",
    "            )\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_images(\n",
    "#     [turn_in_distance_grain_dict[i][\"image\"] for i in turn_in_distance_grain_dict],\n",
    "#     [turn_in_distance_grain_dict[i][\"tag\"] for i in turn_in_distance_grain_dict],\n",
    "#     [i for i in turn_in_distance_grain_dict],\n",
    "#     [turn_in_distance_grain_dict[i][\"p_to_nm\"] for i in turn_in_distance_grain_dict],\n",
    "# )\n",
    "\n",
    "for tag_to_plot in [\"churro\", \"pasty\", \"dorito\", \"teardrop\", \"open\"]:\n",
    "    indexes = [i for i in turn_in_distance_grain_dict if turn_in_distance_grain_dict[i][\"complex_tag\"] == tag_to_plot]\n",
    "    print(tag_to_plot, indexes)\n",
    "    if len(indexes) > 0:\n",
    "        plot_images(\n",
    "            [turn_in_distance_grain_dict[i][\"image\"] for i in indexes],\n",
    "            [turn_in_distance_grain_dict[i][\"complex_tag\"] for i in indexes],\n",
    "            [turn_in_distance_grain_dict[i][\"pooled_trace\"] for i in indexes],\n",
    "            [i for i in indexes],\n",
    "            [turn_in_distance_grain_dict[i][\"complex_defects\"] for i in indexes],\n",
    "            [turn_in_distance_grain_dict[i][\"complex_distances_between_defects\"] for i in indexes],\n",
    "            [turn_in_distance_grain_dict[i][\"feret_ratio\"] for i in indexes],\n",
    "            [turn_in_distance_grain_dict[i][\"perimeter_area_ratio\"] for i in indexes],\n",
    "            [turn_in_distance_grain_dict[i][\"p_to_nm\"] for i in indexes],\n",
    "        )\n",
    "\n",
    "# Plot bar chart of tags\n",
    "tags = [turn_in_distance_grain_dict[i][\"complex_tag\"] for i in turn_in_distance_grain_dict]\n",
    "unique_tags = [\"churro\", \"pasty\", \"dorito\", \"teardrop\", \"open\"]\n",
    "counts = [tags.count(tag) for tag in unique_tags]\n",
    "plt.bar(unique_tags, counts)\n",
    "plt.title(f\"(Turn in distance based) distribution for {SAMPLE_TYPE}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.optimize import minimize\n",
    "\n",
    "# def circularness(points: np.ndarray, initial_radius: float):\n",
    "#     \"\"\"Measure how circular a set of points are by fitting a circle to the points and measuring the residuals and return\n",
    "#     the center and radius of the circle along with the circularness metric which is the mean distance of the points from\n",
    "#     the circle divided by the radius of the circle.\n",
    "#     \"\"\"\n",
    "\n",
    "#     x0 = [np.mean(points[:, 0]), np.mean(points[:, 1]), initial_radius]\n",
    "\n",
    "#     def objective(x):\n",
    "#         # Objective function to minimize, x[0] is the x coordinate of the center, x[1] is the y coordinate of the center, x[2] is the radius\n",
    "#         # The sum of squared distances of the points from the circle\n",
    "#         return np.sum((np.sqrt((points[:, 0] - x[0])**2 + (points[:, 1] - x[1])**2) - x[2])**2)\n",
    "\n",
    "#     # Minimize the objective function\n",
    "#     res = minimize(objective, x0, method=\"nelder-mead\")\n",
    "\n",
    "#     centre_x = res.x[0]\n",
    "#     centre_y = res.x[1]\n",
    "#     radius = res.x[2]\n",
    "\n",
    "#     # squared residuals\n",
    "#     squared_residuals = (np.sqrt((points[:, 0] - centre_x)**2 + (points[:, 1] - centre_y)**2) - radius)**2\n",
    "#     sum_squared_residuals = np.sum(squared_residuals)\n",
    "#     print(f\"sum squared residuals: {sum_squared_residuals}\")\n",
    "#     # circularness metric\n",
    "#     circularness_metric = np.mean(squared_residuals)\n",
    "\n",
    "#     return centre_x, centre_y, radius, circularness_metric\n",
    "\n",
    "\n",
    "# # Test the circularness function using a circle\n",
    "# # Create a circle\n",
    "# theta = np.linspace(0, 2 * np.pi, 100)\n",
    "# radius = 100\n",
    "# center_x = 200\n",
    "# center_y = 200\n",
    "# circle_x = center_x + radius * np.cos(theta)\n",
    "# circle_y = center_y + radius * np.sin(theta)\n",
    "\n",
    "# # Add noise to the circle\n",
    "# circle_x += np.random.normal(0, 10, len(circle_x))\n",
    "# circle_y += np.random.normal(0, 10, len(circle_y))\n",
    "\n",
    "# # plot the circile\n",
    "# plt.scatter(circle_x, circle_y)\n",
    "# plt.show()\n",
    "\n",
    "# # Fit a circle to the points\n",
    "# center_x, center_y, radius, circularness_metric = circularness(np.array([circle_x, circle_y]).T, initial_radius=radius)\n",
    "# print(f\"center_x: {center_x:.2f}, center_y: {center_y:.2f}, radius: {radius:.2f}, circularness_metric: {circularness_metric}\")\n",
    "\n",
    "# # plot the circle\n",
    "# plt.scatter(circle_x, circle_y)\n",
    "# plt.scatter(center_x, center_y, c=\"red\")\n",
    "# plt.plot(center_x + radius * np.cos(theta), center_y + radius * np.sin(theta))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "import pickle\n",
    "\n",
    "filename = f\"{SAMPLE_TYPE}_turn_in_distance_grain_dict.pkl\"\n",
    "\n",
    "with open(SAVE_DIR / filename, \"wb\") as f:\n",
    "    pickle.dump(turn_in_distance_grain_dict, f)\n",
    "\n",
    "print(f\"saved {filename} to {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvature analysis\n",
    "from scipy.interpolate import splprep, splev, UnivariateSpline\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "def plot_colour_line_2d_based_on_value_on_axis(ax: plt.Axes, points: np.ndarray, values: np.ndarray, cmap=\"viridis_r\"):\n",
    "    # Get colours based on the value of the points\n",
    "    normalised_values = (values - values.min()) / (values.max() - values.min())\n",
    "    for i in range(len(points) - 1):\n",
    "        ax.plot(points[i : i + 2, 0], points[i : i + 2, 1], color=plt.cm.get_cmap(cmap)(normalised_values[i]))\n",
    "\n",
    "\n",
    "def plot_colour_line_1d_based_on_value_on_axis(\n",
    "    ax: plt.Axes, values: np.ndarray, hline: Union[None, float] = None, cmap=\"viridis_r\"\n",
    "):\n",
    "    # Get colours based on the value of the points\n",
    "    normalised_values = (values - values.min()) / (values.max() - values.min())\n",
    "    xs = np.arange(len(values))\n",
    "    for i in range(len(values) - 1):\n",
    "        ax.plot(xs[i : i + 2], values[i : i + 2], color=plt.cm.get_cmap(cmap)(normalised_values[i]))\n",
    "    if hline is not None:\n",
    "        ax.axhline(hline, color=\"k\", linestyle=\"-\")\n",
    "\n",
    "\n",
    "def interpolate_points_spline(points: np.ndarray, num_points: Union[int, None] = None, smoothing: float = 0.0):\n",
    "    \"\"\"Interpolate a set of points using a spline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points: np.ndarray\n",
    "        Nx2 Numpy array of coordinates for the points.\n",
    "    num_points: int\n",
    "        The number of points to return following the calculated spline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    interpolated_points: np.ndarray\n",
    "        An Ix2 Numpy array of coordinates of the interpolated points, where I is the number of points\n",
    "        specified.\n",
    "    \"\"\"\n",
    "\n",
    "    if num_points is None:\n",
    "        num_points = points.shape[0]\n",
    "\n",
    "    x, y = splprep(points.T, u=None, s=smoothing, per=1)\n",
    "    x_spline = np.linspace(y.min(), y.max(), num_points)\n",
    "    x_new, y_new = splev(x_spline, x, der=0)\n",
    "    interpolated_points = np.array((x_new, y_new)).T\n",
    "    return interpolated_points\n",
    "\n",
    "\n",
    "def calculate_curvature_from_points(x_points, y_points, error=0.1, k=4):\n",
    "    \"\"\"Calculate the curvature for a set of points\"\"\"\n",
    "    # Check that the number of points is the same for both x and y\n",
    "    if x_points.shape[0] != y_points.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"x_points and y_points must have the same number of points. x_points has {x_points.shape[0]} points and y_points has {y_points.shape[0]} points.\"\n",
    "        )\n",
    "\n",
    "    # Weight the values so less weight is given to points with higher error\n",
    "    # K is the order of the spline to use. Increasing this increases the smoothness of the spline. A\n",
    "    # value of 1 is linear interpolation, 2 is quadratic, 3 is cubic, etc. 4 is used to ensure the\n",
    "    # spline is smooth enough to differentiate to the second derivative.\n",
    "    # t is the independent variable that monotically increases with the data, similar to how\n",
    "    # we use a dummy x variable in plotting calculations.\n",
    "\n",
    "    t = np.arange(x_points.shape[0])\n",
    "    weight_values = 1 / np.sqrt(error * np.ones_like(x_points))\n",
    "    fx = UnivariateSpline(t, x_points, k=k, w=weight_values)\n",
    "    fy = UnivariateSpline(t, y_points, k=k, w=weight_values)\n",
    "\n",
    "    spline_x = fx(t)\n",
    "    spline_y = fy(t)\n",
    "\n",
    "    dx = fx.derivative(1)(t)\n",
    "    dx2 = fx.derivative(2)(t)\n",
    "    dy = fy.derivative(1)(t)\n",
    "    dy2 = fy.derivative(2)(t)\n",
    "    curvatures = (dx * dy2 - dy * dx2) / np.power(dx**2 + dy**2, 3 / 2)\n",
    "    return curvatures, spline_x, spline_y\n",
    "\n",
    "\n",
    "def calculate_curvature_periodic_boundary(x_points, y_points, error=0.1, periods=2, k=4):\n",
    "    \"\"\"Take a set of points that form a loop and calculate the curvature. Uses periodic boundary conditions, so\n",
    "    the first and last points are connected. This reduces the error in the curvature calculation at the\n",
    "    boundaries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_points: np.ndarray\n",
    "        1D numpy array of x coordinates of the points.\n",
    "    y_points: np.ndarray\n",
    "        1D numpy array of y coordinates of the points.\n",
    "    error: float\n",
    "        Error in the points. Used to weight the points in the spline calculation.\n",
    "    periods: int\n",
    "        Number of times to repeat the points either side of the original points to reduce the error at the\n",
    "        boundaries.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    curvature: np.ndarray\n",
    "        1D numpy array of the curvature for each point.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that the number of points is the same for both x and y\n",
    "    if x_points.shape[0] != y_points.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"x_points and y_points must have the same number of points. x_points has\"\n",
    "            f\" {x_points.shape[0]} points and y_points has {y_points.shape[0]} points.\"\n",
    "        )\n",
    "\n",
    "    # Repeat the points either side of the original points to reduce the error at the boundaries\n",
    "    extended_points_x = np.copy(x_points)\n",
    "    extended_points_y = np.copy(y_points)\n",
    "    for i in range(periods * 2):\n",
    "        extended_points_x = np.append(extended_points_x, x_points)\n",
    "        extended_points_y = np.append(extended_points_y, y_points)\n",
    "\n",
    "    # Calculate the curvature\n",
    "    extended_curvature, spline_x, spline_y = calculate_curvature_from_points(\n",
    "        extended_points_x, extended_points_y, error=error, k=k\n",
    "    )\n",
    "\n",
    "    # Return only the original points\n",
    "    return (\n",
    "        extended_curvature[x_points.shape[0] * int(periods / 2) : x_points.shape[0] * int((periods / 2) + 1)],\n",
    "        spline_x[x_points.shape[0] * int(periods / 2) : x_points.shape[0] * int((periods / 2) + 1)],\n",
    "        spline_y[x_points.shape[0] * int(periods / 2) : x_points.shape[0] * int((periods / 2) + 1)],\n",
    "    )\n",
    "\n",
    "\n",
    "def turn_path_into_pixel_map(array: np.ndarray):\n",
    "    # Convert the spline to a pixelated trace 1 pixel thick\n",
    "\n",
    "    # Create a map of pixels\n",
    "    pixel_map = np.zeros((int(np.max(array) + 1), int(np.max(array) + 1)), dtype=int)\n",
    "    pixelated_path = np.empty((0, 2), dtype=int)\n",
    "\n",
    "    def check_is_touching(coordinate, original_coordinate):\n",
    "        if np.abs(coordinate[0] - original_coordinate[0]) <= 1 and np.abs(coordinate[1] - original_coordinate[1]) <= 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # Convert the array to integers and remove duplicates\n",
    "    integer_array = np.array(array, dtype=int)\n",
    "    removed_duplicates = []\n",
    "    for index in range(len(integer_array)):\n",
    "        coordinate = integer_array[index]\n",
    "        if index > 0:\n",
    "            if np.array_equal(coordinate, integer_array[index - 1]):\n",
    "                # print(f\"coordinate {coordinate} is a repeat of {integer_array[index - 1]}, skipping\")\n",
    "                continue\n",
    "\n",
    "        removed_duplicates.append(coordinate)\n",
    "    integer_array = np.array(removed_duplicates)\n",
    "\n",
    "    last_coordinate = None\n",
    "    for index in range(len(integer_array)):\n",
    "        coordinate = integer_array[index]\n",
    "\n",
    "        # If the coordinate is a repeat, skip it\n",
    "        if index > 0:\n",
    "            if np.array_equal(coordinate, integer_array[index - 1]):\n",
    "                # print(\n",
    "                #     f\"coordinate {coordinate} is a repeat of {integer_array[index - 1]}, skipping\"\n",
    "                # )\n",
    "                continue\n",
    "\n",
    "        # print(f\"coordinate: {coordinate}\")\n",
    "        if index == 0:\n",
    "            pixel_map[coordinate[0], coordinate[1]] = 1\n",
    "            last_coordinate = coordinate\n",
    "        elif index == len(integer_array) - 1:\n",
    "            pixel_map[coordinate[0], coordinate[1]] = 1\n",
    "            last_coordinate = coordinate\n",
    "            break\n",
    "        else:\n",
    "            # Check if the coordinate after this one is touching the coordinate before this one\n",
    "            # and if so, skip this pixel\n",
    "            if check_is_touching(integer_array[index + 1], last_coordinate):\n",
    "                # print(f\"coordinate {integer_array[index + 1]} is touching {last_coordinate}\")\n",
    "                continue\n",
    "            else:\n",
    "                # print(\n",
    "                #     f\"coordinate {integer_array[index+1]} is not touching {integer_array[index - 1]}. Adding to map\"\n",
    "                # )\n",
    "\n",
    "                # Add the coordinate to the pixel map and the pixelated path\n",
    "                pixel_map[int(coordinate[0]), int(coordinate[1])] = 1\n",
    "                pixelated_path = np.vstack((pixelated_path, coordinate.reshape(1, 2)))\n",
    "                last_coordinate = coordinate\n",
    "\n",
    "    return pixel_map, pixelated_path\n",
    "\n",
    "\n",
    "def defect_stats(height_trace: np.ndarray, threshold: float):\n",
    "    regions = []\n",
    "    in_region = False\n",
    "    # Find the largest continuous region below the threshold\n",
    "    for index, value in enumerate(height_trace):\n",
    "        if value < threshold:\n",
    "            # print(f\"index {index} is below threshold: {height_trace[index]}\")\n",
    "            if not in_region:\n",
    "                # Start region\n",
    "                region_start = index\n",
    "                area = 0\n",
    "                deepest_point = value\n",
    "                deepest_point_index = index\n",
    "                in_region = True\n",
    "            else:\n",
    "                # print(f\"value {height_trace[index]} is below threshold {threshold} by {threshold - height_trace[index]}\")\n",
    "                area += threshold - value\n",
    "                if value < deepest_point:\n",
    "                    deepest_point = value\n",
    "                    deepest_point_index = index\n",
    "        elif in_region:\n",
    "            regions.append(\n",
    "                {\n",
    "                    \"start\": region_start,\n",
    "                    \"end\": index,\n",
    "                    \"area\": area,\n",
    "                    \"deepest_point_index\": deepest_point_index,\n",
    "                    \"defect_threshold\": threshold,\n",
    "                }\n",
    "            )\n",
    "            in_region = False\n",
    "\n",
    "    # Number of defects\n",
    "    number_of_defects = len(regions)\n",
    "\n",
    "    # Find the largest region\n",
    "    largest_region_below_threshold = None\n",
    "    largest_area = 0\n",
    "    for region in regions:\n",
    "        if region[\"area\"] > largest_area:\n",
    "            largest_area = region[\"area\"]\n",
    "            largest_region_below_threshold = region\n",
    "\n",
    "    return {\n",
    "        \"defect_number\": number_of_defects,\n",
    "        \"defect_largest_region\": largest_region_below_threshold,\n",
    "        \"defect_regions\": regions,\n",
    "    }\n",
    "\n",
    "\n",
    "plotting = True\n",
    "stop_plotting_after = 70\n",
    "curvature_grain_dict = {}\n",
    "\n",
    "for index, grain_data in pooled_curvature_grain_dict.items():\n",
    "    grain_image = grain_data[\"image\"]\n",
    "    grain_mask = grain_data[\"mask\"]\n",
    "    p_to_nm = grain_data[\"p_to_nm\"]\n",
    "    trace = grain_data[\"trace\"]\n",
    "    pooled_trace = grain_data[\"pooled_trace\"]\n",
    "    height_trace = grain_data[\"height_trace\"]\n",
    "\n",
    "    interpolated_points = interpolate_points_spline(pooled_trace, num_points=200, smoothing=0.0)\n",
    "\n",
    "    # Error is the error in the points. Used to weight the points in the spline calculation.\n",
    "    # Low error means the spline will pass through the points, high error means the spline will\n",
    "    # be smooth and not pass through the points.\n",
    "\n",
    "    # Increase smoothing (error) in images that are higher resolution ie lower pixel to nm ratio\n",
    "    error = 0.01 / p_to_nm\n",
    "\n",
    "    curvature, spline_x, spline_y = calculate_curvature_periodic_boundary(\n",
    "        interpolated_points[:, 1], interpolated_points[:, 0], error=error, periods=2, k=5\n",
    "    )\n",
    "\n",
    "    curvature = -curvature\n",
    "\n",
    "    spline_points = np.array((spline_x, spline_y)).T\n",
    "\n",
    "    # Get pixel spline trace\n",
    "    spline_pixel_trace_img, spline_pixelated_path = turn_path_into_pixel_map(spline_points)\n",
    "\n",
    "    # Get the height trace from the spline pixelated path\n",
    "    spline_pixelated_path_heights = grain_image[spline_pixelated_path[:, 1], spline_pixelated_path[:, 0]]\n",
    "\n",
    "    defect_stats_dict = defect_stats(curvature, threshold=-0.1)\n",
    "\n",
    "    if plotting:\n",
    "        if index < stop_plotting_after:\n",
    "            # Plot scatter with colour as curvature\n",
    "            # fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            gs = gridspec.GridSpec(5, 2, figure=fig)\n",
    "\n",
    "            ax0 = fig.add_subplot(gs[0, 0])\n",
    "            ax1 = fig.add_subplot(gs[0, 1])\n",
    "            ax2 = fig.add_subplot(gs[1, 0])\n",
    "            ax3 = fig.add_subplot(gs[1, 1])\n",
    "            ax4 = fig.add_subplot(gs[2, 0])\n",
    "            ax5 = fig.add_subplot(gs[2, 1])\n",
    "            ax6 = fig.add_subplot(gs[3, :])\n",
    "            ax7 = fig.add_subplot(gs[4, :])\n",
    "\n",
    "            ax0.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "            ax0.set_title(\"Grain Image\")\n",
    "            ax1.imshow(grain_mask, cmap=\"gray\")\n",
    "            ax1.set_title(\"Grain Mask\")\n",
    "\n",
    "            ax2.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "            ax2.plot(trace[:, 1], trace[:, 0], \"r\")\n",
    "            ax2.plot(pooled_trace[:, 1], pooled_trace[:, 0], \"b\")\n",
    "            ax2.legend([\"Trace\", \"Pooled Trace\"])\n",
    "            ax2.set_title(\"Pixelated Path\")\n",
    "            ax3.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "            # Plot spline pixelated path including the first point to close the loop\n",
    "            ax3.plot(\n",
    "                np.append(spline_pixelated_path[:, 0], spline_pixelated_path[0, 0]),\n",
    "                np.append(spline_pixelated_path[:, 1], spline_pixelated_path[0, 1]),\n",
    "                \"r\",\n",
    "            )\n",
    "            ax3.set_title(\"Spline Pixel Path\")\n",
    "            ax4.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "            plot_colour_line_2d_based_on_value_on_axis(ax4, spline_points, curvature)\n",
    "            ax4.set_title(\"Spline Path with Curvature\")\n",
    "            # Plot spline pixelated trace heights overlaid on the grain image\n",
    "            ax5.imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "            plot_colour_line_2d_based_on_value_on_axis(ax5, spline_pixelated_path, spline_pixelated_path_heights)\n",
    "            ax5.set_title(\"Spline Pixellated Path with Heights\")\n",
    "            plot_colour_line_1d_based_on_value_on_axis(ax6, curvature, hline=0)\n",
    "            ax6.set_title(\"Curvature\")\n",
    "            ax6.set_ylim(-0.5, 0.5)\n",
    "            # Add red regions over defects\n",
    "            for region in defect_stats_dict[\"defect_regions\"]:\n",
    "                ax6.axvspan(region[\"start\"], region[\"end\"], color=\"r\", alpha=0.5)\n",
    "            # Add a black line at the deepest point of the largest defect\n",
    "            # But only if there are defects\n",
    "            if defect_stats_dict[\"defect_number\"] > 0:\n",
    "                ax6.axvline(\n",
    "                    defect_stats_dict[\"defect_largest_region\"][\"deepest_point_index\"],\n",
    "                    color=\"k\",\n",
    "                    linestyle=\"--\",\n",
    "                    alpha=0.5,\n",
    "                )\n",
    "            plot_colour_line_1d_based_on_value_on_axis(ax7, spline_pixelated_path_heights)\n",
    "            ax7.set_ylim(0.0, 4.0)\n",
    "            ax7.set_title(\"Spline Pixellated Path Heights\")\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    curvature_grain_dict[index] = {\n",
    "        \"image\": grain_image,\n",
    "        \"mask\": grain_mask,\n",
    "        \"trace\": trace,\n",
    "        \"height_trace\": height_trace,\n",
    "        \"spline_points\": spline_points,\n",
    "        \"curvature\": curvature,\n",
    "        \"num_curvature_defects\": defect_stats_dict[\"defect_number\"],\n",
    "        \"p_to_nm\": p_to_nm,\n",
    "    }\n",
    "\n",
    "# Plot kde of number of defects\n",
    "num_defects = [curvature_grain_dict[i][\"num_curvature_defects\"] for i in curvature_grain_dict]\n",
    "sns.kdeplot(num_defects)\n",
    "plt.xlabel(\"Number of defects\")\n",
    "plt.title(f\"Number of defects for {SAMPLE_TYPE} {len(num_defects)} grains\")\n",
    "plt.show()\n",
    "\n",
    "# Plot bar chart of number of defects\n",
    "from collections import Counter\n",
    "\n",
    "num_defects_counter = Counter(num_defects)\n",
    "plt.bar(num_defects_counter.keys(), num_defects_counter.values())\n",
    "plt.xlabel(\"Number of defects\")\n",
    "plt.ylabel(\"Number of grains\")\n",
    "plt.title(f\"Number of defects for {SAMPLE_TYPE} {len(num_defects)} grains\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot trace length in nm\n",
    "trace_lengths = [\n",
    "    len(curvature_grain_dict[i][\"trace\"]) * curvature_grain_dict[i][\"p_to_nm\"] for i in curvature_grain_dict\n",
    "]\n",
    "sns.kdeplot(trace_lengths)\n",
    "plt.xlabel(\"Trace length (nm)\")\n",
    "plt.title(f\"Trace length for {SAMPLE_TYPE} {len(trace_lengths)} grains n={len(trace_lengths)}\")\n",
    "plt.xlim(0, np.max(trace_lengths) * 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling grains for CNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually label each image with a tag. Either churro, dorito, or pasty\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "\n",
    "# Load each image sequentially, wait for user input to tag the image\n",
    "tagged_grain_dict = {}\n",
    "\n",
    "TAGGED_GRAINS_FILENAME = f\"{SAMPLE_TYPE}_tagged_grains.pkl\"\n",
    "\n",
    "ALREADY_LABELLED = True\n",
    "LABELLED_DICTIONARY_PATH = Path(\n",
    "    f\"/Users/sylvi/topo_data/hariborings/dna_manual_tags/{SAMPLE_TYPE}/{TAGGED_GRAINS_FILENAME}\"\n",
    ")\n",
    "\n",
    "if ALREADY_LABELLED:\n",
    "    # Load the already labelled dictionary\n",
    "    with open(LABELLED_DICTIONARY_PATH, \"rb\") as f:\n",
    "        tagged_grain_dict = pickle.load(f)\n",
    "else:\n",
    "    # Manually label the grains\n",
    "    for index, grain_data in curvature_grain_dict.items():\n",
    "        grain_image = grain_data[\"image\"]\n",
    "        grain_mask = grain_data[\"mask\"]\n",
    "        trace = grain_data[\"trace\"]\n",
    "        height_trace = grain_data[\"height_trace\"]\n",
    "        p_to_nm = grain_data[\"p_to_nm\"]\n",
    "        curvature = grain_data[\"curvature\"]\n",
    "        num_curvature_defects = grain_data[\"num_curvature_defects\"]\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        ax[0].imshow(grain_image, cmap=cmap, vmin=-8, vmax=8)\n",
    "        ax[0].set_title(f\"Grain {index} - {SAMPLE_TYPE}\")\n",
    "        ax[1].plot(curvature)\n",
    "        ax[1].set_title(f\"Curvature - {num_curvature_defects} defects\")\n",
    "        plt.show()\n",
    "\n",
    "        if not ALREADY_LABELLED:\n",
    "            tag_chosen = False\n",
    "            while not tag_chosen:\n",
    "                tag = input(f\"Tag grain {index} - {SAMPLE_TYPE} as churro, dorito, pasty or teardrop: \")\n",
    "                if tag == \"1\":\n",
    "                    tag = \"churro\"\n",
    "                    tag_chosen = True\n",
    "                elif tag == \"2\":\n",
    "                    tag = \"dorito\"\n",
    "                    tag_chosen = True\n",
    "                elif tag == \"3\":\n",
    "                    tag = \"pasty\"\n",
    "                    tag_chosen = True\n",
    "                elif tag == \"4\":\n",
    "                    tag = \"teardrop\"\n",
    "                    tag_chosen = True\n",
    "                elif tag == \"exit\":\n",
    "                    raise ValueError(\"Exiting\")\n",
    "\n",
    "            tagged_grain_dict[index] = {\n",
    "                \"image\": grain_image,\n",
    "                \"mask\": grain_mask,\n",
    "                \"trace\": trace,\n",
    "                \"height_trace\": height_trace,\n",
    "                \"curvature\": curvature,\n",
    "                \"num_curvature_defects\": num_curvature_defects,\n",
    "                \"p_to_nm\": p_to_nm,\n",
    "                \"tag\": tag,\n",
    "            }\n",
    "\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tagged grains, plotting them in grids\n",
    "\n",
    "\n",
    "def plot_images(images: list, masks: list, px_to_nms: list, grain_indexes: list, width=5, cmap=cmap, vmin=-8, vmax=8):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 2, figsize=(30, 30))\n",
    "    for i, (image, mask, grain_index) in enumerate(zip(images, masks, grain_indexes)):\n",
    "        ax[i // width, i % width * 2].imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax[i // width, i % width * 2].axis(\"off\")\n",
    "        ax[i // width, i % width * 2 + 1].imshow(mask, cmap=\"binary\")\n",
    "        ax[i // width, i % width * 2].set_title(f\"grain index: {grain_index} p_to_nm: {px_to_nms[i]}\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "classes = np.unique([tagged_grain_dict[i][\"tag\"] for i in tagged_grain_dict])\n",
    "\n",
    "churro_indexes = [i for i in tagged_grain_dict if tagged_grain_dict[i][\"tag\"] == \"churro\"]\n",
    "\n",
    "# Plot the churros\n",
    "plot_images(\n",
    "    [tagged_grain_dict[i][\"image\"] for i in churro_indexes],\n",
    "    [tagged_grain_dict[i][\"mask\"] for i in churro_indexes],\n",
    "    [tagged_grain_dict[i][\"p_to_nm\"] for i in churro_indexes],\n",
    "    churro_indexes,\n",
    ")\n",
    "\n",
    "dorito_indexes = [i for i in tagged_grain_dict if tagged_grain_dict[i][\"tag\"] == \"dorito\"]\n",
    "\n",
    "# Plot the doritos\n",
    "plot_images(\n",
    "    [tagged_grain_dict[i][\"image\"] for i in dorito_indexes],\n",
    "    [tagged_grain_dict[i][\"mask\"] for i in dorito_indexes],\n",
    "    [tagged_grain_dict[i][\"p_to_nm\"] for i in dorito_indexes],\n",
    "    dorito_indexes,\n",
    ")\n",
    "\n",
    "pasty_indexes = [i for i in tagged_grain_dict if tagged_grain_dict[i][\"tag\"] == \"pasty\"]\n",
    "\n",
    "# Plot the pasties\n",
    "plot_images(\n",
    "    [tagged_grain_dict[i][\"image\"] for i in pasty_indexes],\n",
    "    [tagged_grain_dict[i][\"mask\"] for i in pasty_indexes],\n",
    "    [tagged_grain_dict[i][\"p_to_nm\"] for i in pasty_indexes],\n",
    "    pasty_indexes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a single tagged grain to a different tag\n",
    "grain_index = 23\n",
    "plt.imshow(tagged_grain_dict[grain_index][\"image\"], cmap=cmap, vmin=-8, vmax=8)\n",
    "# tagged_grain_dict[grain_index][\"tag\"] = \"dorito\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the manually tagged grains for later use as a pickle\n",
    "import pickle\n",
    "\n",
    "TAGGED_GRAIN_SAVE_DIR = Path(f\"/Users/sylvi/topo_data/hariborings/dna_manual_tags/{SAMPLE_TYPE}/\")\n",
    "TAGGED_GRAIN_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(TAGGED_GRAIN_SAVE_DIR / f\"{SAMPLE_TYPE}_tagged_grains.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tagged_grain_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each image as image_{index}_{tag}.npy\n",
    "\n",
    "TAGGED_GRAIN_SAVE_IMAGES_DIR = TAGGED_GRAIN_SAVE_DIR / \"images\"\n",
    "TAGGED_GRAIN_SAVE_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for index, grain_data in tagged_grain_dict.items():\n",
    "    tag = grain_data[\"tag\"]\n",
    "    image = grain_data[\"image\"]\n",
    "    np.save(TAGGED_GRAIN_SAVE_IMAGES_DIR / f\"image_{index}_{tag}.npy\", image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
