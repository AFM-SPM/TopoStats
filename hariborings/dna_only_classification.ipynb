{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from cnn_classification import classification_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "# Just load OT2_SC for now\n",
    "DATA_PATH = Path(\"/Users/sylvi/topo_data/hariborings/dna_manual_tags/OT2_SC/\")\n",
    "DATA_PATH_IMAGES = DATA_PATH / \"images\"\n",
    "assert DATA_PATH_IMAGES.exists()\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "label_to_int = {\n",
    "    \"churro\": 0,\n",
    "    \"dorito\": 1,\n",
    "    \"pasty\": 2,\n",
    "}\n",
    "\n",
    "tagged_grain_dict_file = DATA_PATH / \"OT2_SC_tagged_grains.pkl\"\n",
    "assert tagged_grain_dict_file.exists()\n",
    "\n",
    "with open(tagged_grain_dict_file, \"rb\") as f:\n",
    "    tagged_grain_dict = pickle.load(f)\n",
    "\n",
    "print(tagged_grain_dict.keys())\n",
    "NUM_IMAGES = len(tagged_grain_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_and_shift(image: np.ndarray, ground_truth: np.ndarray, max_zoom_percentage: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"Zooms in on the image by a random amount between 0 and max_zoom_percentage,\n",
    "    then shifts the image by a random amount up to the number of zoomed pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Choose a zoom percentage and caluculate the number of pixels to zoom in\n",
    "    zoom = np.random.uniform(0, 0.1)\n",
    "    zoom_pixels = int(image.shape[0] * zoom)\n",
    "\n",
    "    # If there is zoom, choose a random shift\n",
    "    if int(zoom_pixels) > 0:\n",
    "        shift_x = np.random.randint(int(-zoom_pixels), int(zoom_pixels))\n",
    "        shift_y = np.random.randint(int(-zoom_pixels), int(zoom_pixels))\n",
    "\n",
    "        # Zoom and shift the image\n",
    "        zoomed_and_shifted_image = image[\n",
    "            zoom_pixels + shift_x : -zoom_pixels + shift_x,\n",
    "            zoom_pixels + shift_y : -zoom_pixels + shift_y,\n",
    "        ]\n",
    "        zoomed_and_shifted_ground_truth = ground_truth[\n",
    "            zoom_pixels + shift_x : -zoom_pixels + shift_x,\n",
    "            zoom_pixels + shift_y : -zoom_pixels + shift_y,\n",
    "        ]\n",
    "    else:\n",
    "        # Do nothing\n",
    "        shift_x = 0\n",
    "        shift_y = 0\n",
    "\n",
    "        zoomed_and_shifted_image = image\n",
    "        zoomed_and_shifted_ground_truth = ground_truth\n",
    "\n",
    "    return zoomed_and_shifted_image, zoomed_and_shifted_ground_truth\n",
    "\n",
    "\n",
    "# An image generator that loads images as they are needed\n",
    "def image_generator(image_indexes, batch_size=4, return_index=False):\n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_image_indexes = np.random.choice(a=image_indexes, size=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        real_image_indexes = []\n",
    "\n",
    "        # Load the image and ground truth\n",
    "        for index in batch_image_indexes:\n",
    "            # Get the nth image after sorting the files\n",
    "            image_path = list(DATA_PATH_IMAGES.glob(\"*.npy\"))\n",
    "            image_path = sorted(image_path)[index]\n",
    "            image = np.load(image_path)\n",
    "\n",
    "            # Get the real image index from the file name\n",
    "            image_index = int(re.search(r\"image_(\\d+)_\", image_path.stem).group(1))\n",
    "\n",
    "            # Get the label, which is the text just after \"image_{number}_\" and before \".npy\"\n",
    "            file_name = image_path.stem\n",
    "            label = re.search(r\"image_\\d+_(\\w+)\", file_name).group(1)\n",
    "\n",
    "            # Convert the label to an integer\n",
    "            label = label_to_int[label]\n",
    "            label = to_categorical(label, num_classes=NUM_CLASSES)\n",
    "\n",
    "            # Pad the image to be square\n",
    "            if image.shape[0] != image.shape[1]:\n",
    "                # Find the difference between the two dimensions\n",
    "                diff = abs(image.shape[0] - image.shape[1])\n",
    "                # If the first dimension is smaller, pad the first dimension\n",
    "                if image.shape[0] < image.shape[1]:\n",
    "                    image = np.pad(image, ((diff // 2, diff // 2), (0, 0)), mode=\"constant\")\n",
    "                # If the second dimension is smaller, pad the second dimension\n",
    "                else:\n",
    "                    image = np.pad(image, ((0, 0), (diff // 2, diff // 2)), mode=\"constant\")\n",
    "\n",
    "            # Randomly zoom and shift the image\n",
    "            image, _ = zoom_and_shift(image=image, ground_truth=image, max_zoom_percentage=0.15)\n",
    "\n",
    "            # Resize to 256x256\n",
    "            image = Image.fromarray(image)\n",
    "            image = image.resize((256, 256), resample=Image.BILINEAR)\n",
    "            image = np.array(image)\n",
    "\n",
    "            # Normalise the image\n",
    "            image = image - np.min(image)\n",
    "            image = image / np.max(image)\n",
    "            # image = np.clip(image, NORM_LOWER_BOUND, NORM_UPPER_BOUND)\n",
    "            # image = image - NORM_LOWER_BOUND\n",
    "            # image = image / (NORM_UPPER_BOUND - NORM_LOWER_BOUND)\n",
    "\n",
    "            # Augment the image\n",
    "            # Flip the images 50% of the time\n",
    "            if random.choice([0, 1]) == 1:\n",
    "                image = np.flip(image, axis=1)\n",
    "            # Rotate the images by either 0, 90, 180, or 270 degrees\n",
    "            rotation = random.choice([0, 1, 2, 3])\n",
    "            image = np.rot90(image, rotation)\n",
    "\n",
    "            batch_input.append(image)\n",
    "            batch_output.append(label)\n",
    "            real_image_indexes.append(image_index)\n",
    "\n",
    "        batch_x = np.array(batch_input).astype(np.float32)\n",
    "        batch_y = np.array(batch_output).astype(np.float32)\n",
    "\n",
    "        if return_index:\n",
    "            yield (batch_x, batch_y, real_image_indexes)\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the generator is doing the right thing\n",
    "# Get a list of available indexes to use from\n",
    "batch_generator = image_generator([0, 1, 2, 3, 4], batch_size=4, return_index=True)\n",
    "(batch_x, batch_y, real_image_indexes) = next(batch_generator)\n",
    "for image, label, real_image_index in zip(batch_x, batch_y, real_image_indexes):\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    print(f\"image max: {np.max(image)}\")\n",
    "    print(f\"image min: {np.min(image)}\")\n",
    "    print(f\"label: {label}\")\n",
    "    print(f\"real_image_index: {real_image_index}\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 30))\n",
    "    ax.imshow(image)\n",
    "    # Get the label from the label_to_int dictionary\n",
    "    text_label = list(label_to_int.keys())[list(label).index(1)]\n",
    "    ax.set_title(f\"label: {label}  {text_label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 5\n",
    "EPOCHS = 25\n",
    "AUGMENTATION_FACTOR = 8\n",
    "LEARNING_RATE = 0.001\n",
    "TRAIN_TEST_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split what images are used for training and validation\n",
    "train_image_indexes, validation_image_indexes = train_test_split(\n",
    "    range(0, NUM_IMAGES), test_size=TRAIN_TEST_SPLIT, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Number of training images: {len(train_image_indexes)}\")\n",
    "print(f\"Number of validation images: {len(validation_image_indexes)}\")\n",
    "\n",
    "print(f\"Training image indexes: {train_image_indexes}\")\n",
    "print(f\"Validation image indexes: {validation_image_indexes}\")\n",
    "\n",
    "# Create the generators\n",
    "train_generator = image_generator(train_image_indexes, batch_size=BATCH_SIZE)\n",
    "validation_generator = image_generator(validation_image_indexes, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model = classification_model(img_size=IMG_SIZE, classes=NUM_CLASSES, learning_rate=LEARNING_RATE)\n",
    "class_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = class_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_image_indexes) // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_image_indexes) // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(30, 8))\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "ax[0].plot(epochs, loss, \"y\", label=\"Training loss\")\n",
    "ax[0].plot(epochs, val_loss, \"r\", label=\"Valdation loss\")\n",
    "ax[0].set_title(\"Training and validation loss\")\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "\n",
    "print(history.history.keys())\n",
    "# acc = history.history[\"mean_io_u\"]\n",
    "# val_acc = history.history[\"val_mean_io_u\"]\n",
    "\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "ax[1].plot(epochs, acc, \"y\", label=\"Training acc\")\n",
    "ax[1].plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
    "ax[1].set_title(\"Training and validation accuracy\")\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "if \"iou\" in history.history:\n",
    "    ax[1].plot(epochs, history.history[\"iou\"], \"b\", label=\"Training iou\")\n",
    "    ax[1].plot(epochs, history.history[\"val_iou\"], \"g\", label=\"Validation iou\")\n",
    "\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results of the model on the testing set using the validation generator\n",
    "# Get the next batch from the generator\n",
    "(batch_x, batch_y) = next(validation_generator)\n",
    "# Predict the classes\n",
    "predicted_class = class_model.predict(batch_x)\n",
    "\n",
    "print(predicted_class)\n",
    "print(batch_x.shape)\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(len(batch_x), 1, figsize=(10, 30))\n",
    "for index, (image, ground_truth_label, predicted_label) in enumerate(zip(batch_x, batch_y, predicted_class)):\n",
    "    ax[index].imshow(image)\n",
    "    # Get the label from the label_to_int dictionary\n",
    "    text_label = list(label_to_int.keys())[list(ground_truth_label).index(1)]\n",
    "    text_predicted = list(label_to_int.keys())[np.argmax(predicted_label)]\n",
    "    title = f\"predicted: {text_predicted.upper()} {predicted_label[0]:.2f} {predicted_label[1]:.2f} {predicted_label[2]:.2f} \\nground truth: {text_label.upper()} {ground_truth_label}\"\n",
    "    if text_label == text_predicted:\n",
    "        # Set the title to green if the prediction is correct\n",
    "        ax[index].set_title(title, color=\"green\")\n",
    "    else:\n",
    "        # Set the title to red if the prediction is wrong\n",
    "        ax[index].set_title(title, color=\"red\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
