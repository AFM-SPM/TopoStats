{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from typing import Any\n",
    "from scipy import ndimage\n",
    "import networkx as nx\n",
    "from topostats.io import LoadScans\n",
    "from topostats.plottingfuncs import Colormap\n",
    "from topostats.utils import convolve_skeleton\n",
    "from topostats.mask_manipulation import smooth_mask\n",
    "from topostats.tracing.skeletonize import getSkeleton\n",
    "from topostats.measure.geometry import calculate_mask_width_with_skeleton, calculate_pixel_path_distance\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colormap = Colormap()\n",
    "cmap = colormap.get_cmap()\n",
    "vmin = -3.0\n",
    "vmax = 4.0\n",
    "\n",
    "\n",
    "def clear_output():\n",
    "    from IPython.display import clear_output as co\n",
    "\n",
    "    co()\n",
    "\n",
    "\n",
    "def load_data(dir: Path) -> dict[str, Any]:\n",
    "    files = list(dir.glob(\"*.topostats\"))\n",
    "    loader = LoadScans(files, channel=\"dummy\")\n",
    "    loader.get_data()\n",
    "    clear_output()\n",
    "    return loader.img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a3094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mid_process_files = Path(\"/Users/sylvi/topo_data/connect-loose-ends/mid-topostats-processing-data-files\")\n",
    "files = list(dir_mid_process_files.glob(\"*.pkl\"))\n",
    "loaded_files: dict[str, dict] = {}\n",
    "for file in files:\n",
    "    with open(file, \"rb\") as f:\n",
    "        loaded_file = pickle.load(f)\n",
    "        filename = loaded_file[\"filename\"]\n",
    "        loaded_files[filename] = loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7683567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Endpoint(BaseModel):\n",
    "    id: int\n",
    "    position: tuple[int, int]\n",
    "\n",
    "\n",
    "class ConnectionGroup(BaseModel):\n",
    "    id: int\n",
    "    endpoints: dict[int, Endpoint] = Field(default_factory=dict)\n",
    "    hard_connected_endpoints: list[tuple[int, int]] = Field(default_factory=list)\n",
    "    close_endpoint_pairs: list[tuple[int, int]] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_only_nonrepeated_endpoints(\n",
    "    potential_pairs: list[list[list[int, int], list[int, int], float]],\n",
    ") -> list[list[list[int, int], list[int, int], float]]:\n",
    "\n",
    "    used_endpoints: list[tuple[int, int]] = []\n",
    "    for potential_pair in potential_pairs:\n",
    "        endpoint_1, endpoint_2, distance_nm = potential_pair\n",
    "        used_endpoints.append((endpoint_1[0], endpoint_1[1]))\n",
    "        used_endpoints.append((endpoint_2[0], endpoint_2[1]))\n",
    "\n",
    "    repeated_endpoints = set([ep for ep in used_endpoints if used_endpoints.count(ep) > 1])\n",
    "\n",
    "    pairs_no_repeated_ends: list[list[list[int, int], list[int, int], float]] = []\n",
    "    for potential_pair in potential_pairs:\n",
    "        endpoint_1, endpoint_2, distance_nm = potential_pair\n",
    "        if (endpoint_1[0], endpoint_1[1]) not in repeated_endpoints and (\n",
    "            endpoint_2[0],\n",
    "            endpoint_2[1],\n",
    "        ) not in repeated_endpoints:\n",
    "            pairs_no_repeated_ends.append(potential_pair)\n",
    "        else:\n",
    "            print(f\"excluding pair {endpoint_1}, {endpoint_2} due to repeated endpoints\")\n",
    "\n",
    "    return pairs_no_repeated_ends\n",
    "\n",
    "\n",
    "def connect_endpoints_with_best_path(\n",
    "    image: npt.NDArray[np.float32],\n",
    "    mask: npt.NDArray[np.bool_],\n",
    "    p2nm: float,\n",
    "    endpoint_1: tuple[int, int],\n",
    "    endpoint_2: tuple[int, int],\n",
    "    endpoint_connection_cost_map_height_maximum: float,\n",
    ") -> tuple[npt.NDArray[np.uint8], float, float]:\n",
    "    # create a weight cost map from the image, where 0 is the maximum cost, and the lowest cost is configurable.\n",
    "    # first create a crop around the two endpoints to speed up pathfinding\n",
    "    cost_map_bbox_padding_px = 10\n",
    "    min_y = max(0, min(endpoint_1[0], endpoint_2[0]) - cost_map_bbox_padding_px)\n",
    "    max_y = min(image.shape[0], max(endpoint_1[0], endpoint_2[0]) + cost_map_bbox_padding_px)\n",
    "    min_x = max(0, min(endpoint_1[1], endpoint_2[1]) - cost_map_bbox_padding_px)\n",
    "    max_x = min(image.shape[1], max(endpoint_1[1], endpoint_2[1]) + cost_map_bbox_padding_px)\n",
    "    cost_map = image[min_y:max_y, min_x:max_x]\n",
    "    mask_crop = mask[min_y:max_y, min_x:max_x]\n",
    "    image_crop = image[min_y:max_y, min_x:max_x]\n",
    "    local_endpoint_1 = (endpoint_1[0] - min_y, endpoint_1[1] - min_x)\n",
    "    local_endpoint_2 = (endpoint_2[0] - min_y, endpoint_2[1] - min_x)\n",
    "    # clip it to the height bounds\n",
    "    cost_map = np.clip(\n",
    "        cost_map,\n",
    "        a_min=0,\n",
    "        a_max=endpoint_connection_cost_map_height_maximum,\n",
    "    )\n",
    "    # invert it\n",
    "    cost_map = endpoint_connection_cost_map_height_maximum - cost_map\n",
    "    # normalise to 0-1\n",
    "    cost_map = cost_map / endpoint_connection_cost_map_height_maximum\n",
    "\n",
    "    # find the lowest cost path between the two endpoints\n",
    "    from skimage.graph import route_through_array\n",
    "\n",
    "    path, cost = route_through_array(\n",
    "        cost_map,\n",
    "        start=local_endpoint_1,\n",
    "        end=local_endpoint_2,\n",
    "        fully_connected=True,  # allow diagonal moves\n",
    "    )\n",
    "\n",
    "    # Convert the path back to the original image coordinates\n",
    "    path = [(y + min_y, x + min_x) for y, x in path]\n",
    "    # Convert to numpy array for easier indexing\n",
    "    path = np.array(path)\n",
    "\n",
    "    # Calculate the distance of the path in nm, taking into account diagnonal distances\n",
    "    path_distance_nm = calculate_pixel_path_distance(path) * p2nm\n",
    "\n",
    "    return path, cost, path_distance_nm\n",
    "\n",
    "\n",
    "def group_endpoints(\n",
    "    endpoints: dict[int, Endpoint], close_pairs: list[int, int, float], draw_graph: bool = False\n",
    ") -> dict[int, ConnectionGroup]:\n",
    "    \"\"\"\n",
    "    Group endpoints into connection groups based on interconnections.\n",
    "    \"\"\"\n",
    "    # Split the graph into connected groups\n",
    "\n",
    "    # Create a graph\n",
    "    G = nx.Graph()\n",
    "    # Add the nodes (endpoints) as endpoint IDs\n",
    "    for endpoint_index, endpoint in endpoints.items():\n",
    "        G.add_node(endpoint_index)\n",
    "    # Add edges for each close pair (as endpoint IDs)\n",
    "    for endpoint_1_index, endpoint_2_index, distance_nm in close_pairs:\n",
    "        G.add_edge(endpoint_1_index, endpoint_2_index)\n",
    "\n",
    "    # draw it\n",
    "    if draw_graph:\n",
    "        nx.draw(G, with_labels=True)\n",
    "        plt.show()\n",
    "\n",
    "    # Get networkx to find connected components\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    # Create ConnectionGroup objects for each connected component\n",
    "    connection_groups: dict[int, ConnectionGroup] = {}\n",
    "    for group_id, component in enumerate(connected_components):\n",
    "        group_endpoints = {endpoint_index: endpoints[endpoint_index] for endpoint_index in component}\n",
    "        # Get the close pairs that are within this component\n",
    "        group_close_pairs = [\n",
    "            (endpoint_1_index, endpoint_2_index)\n",
    "            for endpoint_1_index, endpoint_2_index, _distance_nm in close_pairs\n",
    "            if endpoint_1_index in component and endpoint_2_index in component\n",
    "        ]\n",
    "        connection_group = ConnectionGroup(\n",
    "            id=group_id,\n",
    "            endpoints=group_endpoints,\n",
    "            close_endpoint_pairs=group_close_pairs,\n",
    "        )\n",
    "        connection_groups[group_id] = connection_group\n",
    "    return connection_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbe6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeletonisation_holearea_min_max = (0, None)\n",
    "skeletonisation_mask_smoothing_dilation_iterations = 2\n",
    "skeletonisation_mask_smoothing_gaussian_sigma = 2\n",
    "skeletonisation_method = \"topostats\"\n",
    "skeletonisation_height_bias = 0.6\n",
    "endpoint_connection_distance_nm = 10\n",
    "endpoint_connection_cost_map_height_maximum = 3.0\n",
    "endpoint_hard_connection_distance_nm = 20.0\n",
    "\n",
    "\n",
    "for filename, file_data in loaded_files.items():\n",
    "\n",
    "    # Let's focus on this one file for now.\n",
    "    # if filename != \"20251031_nicked_picoz_8ng_nicl.0_00062\":\n",
    "    #     continue\n",
    "\n",
    "    if filename != \"20251031_nicked_picoz_8ng_nicl.0_00083\":\n",
    "        continue\n",
    "\n",
    "    print(f\"processing file: {filename}\")\n",
    "    p2nm = file_data[\"pixel_to_nm_scaling\"]\n",
    "    tensor = file_data[\"full_mask_tensor\"]\n",
    "    image = file_data[\"image\"]\n",
    "\n",
    "    channel_to_connect_ends = 1  # use the DNA channel for connecting loose ends.\n",
    "\n",
    "    mask = tensor[:, :, channel_to_connect_ends].astype(bool)\n",
    "    # plt.imshow(mask, cmap=\"gray\")\n",
    "    # plt.title(\"Original mask\")\n",
    "    # plt.show()\n",
    "\n",
    "    smoothed_mask = smooth_mask(\n",
    "        filename=filename,\n",
    "        pixel_to_nm_scaling=p2nm,\n",
    "        grain=mask,\n",
    "        gaussian_sigma=skeletonisation_mask_smoothing_gaussian_sigma,\n",
    "        holearea_min_max=skeletonisation_holearea_min_max,\n",
    "        dilation_iterations=skeletonisation_mask_smoothing_dilation_iterations,\n",
    "    )\n",
    "    # plt.imshow(smoothed_mask, cmap=\"gray\")\n",
    "    # plt.title(\"Smoothed mask\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Maybe need to check it doesn't touch the edge of the image like we do in disordered_tracing? unsure.\n",
    "\n",
    "    # Next step, skeletonize\n",
    "    skeleton = getSkeleton(\n",
    "        image=image,\n",
    "        mask=smoothed_mask,\n",
    "        method=skeletonisation_method,\n",
    "        height_bias=0.6,\n",
    "    ).get_skeleton()\n",
    "\n",
    "    # Calculate the mask width along the skeleton for later\n",
    "    mean_mask_width_nm = calculate_mask_width_with_skeleton(\n",
    "        mask=smoothed_mask,\n",
    "        skeleton=skeleton,\n",
    "        pixel_to_nm_scaling=p2nm,\n",
    "    )\n",
    "    mean_mask_width_px = mean_mask_width_nm / p2nm\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    # plt.imshow(skeleton, cmap=\"gray\")\n",
    "    # plt.title(\"skeleton\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Now to find the skeleton endpoints and connect close ones.\n",
    "    convolved_skeleton = convolve_skeleton(skeleton=skeleton)\n",
    "    # Get the endpoints, value = 2\n",
    "    endpoint_coords = np.argwhere(convolved_skeleton == 2)\n",
    "    print(\"endpoints:\")\n",
    "    print(endpoint_coords)\n",
    "\n",
    "    # construct list of Endpoint objects\n",
    "    endpoints: dict[int, Endpoint] = {}\n",
    "    for endpoint_index, coord in enumerate(endpoint_coords):\n",
    "        endpoint = Endpoint(id=endpoint_index, position=(coord[0], coord[1]))\n",
    "        endpoints[endpoint_index] = endpoint\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    plt.imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    grain_mask_mask = np.ma.masked_where(~mask, mask)\n",
    "    plt.imshow(grain_mask_mask, cmap=\"Blues_r\", alpha=0.3)\n",
    "    skeleton_mask = np.ma.masked_where(~convolved_skeleton.astype(bool), convolved_skeleton)\n",
    "    plt.imshow(skeleton_mask, cmap=\"viridis\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # For each endpoint, determine if any others are close enough to connect.\n",
    "    nearby_endpoint_pairs: list[tuple[int, int, float]] = []\n",
    "    for i, endpoint_1 in endpoints.items():\n",
    "        for j, endpoint_2 in endpoints.items():\n",
    "            if i >= j:\n",
    "                continue  # avoid double counting\n",
    "            distance_nm = np.linalg.norm((np.array(endpoint_1.position) - np.array(endpoint_2.position)) * p2nm)\n",
    "            if distance_nm <= endpoint_connection_distance_nm:\n",
    "                nearby_endpoint_pairs.append((endpoint_1.id, endpoint_2.id, distance_nm))\n",
    "\n",
    "    # Group nearby endpoint pairs into connection groups\n",
    "    connection_groups = group_endpoints(endpoints=endpoints, close_pairs=nearby_endpoint_pairs)\n",
    "    print(f\"connection groups:\")\n",
    "    print(connection_groups)\n",
    "\n",
    "    # # Now consider each group and decide how to connect them.\n",
    "    # # Iterate over each possible pair\n",
    "    # for group_index, group_of_pairs in enumerate(groups_of_potentially_connected_endpoint_pairs):\n",
    "    #     print(f\"processing group {group_index} of {len(groups_of_potentially_connected_endpoint_pairs)}\")\n",
    "\n",
    "    #     # If there is only one pair in the group, just connect it.\n",
    "    #     if len(group_of_pairs) == 1:\n",
    "    #         pair = group_of_pairs[0]\n",
    "    #         endpoint_1, endpoint_2, distance_nm = pair\n",
    "\n",
    "    #         path, cost, distance_nm = connect_endpoints_with_best_path(\n",
    "    #             image=image,\n",
    "    #             mask=mask,\n",
    "    #             p2nm=p2nm,\n",
    "    #             endpoint_1=(endpoint_1[0], endpoint_1[1]),\n",
    "    #             endpoint_2=(endpoint_2[0], endpoint_2[1]),\n",
    "    #             endpoint_connection_cost_map_height_maximum=endpoint_connection_cost_map_height_maximum,\n",
    "    #         )\n",
    "\n",
    "    #         path_mask = np.zeros_like(mask, dtype=bool)\n",
    "    #         # Set the path to True\n",
    "    #         for y, x in path:\n",
    "    #             path_mask[y, x] = True\n",
    "    #         # Calculate the dilation iterations needed to reach the mean mask width\n",
    "    #         dilation_radius = int(np.ceil(mean_mask_width_px / 2))\n",
    "    #         dilated_path_array = ndimage.binary_dilation(\n",
    "    #             path_mask,\n",
    "    #             iterations=dilation_radius,\n",
    "    #         )\n",
    "\n",
    "    #         # Add the dilated path to the whole mask\n",
    "    #         mask = mask | dilated_path_array\n",
    "\n",
    "    #         # Update the skeleton to include the path\n",
    "    #         for y, x in path:\n",
    "    #             skeleton[y, x] = True\n",
    "\n",
    "    #         continue  # move to next group\n",
    "\n",
    "    #     # For groups with multiple pairs, we need to find a way to connect all endpoints together.\n",
    "\n",
    "    #     # find the hard-connected endpoints in this group, defined as the endpoints that are connected via the\n",
    "    #     # skeleton already, within a configurable hard connection distance.\n",
    "    #     endpoint_hard_connection_distance_px = int(endpoint_hard_connection_distance_nm / p2nm)\n",
    "\n",
    "    # #     path_mask = np.zeros_like(mask, dtype=bool)\n",
    "    # #     # Set the path to True\n",
    "    # #     for y, x in path:\n",
    "    # #         path_mask[y, x] = True\n",
    "    # #     # Calculate the dilation iterations needed to reach the mean mask width\n",
    "    # #     dilation_radius = int(np.ceil(mean_mask_width_px / 2))\n",
    "    # #     dilated_path_array = ndimage.binary_dilation(\n",
    "    # #         path_mask,\n",
    "    # #         iterations=dilation_radius,\n",
    "    # #     )\n",
    "\n",
    "    # #     # Add the dilated path to the whole mask\n",
    "    # #     mask = mask | dilated_path_array\n",
    "\n",
    "    # #     # Update the skeleton to include the path\n",
    "    # #     for y, x in path:\n",
    "    # #         skeleton[y, x] = True\n",
    "\n",
    "    # # fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    # # plt.imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    # # grain_mask_mask = np.ma.masked_where(~mask, mask)\n",
    "    # # plt.imshow(grain_mask_mask, cmap=\"Blues_r\", alpha=0.3)\n",
    "    # # skeleton_mask = np.ma.masked_where(~skeleton.astype(bool), skeleton)\n",
    "    # # plt.imshow(skeleton_mask, cmap=\"viridis\", alpha=0.7)\n",
    "    # # plt.title(\"skeleton after connecting loose ends\")\n",
    "    # # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topostats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
