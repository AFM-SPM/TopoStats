{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from typing import Any\n",
    "from topostats.io import LoadScans\n",
    "from topostats.plottingfuncs import Colormap\n",
    "from topostats.utils import convolve_skeleton\n",
    "from topostats.mask_manipulation import smooth_mask\n",
    "from topostats.tracing.skeletonize import getSkeleton\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colormap = Colormap()\n",
    "cmap = colormap.get_cmap()\n",
    "vmin = -3.0\n",
    "vmax = 4.0\n",
    "\n",
    "\n",
    "def clear_output():\n",
    "    from IPython.display import clear_output as co\n",
    "\n",
    "    co()\n",
    "\n",
    "\n",
    "def load_data(dir: Path) -> dict[str, Any]:\n",
    "    files = list(dir.glob(\"*.topostats\"))\n",
    "    loader = LoadScans(files, channel=\"dummy\")\n",
    "    loader.get_data()\n",
    "    clear_output()\n",
    "    return loader.img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a3094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_mid_process_files = Path(\"/Users/sylvi/topo_data/connect-loose-ends/mid-topostats-processing-data-files\")\n",
    "files = list(dir_mid_process_files.glob(\"*.pkl\"))\n",
    "loaded_files: dict[str, dict] = {}\n",
    "for file in files:\n",
    "    with open(file, \"rb\") as f:\n",
    "        loaded_file = pickle.load(f)\n",
    "        filename = loaded_file[\"filename\"]\n",
    "        loaded_files[filename] = loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbe6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeletonisation_holearea_min_max = (0, None)\n",
    "skeletonisation_mask_smoothing_dilation_iterations = 2\n",
    "skeletonisation_mask_smoothing_gaussian_sigma = 2\n",
    "skeletonisation_method = \"topostats\"\n",
    "skeletonisation_height_bias = 0.6\n",
    "endpoint_connectio_distance_nm = 10\n",
    "\n",
    "for filename, file_data in loaded_files.items():\n",
    "\n",
    "    # Let's focus on this one file for now.\n",
    "    if filename != \"20251031_nicked_picoz_8ng_nicl.0_00062\":\n",
    "        continue\n",
    "\n",
    "    print(f\"processing file: {filename}\")\n",
    "    p2nm = file_data[\"pixel_to_nm_scaling\"]\n",
    "    tensor = file_data[\"full_mask_tensor\"]\n",
    "    image = file_data[\"image\"]\n",
    "\n",
    "    channel_to_connect_ends = 1  # use the DNA channel for connecting loose ends.\n",
    "\n",
    "    mask = tensor[:, :, channel_to_connect_ends].astype(bool)\n",
    "    # plt.imshow(mask, cmap=\"gray\")\n",
    "    # plt.title(\"Original mask\")\n",
    "    # plt.show()\n",
    "\n",
    "    smoothed_mask = smooth_mask(\n",
    "        filename=filename,\n",
    "        pixel_to_nm_scaling=p2nm,\n",
    "        grain=mask,\n",
    "        gaussian_sigma=skeletonisation_mask_smoothing_gaussian_sigma,\n",
    "        holearea_min_max=skeletonisation_holearea_min_max,\n",
    "        dilation_iterations=skeletonisation_mask_smoothing_dilation_iterations,\n",
    "    )\n",
    "    # plt.imshow(smoothed_mask, cmap=\"gray\")\n",
    "    # plt.title(\"Smoothed mask\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Maybe need to check it doesn't touch the edge of the image like we do in disordered_tracing? unsure.\n",
    "\n",
    "    # Next step, skeletonize\n",
    "    skeleton = getSkeleton(\n",
    "        image=image,\n",
    "        mask=smoothed_mask,\n",
    "        method=skeletonisation_method,\n",
    "        height_bias=0.6,\n",
    "    ).get_skeleton()\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    # plt.imshow(skeleton, cmap=\"gray\")\n",
    "    # plt.title(\"skeleton\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Now to find the skeleton endpoints and connect close ones.\n",
    "    convolved_skeleton = convolve_skeleton(skeleton=skeleton)\n",
    "    # Get the endpoints, value = 2\n",
    "    endpoint_coords = np.argwhere(convolved_skeleton == 2)\n",
    "    print(\"endpoints:\")\n",
    "    print(endpoint_coords)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    plt.imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    grain_mask_mask = np.ma.masked_where(~mask, mask)\n",
    "    plt.imshow(grain_mask_mask, cmap=\"Blues_r\", alpha=0.3)\n",
    "    skeleton_mask = np.ma.masked_where(~convolved_skeleton.astype(bool), convolved_skeleton)\n",
    "    plt.imshow(skeleton_mask, cmap=\"viridis\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # For each endpoint, determine if any others are close enough to connect.\n",
    "    potential_pairs: list[list[list[int, int], list[int, int], float]] = []\n",
    "    for i, endpoint_1 in enumerate(endpoint_coords):\n",
    "        for j, endpoint_2 in enumerate(endpoint_coords):\n",
    "            if i >= j:\n",
    "                continue  # avoid double counting\n",
    "            distance_nm = np.linalg.norm((endpoint_1 - endpoint_2) * p2nm)\n",
    "            if distance_nm <= endpoint_connectio_distance_nm:\n",
    "                potential_pairs.append(((endpoint_1), (endpoint_2), distance_nm))\n",
    "\n",
    "    # for now, for simplicity, let's delete any pairs that are involved in other pairs.\n",
    "    # Construct a list of all endpoints involved in pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6904bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_pairs: list[list[list[int, int], list[int, int], float]] = [\n",
    "    [[10, 20], [15, 25], 7.07], # repeated [15, 25]\n",
    "    [[30, 40], [35, 45], 5.0], # repeated [30, 40]\n",
    "    [[15, 25], [50, 60], 40.0], # repeated [15, 25]\n",
    "    [[70, 80], [75, 85], 21.5], # unique\n",
    "    [[30, 40], [71, 81], 56.57], # repeated [30, 40]\n",
    "    [[10, 21], [16, 25], 7.81], # unique\n",
    "]\n",
    "\n",
    "\n",
    "def keep_only_nonrepeated_endpoints(\n",
    "    potential_pairs: list[list[list[int, int], list[int, int], float]],\n",
    ") -> list[list[list[int, int], list[int, int], float]]:\n",
    "\n",
    "    used_endpoints: list[tuple[int, int]] = []\n",
    "    for potential_pair in potential_pairs:\n",
    "        endpoint_1, endpoint_2, distance_nm = potential_pair\n",
    "        used_endpoints.append((endpoint_1[0], endpoint_1[1]))\n",
    "        used_endpoints.append((endpoint_2[0], endpoint_2[1]))\n",
    "\n",
    "    repeated_endpoints = set([ep for ep in used_endpoints if used_endpoints.count(ep) > 1])\n",
    "\n",
    "    print(\"repeated endpoints:\")\n",
    "    print(repeated_endpoints)\n",
    "\n",
    "\n",
    "    pairs_no_repeated_ends: list[list[list[int, int], list[int, int], float]] = []\n",
    "    for potential_pair in potential_pairs:\n",
    "        endpoint_1, endpoint_2, distance_nm = potential_pair\n",
    "        if (endpoint_1[0], endpoint_1[1]) not in repeated_endpoints and (\n",
    "            endpoint_2[0],\n",
    "            endpoint_2[1],\n",
    "        ) not in repeated_endpoints:\n",
    "            pairs_no_repeated_ends.append(potential_pair)\n",
    "        else:\n",
    "            print(f\"excluding pair {endpoint_1}, {endpoint_2} due to repeated endpoints\")\n",
    "\n",
    "    return pairs_no_repeated_ends\n",
    "\n",
    "pairs_to_connect = keep_only_nonrepeated_endpoints(potential_pairs)\n",
    "print(\"pairs to connect:\")\n",
    "for pair in pairs_to_connect:\n",
    "    print(pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topostats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
