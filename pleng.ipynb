{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from topostats.io import hdf5_to_dict\n",
    "import h5glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Users/sylvi/topo_data/pleng/data/\")\n",
    "assert data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"20231218_2ngSCcats.0_00003.topostats\"\n",
    "file_path = data_dir / filename\n",
    "assert file_path.exists()\n",
    "\n",
    "with h5py.File(file_path, \"r\") as f:\n",
    "    image_data = hdf5_to_dict(f, group_path=\"/\")\n",
    "    print(image_data.keys())\n",
    "    spline_data = image_data[\"splining\"][\"above\"]\n",
    "    p_to_nm = image_data[\"pixel_to_nm_scaling\"]\n",
    "    print(f\"pixel to nm scaling: {p_to_nm}\")\n",
    "\n",
    "    image = image_data[\"image\"]\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    spline_data = spline_data[\"grain_0\"][\"mol_0\"]\n",
    "    print(spline_data.keys())\n",
    "    spline_coords = spline_data[\"spline_coords\"]\n",
    "\n",
    "    # plot spline coords\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    # ax.plot(spline_coords[:, 0], spline_coords[:, 1], marker=\"o\", markersize=1)\n",
    "    ax.scatter(spline_coords[:, 0], spline_coords[:, 1], s=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucledian_dist(x, pleng):\n",
    "    return 4 * pleng * x * (1 - (2 * pleng / x)) * (1 - np.exp(-x / (2 * pleng)))\n",
    "\n",
    "\n",
    "def betterpleng(\n",
    "    points: np.ndarray, maximum_length_nm: float, plot=False, log_angle_warnings=True, log_details=False\n",
    ") -> tuple[float, float]:\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        ax.plot(points[:, 1], points[:, 0], c=\"red\")\n",
    "        ax.scatter(points[0, 1], points[0, 0], c=\"blue\")\n",
    "\n",
    "    current_distance = 0\n",
    "\n",
    "    distance_cos_angle_pairs = {}\n",
    "    distances = []\n",
    "    cos_angles = []\n",
    "\n",
    "    # iterate over each point\n",
    "    first_vector = points[1] - points[0]\n",
    "    first_point = points[0]\n",
    "    first_vector /= np.linalg.norm(first_vector)\n",
    "    for point_index, point in enumerate(points):\n",
    "        if point_index == 0:\n",
    "            # Skip the first point completely since we can't calculate a vector yet.\n",
    "            # Don't even add the distance to the dictionary\n",
    "            continue\n",
    "        if point_index == len(points) - 1:\n",
    "            # don't include the last set of points since they're not complete\n",
    "            break\n",
    "        vector = point - points[point_index - 1]\n",
    "        vector_distance = np.linalg.norm(vector)\n",
    "        current_distance += vector_distance\n",
    "        vector /= vector_distance\n",
    "        cos_angle = np.dot(first_vector, vector)\n",
    "        # Check for bad angles (for cos(angle))\n",
    "        if log_angle_warnings:\n",
    "            if cos_angle == 0:\n",
    "                print(\"[warning] cos(angle) is orthogonal to first vector, can't be fitted to log plot\")\n",
    "            elif cos_angle < 0:\n",
    "                print(\"[warning] cos(angle) is negative, can't be fitted to log plot\")\n",
    "\n",
    "        if current_distance > maximum_length_nm:\n",
    "            # reset this section and add stats to dictionary\n",
    "            first_vector = vector\n",
    "            first_point = point\n",
    "            current_distance = 0\n",
    "            # add the distances and cos angles to the list\n",
    "            distance_cos_angle_pairs[point_index] = {\n",
    "                \"distances\": distances,\n",
    "                \"cos_angles\": cos_angles,\n",
    "            }\n",
    "            distances = []\n",
    "            cos_angles = []\n",
    "            if plot:\n",
    "                ax.scatter(point[1], point[0], c=\"green\")\n",
    "        else:\n",
    "            if plot:\n",
    "                ax.scatter(point[1], point[0], c=\"blue\", s=1)\n",
    "            distances.append(current_distance)\n",
    "            cos_angles.append(cos_angle)\n",
    "\n",
    "    if plot:\n",
    "        ax.set_aspect(\"equal\")\n",
    "        plt.show()\n",
    "\n",
    "    # plot the distances and cos angles\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "    for point_index, distance_cos_angle_pair in distance_cos_angle_pairs.items():\n",
    "        distances = distance_cos_angle_pair[\"distances\"]\n",
    "        cos_angles = distance_cos_angle_pair[\"cos_angles\"]\n",
    "        if plot:\n",
    "            ax.plot(distances, cos_angles, label=f\"point {point_index}\")\n",
    "    if plot:\n",
    "        # put the legend to the rhs of the plot and wrap it do it doesn't go off the screen\n",
    "        ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), ncol=len(distance_cos_angle_pairs) // 4)\n",
    "        plt.show()\n",
    "\n",
    "    # get rid of distance cos angle pairs where cos angles are zero or negative, since they can't be fitted\n",
    "    # to a log plot\n",
    "    vetted_distance_cos_angle_pairs = {}\n",
    "    for point_index, distance_cos_angle_pair in distance_cos_angle_pairs.items():\n",
    "        cos_angles = distance_cos_angle_pair[\"cos_angles\"]\n",
    "        if np.any(np.array(cos_angles) <= 0):\n",
    "            continue\n",
    "        vetted_distance_cos_angle_pairs[point_index] = distance_cos_angle_pair\n",
    "\n",
    "    distance_cos_angle_pairs = vetted_distance_cos_angle_pairs\n",
    "\n",
    "    # calculate the average of the cos angles, but since they are all at different distances, resample to use common\n",
    "    # distances, we need to ditch any points that are outside the smallest range of distances\n",
    "    average_cos_angles = []\n",
    "    # find the smallest range of distances\n",
    "    largest_minimum = -np.inf\n",
    "    smallest_maximum = np.inf\n",
    "    if len(distance_cos_angle_pairs) == 0:\n",
    "        raise ValueError(\"no points found\")\n",
    "    for point_index, distance_cos_angle_pair in distance_cos_angle_pairs.items():\n",
    "        distances = distance_cos_angle_pair[\"distances\"]\n",
    "        smallest_distance = np.min(distances)\n",
    "        largest_distance = np.max(distances)\n",
    "        if smallest_distance > largest_minimum:\n",
    "            largest_minimum = smallest_distance\n",
    "        if largest_distance < smallest_maximum:\n",
    "            smallest_maximum = largest_distance\n",
    "    if largest_minimum == -np.inf or smallest_maximum == np.inf:\n",
    "        raise ValueError(\"no common range of distances found\")\n",
    "    common_distances = np.arange(largest_minimum, smallest_maximum, 0.1)\n",
    "    if log_details:\n",
    "        print(f\"common distances shape: {common_distances.shape}\")\n",
    "    # resample each set of distances and cos angles to the common distances\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    for point_index, distance_cos_angle_pair in distance_cos_angle_pairs.items():\n",
    "        distances = distance_cos_angle_pair[\"distances\"]\n",
    "        cos_angles = distance_cos_angle_pair[\"cos_angles\"]\n",
    "        interpolated_cos_angles = np.interp(common_distances, distances, cos_angles)\n",
    "        average_cos_angles.append(interpolated_cos_angles)\n",
    "        if plot:\n",
    "            ax.plot(common_distances, interpolated_cos_angles, label=f\"point {point_index}\")\n",
    "\n",
    "    if plot:\n",
    "        ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), ncol=len(distance_cos_angle_pairs) // 4)\n",
    "        plt.show()\n",
    "\n",
    "    average_cos_angles = np.mean(average_cos_angles, axis=0)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(common_distances, average_cos_angles)\n",
    "        plt.title(\"average cos angles\")\n",
    "        plt.show()\n",
    "\n",
    "    inverse_log_cos_angles = -np.log(average_cos_angles)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(common_distances, inverse_log_cos_angles)\n",
    "        plt.title(\"inverse log cos angles\")\n",
    "        plt.show()\n",
    "\n",
    "    def linear(x, a, b):\n",
    "        return a * x + b\n",
    "\n",
    "    if log_details:\n",
    "        print(f\"common distances shape: {common_distances.shape}\")\n",
    "        print(f\"inverse log cos angles shape: {inverse_log_cos_angles.shape}\")\n",
    "\n",
    "    popt, pcov = curve_fit(linear, common_distances, inverse_log_cos_angles)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(common_distances, linear(common_distances, *popt), label=\"fit\")\n",
    "        ax.plot(common_distances, inverse_log_cos_angles, label=\"data\")\n",
    "        plt.title(\"fit\")\n",
    "        plt.legend()\n",
    "        plt.show\n",
    "\n",
    "    # the slope is 1/(2p) where p is the pleng\n",
    "    pleng = 1 / (2 * popt[0])\n",
    "\n",
    "    # calculate residuals\n",
    "    residuals = inverse_log_cos_angles - linear(common_distances, *popt)\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(x=common_distances, y=residuals)\n",
    "        plt.title(\"residuals\")\n",
    "        plt.show()\n",
    "        print(f\"pleng: {pleng}\")\n",
    "\n",
    "    # calculate root mean squared error\n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    if plot:\n",
    "        print(f\"rmse: {rmse}\")\n",
    "\n",
    "    return pleng, rmse\n",
    "\n",
    "\n",
    "betterpleng(spline_coords, maximum_length_nm=10, plot=True, log_details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pleng = None\n",
    "best_rmse = None\n",
    "best_max_length = None\n",
    "for maximum_length_nm in [10, 20, 30, 40, 50]:\n",
    "    pleng, rmse = betterpleng(spline_coords, maximum_length_nm, plot=False)\n",
    "    # check if better rmse\n",
    "    if best_rmse is None or rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_pleng = pleng\n",
    "        best_max_length = maximum_length_nm\n",
    "\n",
    "pleng, rmse = betterpleng(spline_coords, maximum_length_nm=best_max_length, plot=True)\n",
    "\n",
    "print(f\"best pleng: {pleng} with rmse: {rmse} at maximum length: {best_max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore what happens are p and s are changed for many different values\n",
    "p_values = np.linspace(0.01, 0.1, 100)\n",
    "s_values = np.linspace(0.1, 1, 100)\n",
    "rsquared_values = np.zeros((len(p_values), len(s_values)))\n",
    "for p_index, pleng in enumerate(p_values):\n",
    "    for s_index, x in enumerate(s_values):\n",
    "        rsquared_values[p_index, s_index] = eucledian_dist(pleng, x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(rsquared_values, cmap=\"viridis\")\n",
    "fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pleng = 50\n",
    "contour_lengths = np.linspace(10, 150, 100)\n",
    "euclidian_distances = np.zeros_like(contour_lengths)\n",
    "for index, contour_length in enumerate(contour_lengths):\n",
    "    euclidian_distances[index] = eucledian_dist(x=contour_length, pleng=pleng)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(contour_lengths, euclidian_distances)\n",
    "plt.xlabel(\"contour length\")\n",
    "plt.ylabel(\"euclidean distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create results dictionary\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_file_pleng(\n",
    "    data_dir: Path,\n",
    "    maximum_length_nm: float,\n",
    "    maximum_px_to_nm: float,\n",
    "    use_grains_with_only_one_molecule: bool,\n",
    "    quiet=True,\n",
    ") -> tuple[list, list, list, int]:\n",
    "\n",
    "    def qprint(*args, **kwargs):\n",
    "        if not quiet:\n",
    "            print(*args, **kwargs)\n",
    "\n",
    "    num_molecules_processed = 0\n",
    "\n",
    "    plengs, rmses, p2nms = [], [], []\n",
    "\n",
    "    # get all .topostats files\n",
    "    topostats_files = list(data_dir.glob(\"*.topostats\"))\n",
    "    print(f\"Found {len(topostats_files)} .topostats files\")\n",
    "    for file in topostats_files:\n",
    "        qprint(f\"file: {file.name}\")\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            image_data = hdf5_to_dict(f, group_path=\"/\")\n",
    "            if \"splining\" not in image_data:\n",
    "                qprint(\"[ERROR] no splining data\")\n",
    "                continue\n",
    "            spline_data = image_data[\"splining\"][\"above\"]\n",
    "            p_to_nm = image_data[\"pixel_to_nm_scaling\"]\n",
    "\n",
    "            if p_to_nm > maximum_px_to_nm:\n",
    "                qprint(f\"skipping file, pixel to nm scaling is too high: {p_to_nm}\")\n",
    "                continue\n",
    "\n",
    "            for grain_index, grain_data in spline_data.items():\n",
    "                qprint(f\"  grain: {grain_index}\")\n",
    "                qprint(f\"  number of molecules: {len(grain_data)}\")\n",
    "                if use_grains_with_only_one_molecule and len(grain_data) != 1:\n",
    "                    qprint(f\"    skipping grain with {len(grain_data)} molecules\")\n",
    "                    continue\n",
    "                for molecule_index, molecule_data in grain_data.items():\n",
    "                    qprint(f\"    molecule: {molecule_index}\")\n",
    "                    spline_coords = molecule_data[\"spline_coords\"] * p_to_nm\n",
    "                    try:\n",
    "                        pleng, rmse = betterpleng(\n",
    "                            points=spline_coords,\n",
    "                            maximum_length_nm=maximum_length_nm,\n",
    "                            plot=False,\n",
    "                            log_angle_warnings=False,\n",
    "                        )\n",
    "                        plengs.append(pleng)\n",
    "                        rmses.append(rmse)\n",
    "                        p2nms.append(p_to_nm)\n",
    "                    except ValueError as e:\n",
    "                        if \"no points found\" in str(e):\n",
    "                            qprint(\"[ERROR] no points found\")\n",
    "                            continue\n",
    "                        elif \"no common range of distances found\" in str(e):\n",
    "                            qprint(\"[ERROR] no common range of distances found\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            raise e\n",
    "                    num_molecules_processed += 1\n",
    "    print(f\"processed {num_molecules_processed} molecules\")\n",
    "\n",
    "    return plengs, rmses, p2nms, num_molecules_processed\n",
    "\n",
    "\n",
    "sample_type = \"magnesium-unknot-plasmid-nicked\"\n",
    "data_dir = Path(f\"/Users/sylvi/topo_data/pleng/topology-data-check/processed-data-{sample_type}\")\n",
    "maximum_length_nm = 10\n",
    "maximum_px_to_nm = 1.0\n",
    "use_grains_with_only_one_molecule = True\n",
    "assert data_dir.exists()\n",
    "\n",
    "plengs, rmses, p2nms, num_molecules_processed = multi_file_pleng(\n",
    "    data_dir=data_dir,\n",
    "    maximum_length_nm=maximum_length_nm,\n",
    "    maximum_px_to_nm=maximum_px_to_nm,\n",
    "    use_grains_with_only_one_molecule=use_grains_with_only_one_molecule,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "p2nms = np.array(p2nms)\n",
    "ax.scatter(x=plengs, y=rmses, s=4, c=p2nms, cmap=\"viridis\")\n",
    "cbar = plt.colorbar(ax.collections[0], ax=ax)\n",
    "\n",
    "plt.xlabel(\"pleng\")\n",
    "plt.ylabel(\"rmse\")\n",
    "plt.title(f\"pleng vs rmse for {sample_type}, n={num_molecules_processed} L={maximum_length_nm}\")\n",
    "plt.show()\n",
    "\n",
    "# calculate a weighted average, inversely proportional to the rmse\n",
    "weighted_average = np.average(plengs, weights=1 / np.array(rmses))\n",
    "print(f\"rmse weighted average: {weighted_average}\")\n",
    "\n",
    "non_weighted_average = np.mean(plengs)\n",
    "print(f\"non weighted average: {non_weighted_average}\")\n",
    "\n",
    "results[sample_type] = {\n",
    "    \"plengs\": plengs,\n",
    "    \"rmses\": rmses,\n",
    "    \"p2nms\": p2nms,\n",
    "    \"weighted_average\": weighted_average,\n",
    "    \"non_weighted_average\": non_weighted_average,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what happens to a dataset when changing maximum length\n",
    "# sample_type = \"magnesium-unknot-plasmid-nicked\"\n",
    "sample_type = \"magnesium-unknot-plasmid-supercoiled\"\n",
    "data_dir = Path(f\"/Users/sylvi/topo_data/pleng/topology-data-check/processed-data-{sample_type}\")\n",
    "maximum_px_to_nm = 1.0\n",
    "use_grains_with_only_one_molecule = True\n",
    "assert data_dir.exists()\n",
    "\n",
    "maximum_lengths = list(range(8, 30, 1))\n",
    "average_plengs = []\n",
    "\n",
    "for maximum_length_nm in maximum_lengths:\n",
    "    plengs, rmses, p2nms, num_molecules_processed = multi_file_pleng(\n",
    "        data_dir=data_dir,\n",
    "        maximum_length_nm=maximum_length_nm,\n",
    "        maximum_px_to_nm=maximum_px_to_nm,\n",
    "        use_grains_with_only_one_molecule=use_grains_with_only_one_molecule,\n",
    "    )\n",
    "\n",
    "    non_weighted_average = np.mean(plengs)\n",
    "    average_plengs.append(non_weighted_average)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(maximum_lengths, average_plengs)\n",
    "plt.xlabel(\"maximum length\")\n",
    "plt.ylabel(\"average pleng\")\n",
    "plt.title(f\"average pleng vs maximum length for {sample_type}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_types = [\n",
    "    \"magnesium-unknot-plasmid-nicked\",\n",
    "    \"magnesium-unknot-plasmid-supercoiled\",\n",
    "    \"nickel-relaxed\",\n",
    "    \"nickel-supercoiled\",\n",
    "]\n",
    "data_dir_prefix = \"/Users/sylvi/topo_data/pleng/topology-data-check/processed-data-\"\n",
    "maximum_length_nm = 20\n",
    "maximum_px_to_nm = 1.0\n",
    "use_grains_with_only_one_molecule = True\n",
    "assert data_dir.exists()\n",
    "\n",
    "results = {}\n",
    "\n",
    "for sample_type in sample_types:\n",
    "    data_dir = Path(data_dir_prefix + sample_type)\n",
    "    plengs, rmses, p2nms, num_molecules_processed = multi_file_pleng(\n",
    "        data_dir=data_dir,\n",
    "        maximum_length_nm=maximum_length_nm,\n",
    "        maximum_px_to_nm=maximum_px_to_nm,\n",
    "        use_grains_with_only_one_molecule=use_grains_with_only_one_molecule,\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    p2nms = np.array(p2nms)\n",
    "    ax.scatter(x=plengs, y=rmses, s=4, c=p2nms, cmap=\"viridis\")\n",
    "    cbar = plt.colorbar(ax.collections[0], ax=ax)\n",
    "\n",
    "    plt.xlabel(\"pleng\")\n",
    "    plt.ylabel(\"rmse\")\n",
    "    plt.title(f\"pleng vs rmse for {sample_type}, n={num_molecules_processed} L={maximum_length_nm}\")\n",
    "    plt.show()\n",
    "\n",
    "    # calculate a weighted average, inversely proportional to the rmse\n",
    "    weighted_average = np.average(plengs, weights=1 / np.array(rmses))\n",
    "    print(f\"rmse weighted average: {weighted_average}\")\n",
    "\n",
    "    non_weighted_average = np.mean(plengs)\n",
    "    print(f\"non weighted average: {non_weighted_average}\")\n",
    "\n",
    "    results[sample_type] = {\n",
    "        \"plengs\": plengs,\n",
    "        \"rmses\": rmses,\n",
    "        \"p2nms\": p2nms,\n",
    "        \"weighted_average\": weighted_average,\n",
    "        \"non_weighted_average\": non_weighted_average,\n",
    "    }\n",
    "\n",
    "\n",
    "# plot kde of plengs in results\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "for sample_type, data in results.items():\n",
    "    plengs = data[\"plengs\"]\n",
    "    sns.kdeplot(\n",
    "        plengs,\n",
    "        # label=f\" {sample_type}\\n   | n: {len(plengs)}\\n   | mean: {np.mean(plengs):.2f} | std: {np.std(plengs):.2f} |\\n\",\n",
    "        label=f\" {sample_type}\\n    n: {len(plengs)} \",\n",
    "        ax=ax,\n",
    "    )\n",
    "# force the legend to be outside the plot\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.title(f\"plengs L={maximum_length_nm}\")\n",
    "plt.xlabel(\"pleng (nm)\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.show()\n",
    "\n",
    "# plot another kde but using samples that contain nickel and samples that contain magnesium as the two groups\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "nickel_plengs = results[\"nickel-relaxed\"][\"plengs\"] + results[\"nickel-supercoiled\"][\"plengs\"]\n",
    "magnesium_plengs = (\n",
    "    results[\"magnesium-unknot-plasmid-nicked\"][\"plengs\"] + results[\"magnesium-unknot-plasmid-supercoiled\"][\"plengs\"]\n",
    ")\n",
    "sns.kdeplot(\n",
    "    nickel_plengs,\n",
    "    # label=f\"nickel\\n n:{len(nickel_plengs)}\\n mean: {np.mean(nickel_plengs):.2f} std: {np.std(nickel_plengs):.2f}\",\n",
    "    label=f\"nickel\\n n:{len(nickel_plengs)}\",\n",
    "    ax=ax,\n",
    ")\n",
    "sns.kdeplot(\n",
    "    magnesium_plengs,\n",
    "    # label=f\"magnesium\\n n:{len(magnesium_plengs)}\\n mean: {np.mean(magnesium_plengs):.2f} std: {np.std(magnesium_plengs):.2f}\",\n",
    "    label=f\"magnesium\\n n:{len(magnesium_plengs)}\",\n",
    "    ax=ax,\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(f\"nickel vs magnesium plengs L={maximum_length_nm}\")\n",
    "plt.xlabel(\"pleng (nm)\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo-unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
