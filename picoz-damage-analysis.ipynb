{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Generator\n",
    "\n",
    "from hashlib import sha256\n",
    "import matplotlib.pyplot as plt\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from AFMReader.topostats import load_topostats\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from topostats.damage.damage import (\n",
    "    Defect,\n",
    "    DefectGap,\n",
    "    OrderedDefectGapList,\n",
    "    calculate_indirect_defect_gaps,\n",
    "    get_defects_and_gaps_from_bool_array,\n",
    ")\n",
    "from topostats.io import LoadScans\n",
    "from topostats.measure.curvature import discrete_angle_difference_per_nm_circular, total_turn_in_region_radians\n",
    "from topostats.tracing.splining import resample_points_regular_interval\n",
    "from topostats.unet_masking import make_bounding_box_square, pad_bounding_box_cutting_off_at_image_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_output():\n",
    "    from IPython.display import clear_output as ipy_clear_output\n",
    "\n",
    "    ipy_clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data directories set up\n",
    "dir_base = Path(\"/Volumes/shared/pyne_group/Shared/AFM_Data/dna_damage/Cs137_irradiations\")\n",
    "assert dir_base.exists()\n",
    "dir_this_analysis = dir_base / \"20260204-analysis-getting-back-into-the-project\"\n",
    "assert dir_this_analysis.exists()\n",
    "dir_processed_data = dir_this_analysis / \"output\"\n",
    "assert dir_processed_data.exists()\n",
    "dir_results = dir_this_analysis / \"analysis_results\"\n",
    "dir_results.mkdir(exist_ok=True)\n",
    "assert dir_results.exists()\n",
    "\n",
    "# Load the data, lazily since the files are large?\n",
    "topo_files = list(dir_processed_data.glob(\"*/**/*.topostats\"))\n",
    "print(f\"found {len(topo_files)} topo files\")\n",
    "\n",
    "# Load the corresponding statistics csv file\n",
    "csv_grain_stats = dir_processed_data / \"grain_statistics.csv\"\n",
    "assert csv_grain_stats.exists(), f\"could not find grain stats csv at {csv_grain_stats}\"\n",
    "df_grain_stats = pd.read_csv(csv_grain_stats)\n",
    "print(f\"grain stats columns: {df_grain_stats.columns}\")\n",
    "\n",
    "# convert some columns to nanometres\n",
    "df_grain_stats[\"total_contour_length\"] /= 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot contour length distributions\n",
    "sns.stripplot(data=df_grain_stats, x=\"basename\", y=\"total_contour_length\", s=2)\n",
    "sns.violinplot(data=df_grain_stats, x=\"basename\", y=\"total_contour_length\", inner=None)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Contour length distributions\")\n",
    "plt.show()\n",
    "\n",
    "# drop any rows with contour length less than a threshold\n",
    "threshold_contour_length = 300\n",
    "\n",
    "n_rows_before = len(df_grain_stats)\n",
    "df_grain_stats = df_grain_stats[df_grain_stats[\"total_contour_length\"] >= threshold_contour_length]\n",
    "n_rows_after = len(df_grain_stats)\n",
    "print(\n",
    "    f\"dropped {n_rows_before - n_rows_after} rows with contour length < {threshold_contour_length} nm. remaining rows: {n_rows_after}\"\n",
    ")\n",
    "\n",
    "sns.stripplot(data=df_grain_stats, x=\"basename\", y=\"total_contour_length\", s=2)\n",
    "sns.violinplot(data=df_grain_stats, x=\"basename\", y=\"total_contour_length\", inner=None)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Contour length distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check ram usage of the notebook\n",
    "def notebook_ram_usage():\n",
    "    process = psutil.Process()\n",
    "    print(f\"process: {process}\")\n",
    "    mem_info = process.memory_info()\n",
    "    print(f\"memory info: {mem_info}\")\n",
    "    ram_usage_gb = mem_info.rss / (1024**3)\n",
    "    print(f\"RAM usage: {ram_usage_gb:.2f} GB\")\n",
    "\n",
    "\n",
    "notebook_ram_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5db1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "class BaseDamageAnalysis(BaseModel):\n",
    "    \"\"\"Data object to hold settings for Models used in the project.\"\"\"\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "\n",
    "class GrainModel(BaseDamageAnalysis):\n",
    "    grain_id: int\n",
    "    filename: str\n",
    "    pixel_to_nm_scaling: float\n",
    "    folder: str\n",
    "    percent_damage: float\n",
    "    bbox: tuple[int, int, int, int]\n",
    "    image: npt.NDArray[np.float64]\n",
    "    aspect_ratio: float\n",
    "    smallest_bounding_area: float\n",
    "    total_contour_length: float\n",
    "    num_crossings: int\n",
    "    molecule_data: dict[int, dict[str, npt.NDArray[np.float64]]]\n",
    "    added_left: int\n",
    "    added_top: int\n",
    "    padding: int\n",
    "    mask: npt.NDArray[np.bool_]\n",
    "    node_coords: npt.NDArray[np.float64]\n",
    "    num_nodes: int\n",
    "\n",
    "\n",
    "class GrainModelCollection(BaseDamageAnalysis):\n",
    "    grains: dict[int, GrainModel]\n",
    "\n",
    "    def __getitem__(self, key: int) -> GrainModel:\n",
    "        return self.grains[key]\n",
    "\n",
    "    def __iter__(self) -> Generator[tuple[int, GrainModel], None, None]:\n",
    "        return (item for item in self.grains.items())\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.grains)\n",
    "\n",
    "    def __contains__(self, key: int) -> bool:\n",
    "        return key in self.grains\n",
    "\n",
    "    def items(self) -> Generator[tuple[int, GrainModel], None, None]:\n",
    "        return (item for item in self.grains.items())\n",
    "\n",
    "    def keys(self) -> Generator[int, None, None]:\n",
    "        return (key for key in self.grains.keys())\n",
    "\n",
    "    def values(self) -> Generator[GrainModel, None, None]:\n",
    "        return (value for value in self.grains.values())\n",
    "\n",
    "    def get(self, key: int, default: GrainModel | None = None) -> GrainModel | None:\n",
    "        return self.grains.get(key, default)\n",
    "\n",
    "    def add_grain(self, grain: GrainModel) -> None:\n",
    "        # Check if the grain ID already exists in the collection\n",
    "        if grain.grain_id in self.grains:\n",
    "            raise ValueError(f\"Grain with ID {grain.grain_id} already exists in the collection.\")\n",
    "        self.grains[grain.grain_id] = grain\n",
    "\n",
    "    def remove_grain(self, grain_id: int) -> None:\n",
    "        if grain_id not in self.grains:\n",
    "            raise KeyError(f\"Grain with ID {grain_id} does not exist in the collection.\")\n",
    "        del self.grains[grain_id]\n",
    "\n",
    "\n",
    "def combine_grain_model_collections(collections: list[GrainModelCollection]) -> GrainModelCollection:\n",
    "    combined_collection = GrainModelCollection(grains={})\n",
    "    for collection in collections:\n",
    "        for grain_id, grain in collection.items():\n",
    "            if grain_id in combined_collection:\n",
    "                raise ValueError(f\"Duplicate grain ID {grain_id} found in multiple collections.\")\n",
    "            combined_collection.add_grain(grain)\n",
    "    return combined_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31445145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files\n",
    "def load_grain_models_from_topo_files(\n",
    "    topo_files: list[Path],\n",
    "    df_grain_stats: pd.DataFrame,\n",
    "    bbox_padding: int,\n",
    "    sample_type: str,\n",
    ") -> GrainModelCollection:\n",
    "    grain_model_collection = GrainModelCollection(grains={})\n",
    "    loadscans = LoadScans(img_paths=topo_files, channel=\"dummy\")\n",
    "    loadscans.get_data()\n",
    "    loadscans_img_dict = loadscans.img_dict\n",
    "    for filename, file_data in loadscans_img_dict.items():\n",
    "        df_grain_stats_image = df_grain_stats[df_grain_stats[\"image\"] == filename]\n",
    "        full_image = file_data[\"image\"]\n",
    "        full_mask = file_data[\"grain_tensors\"][\"above\"]\n",
    "        pixel_to_nm_scaling = file_data[\"pixel_to_nm_scaling\"]\n",
    "        ordered_trace_data = file_data[\"ordered_traces\"][\"above\"]\n",
    "        try:\n",
    "            nodestats_data = file_data[\"nodestats\"][\"above\"][\"stats\"]\n",
    "        except KeyError:\n",
    "            nodestats_data = None\n",
    "        for current_grain_id_str, grain_ordered_trace_data in ordered_trace_data.items():\n",
    "            grain_id = int(re.sub(r\"grain_\", \"\", current_grain_id_str))\n",
    "            df_grain_stats_grain = df_grain_stats_image[df_grain_stats_image[\"grain_number\"] == grain_id]\n",
    "            # get the irradiation dose from the folder path in the form \"{dose_percentage}_percent_damage\"\n",
    "            if \"Controls\" in sample_type:\n",
    "                dose_percentage = 0\n",
    "            else:\n",
    "                dose_percentage_match = re.search(r\"(\\d+)_percent_damage\", str(sample_type))\n",
    "                if dose_percentage_match:\n",
    "                    dose_percentage = int(dose_percentage_match.group(1))\n",
    "                else:\n",
    "                    raise ValueError(f\"could not extract dose percentage from folder path {sample_type}\")\n",
    "            smallest_bounding_area = df_grain_stats_grain[\"smallest_bounding_area\"].values[0]\n",
    "            aspect_ratio = df_grain_stats_grain[\"aspect_ratio\"].values[0]\n",
    "            total_contour_length = df_grain_stats_grain[\"total_contour_length\"].values[0]\n",
    "            num_crossings = df_grain_stats_grain[\"num_crossings\"].values[0]\n",
    "\n",
    "            all_molecule_data = {}\n",
    "            for current_molecule_id_str, molecule_ordered_trace_data in grain_ordered_trace_data.items():\n",
    "                molecule_data = {}\n",
    "                molecule_id = int(re.sub(r\"mol_\", \"\", current_molecule_id_str))\n",
    "                ordered_coords = molecule_ordered_trace_data[\"ordered_coords\"]\n",
    "                molecule_data[\"heights\"] = molecule_ordered_trace_data[\"heights\"]\n",
    "                molecule_data[\"distances\"] = molecule_ordered_trace_data[\"distances\"]\n",
    "                molecule_data[\"circular\"] = molecule_ordered_trace_data[\"mol_stats\"][\"circular\"]\n",
    "                bbox = molecule_ordered_trace_data[\"bbox\"]\n",
    "\n",
    "                splining_coords = file_data[\"splining\"][\"above\"][current_grain_id_str][current_molecule_id_str][\n",
    "                    \"spline_coords\"\n",
    "                ]\n",
    "                curvatures = file_data[\"grain_curvature_stats\"][\"above\"][current_grain_id_str][current_molecule_id_str]\n",
    "                molecule_data[\"curvatures\"] = curvatures\n",
    "\n",
    "                # bbox will be the same for all molecules so this is okay\n",
    "                bbox_square = make_bounding_box_square(\n",
    "                    crop_min_row=bbox[0], crop_min_col=bbox[1], crop_max_row=bbox[2], crop_max_col=bbox[3]\n",
    "                )\n",
    "                bbox_padded = pad_bounding_box_cutting_off_at_image_bounds(\n",
    "                    crop_min_row=bbox_square[0],\n",
    "                    crop_min_col=bbox_square[1],\n",
    "                    crop_max_row=bbox_square[2],\n",
    "                    crop_max_col=bbox_square[3],\n",
    "                    image_shape=full_image.shape,\n",
    "                    padding=bbox_padding,\n",
    "                )\n",
    "                added_left = bbox_padded[1] - bbox[1]\n",
    "                added_top = bbox_padded[0] - bbox[0]\n",
    "\n",
    "                # adjust the splining coords to account for padding\n",
    "                splining_coords[:, 0] -= added_top\n",
    "                splining_coords[:, 1] -= added_left\n",
    "                molecule_data[\"spline_coords\"] = splining_coords\n",
    "\n",
    "                # adjust the ordered coords to account for padding\n",
    "                ordered_coords[:, 0] -= added_top\n",
    "                ordered_coords[:, 1] -= added_left\n",
    "                molecule_data[\"ordered_coords\"] = ordered_coords\n",
    "\n",
    "                all_molecule_data[molecule_id] = molecule_data\n",
    "\n",
    "            mask = full_mask[\n",
    "                bbox_padded[0] : bbox_padded[2],\n",
    "                bbox_padded[1] : bbox_padded[3],\n",
    "            ]\n",
    "\n",
    "            image = full_image[\n",
    "                bbox_padded[0] : bbox_padded[2],\n",
    "                bbox_padded[1] : bbox_padded[3],\n",
    "            ]\n",
    "\n",
    "            all_node_coords = []\n",
    "            num_nodes: int = 0\n",
    "            if nodestats_data is not None:\n",
    "                try:\n",
    "                    grain_nodestats_data = nodestats_data[current_grain_id_str]\n",
    "                    num_nodes = len(grain_nodestats_data)\n",
    "                    for _node_index, node_data in grain_nodestats_data.items():\n",
    "                        node_coords = node_data[\"coords\"]\n",
    "                        # adjust the node coords to account for padding\n",
    "                        node_coords[:, 0] -= added_top\n",
    "                        node_coords[:, 1] -= added_left\n",
    "                        for node_coord in node_coords:\n",
    "                            all_node_coords.append(node_coord)\n",
    "                except KeyError as e:\n",
    "                    if \"grain_\" in str(e):\n",
    "                        # grain has no nodestats data here, skip\n",
    "                        pass\n",
    "            all_node_coords_array = np.array(all_node_coords)\n",
    "\n",
    "            grain_model = GrainModel(\n",
    "                grain_id=grain_id,\n",
    "                filename=filename,\n",
    "                pixel_to_nm_scaling=pixel_to_nm_scaling,\n",
    "                folder=str(sample_type),\n",
    "                percent_damage=dose_percentage,\n",
    "                bbox=bbox_padded,\n",
    "                image=image,\n",
    "                mask=mask,\n",
    "                aspect_ratio=aspect_ratio,\n",
    "                total_contour_length=total_contour_length,\n",
    "                num_crossings=num_crossings,\n",
    "                molecule_data=all_molecule_data,\n",
    "                added_left=added_left,\n",
    "                added_top=added_top,\n",
    "                padding=bbox_padding,\n",
    "                node_coords=all_node_coords_array,\n",
    "                num_nodes=num_nodes,\n",
    "                smallest_bounding_area=smallest_bounding_area,\n",
    "            )\n",
    "\n",
    "            grain_model_collection.add_grain(grain_model)\n",
    "    return grain_model_collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topostats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
