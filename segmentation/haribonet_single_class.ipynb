{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from unet import unet_model\n",
    "import random\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "LOGGER = logging.getLogger()\n",
    "from datetime import datetime\n",
    "\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.filters import hessian\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "from skimage.morphology import label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for key, value in os.environ.items():\n",
    "#     print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that your GPU is working\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seeds\n",
    "SEED = 5\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# Set the normalisation bounds for the molecules in nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MacOS\n",
    "# ORIGINAL_IMAGE_DIR = Path(\n",
    "#     \"/Users/sylvi/topo_data/hariborings/training_data/cropped/dna_only/images_256/\"\n",
    "# )\n",
    "# MASK_DIR = Path(\"/Users/sylvi/topo_data/hariborings/training_data/cropped/dna_only/masks_256/\")\n",
    "# ORIGINAL_IMAGE_DIR = Path(\"/Users/sylvi/topo_data/hariborings/training_data/cropped/dna_cas9/images_256/\")\n",
    "# MASK_DIR = Path(\"/Users/sylvi/topo_data/hariborings/training_data/cropped/dna_cas9/masks_256_ring/\")\n",
    "\n",
    "# DNA ONLY SHARPER\n",
    "ORIGINAL_IMAGE_DIR = Path(\"/Users/sylvi/topo_data/hariborings/training_data/cropped/dna_only/images_extra_doritos_256/\")\n",
    "MASK_DIR = Path(\"/Users/sylvi/topo_data/hariborings/training_data/cropped/dna_only/masks_extra_doritos_256/\")\n",
    "\n",
    "# Upper and lower bounds for normalisation\n",
    "NORM_UPPER_BOUND = 5\n",
    "NORM_LOWER_BOUND = -1\n",
    "\n",
    "# MODEL_SAVE_DIR = Path(\"./saved_models\")\n",
    "# MacOS\n",
    "# MODEL_SAVE_DIR = Path(\"/Users/sylvi/topo_data/hariborings/training_data/cropped/saved_models/dna_cas9_ring\")\n",
    "MODEL_SAVE_DIR = Path(\"/Users/sylvi/topo_data/hariborings/saved_models/dna_only_extra_doritos/\")\n",
    "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get the number of .png images\n",
    "NUM_IMAGES = len(list(ORIGINAL_IMAGE_DIR.glob(\"*.npy\")))\n",
    "NUM_MASKS = len(list(MASK_DIR.glob(\"*.npy\")))\n",
    "print(f\"Number of images: {NUM_IMAGES}, number of masks: {NUM_MASKS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_and_shift(image: np.ndarray, ground_truth: np.ndarray, max_zoom_percentage: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"Zooms in on the image by a random amount between 0 and max_zoom_percentage,\n",
    "    then shifts the image by a random amount up to the number of zoomed pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Choose a zoom percentage and caluculate the number of pixels to zoom in\n",
    "    zoom = np.random.uniform(0, 0.1)\n",
    "    zoom_pixels = int(image.shape[0] * zoom)\n",
    "\n",
    "    # If there is zoom, choose a random shift\n",
    "    if int(zoom_pixels) > 0:\n",
    "        shift_x = np.random.randint(int(-zoom_pixels), int(zoom_pixels))\n",
    "        shift_y = np.random.randint(int(-zoom_pixels), int(zoom_pixels))\n",
    "\n",
    "        # Zoom and shift the image\n",
    "        zoomed_and_shifted_image = image[\n",
    "            zoom_pixels + shift_x : -zoom_pixels + shift_x,\n",
    "            zoom_pixels + shift_y : -zoom_pixels + shift_y,\n",
    "        ]\n",
    "        zoomed_and_shifted_ground_truth = ground_truth[\n",
    "            zoom_pixels + shift_x : -zoom_pixels + shift_x,\n",
    "            zoom_pixels + shift_y : -zoom_pixels + shift_y,\n",
    "        ]\n",
    "    else:\n",
    "        # Do nothing\n",
    "        shift_x = 0\n",
    "        shift_y = 0\n",
    "\n",
    "        zoomed_and_shifted_image = image\n",
    "        zoomed_and_shifted_ground_truth = ground_truth\n",
    "\n",
    "    return zoomed_and_shifted_image, zoomed_and_shifted_ground_truth\n",
    "\n",
    "\n",
    "# An image generator that loads images as they are needed\n",
    "def image_generator(image_indexes, batch_size=4):\n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_image_indexes = np.random.choice(a=image_indexes, size=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "\n",
    "        # Load the image and ground truth\n",
    "        for index in batch_image_indexes:\n",
    "            # Get the image\n",
    "            image = np.load(ORIGINAL_IMAGE_DIR / f\"image_{index}.npy\")\n",
    "            image = np.array(image)\n",
    "\n",
    "            ground_truth = np.load(MASK_DIR / f\"mask_{index}.npy\")\n",
    "            ground_truth = ground_truth.astype(bool)\n",
    "\n",
    "            # Randomly zoom and shift the image\n",
    "            image, ground_truth = zoom_and_shift(image=image, ground_truth=ground_truth, max_zoom_percentage=0.2)\n",
    "\n",
    "            # Resize to 256x256\n",
    "            image = Image.fromarray(image)\n",
    "            image = image.resize((256, 256), resample=Image.BILINEAR)\n",
    "            image = np.array(image)\n",
    "            ground_truth = Image.fromarray(ground_truth)\n",
    "            ground_truth = ground_truth.resize((256, 256), resample=Image.NEAREST)\n",
    "            ground_truth = np.array(ground_truth)\n",
    "\n",
    "            # Normalise the image\n",
    "            # image = image - np.min(image)\n",
    "            # image = image / np.max(image)\n",
    "            image = np.clip(image, NORM_LOWER_BOUND, NORM_UPPER_BOUND)\n",
    "            image = image - NORM_LOWER_BOUND\n",
    "            image = image / (NORM_UPPER_BOUND - NORM_LOWER_BOUND)\n",
    "\n",
    "            # Get the ground truth\n",
    "\n",
    "            # ground_truth = Image.fromarray(ground_truth)\n",
    "            # No interpolation\n",
    "            # ground_truth = ground_truth.resize((512, 512), resample=Image.NEAREST)\n",
    "            # ground_truth = np.array(ground_truth)\n",
    "\n",
    "            # Augment the images\n",
    "            # Flip the images 50% of the time\n",
    "            if random.choice([0, 1]) == 1:\n",
    "                image = np.flip(image, axis=1)\n",
    "                ground_truth = np.flip(ground_truth, axis=1)\n",
    "            # Rotate the images by either 0, 90, 180, or 270 degrees\n",
    "            rotation = random.choice([0, 1, 2, 3])\n",
    "            image = np.rot90(image, rotation)\n",
    "            ground_truth = np.rot90(ground_truth, rotation)\n",
    "\n",
    "            batch_input.append(image)\n",
    "            batch_output.append(ground_truth)\n",
    "\n",
    "        batch_x = np.array(batch_input).astype(np.float32)\n",
    "        batch_y = np.array(batch_output).astype(np.float32)\n",
    "\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the generator is doing the right thing\n",
    "batch_generator = image_generator([0, 1, 2, 3, 4], batch_size=4)\n",
    "(batch_x, batch_y) = next(batch_generator)\n",
    "for image, mask in zip(batch_x, batch_y):\n",
    "    print(f\"image shape: {image.shape}\")\n",
    "    print(f\"image max: {np.max(image)}\")\n",
    "    print(f\"image min: {np.min(image)}\")\n",
    "    print(f\"mask shape: {mask.shape}\")\n",
    "    print(f\"mask unique: {np.unique(mask)}\")\n",
    "    print(f\"mask dtype: {mask.dtype}\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 30))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title(\"image\")\n",
    "    ax[1].imshow(mask)\n",
    "    ax[1].set_title(\"mask\")\n",
    "    ax[2].imshow(image)\n",
    "    ax[2].imshow(mask, alpha=0.2)\n",
    "    ax[2].set_title(\"image with mask\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH, IMG_HEIGHT = (256, 256)\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 25\n",
    "EPOCHS = 45\n",
    "AUGMENTATION_FACTOR = 8\n",
    "LEARNING_RATE = 0.001\n",
    "TRAIN_TEST_SPLIT = 0.1\n",
    "LOSS_FUNCTION = \"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split what images are used for training and validation\n",
    "train_image_indexes, validation_image_indexes = train_test_split(\n",
    "    range(0, NUM_IMAGES), test_size=TRAIN_TEST_SPLIT, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Number of training images: {len(train_image_indexes)}\")\n",
    "print(f\"Number of validation images: {len(validation_image_indexes)}\")\n",
    "\n",
    "print(f\"Training image indexes: {train_image_indexes}\")\n",
    "print(f\"Validation image indexes: {validation_image_indexes}\")\n",
    "\n",
    "# Create the generators\n",
    "train_generator = image_generator(train_image_indexes, batch_size=BATCH_SIZE)\n",
    "validation_generator = image_generator(validation_image_indexes, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "model = unet_model(\n",
    "    IMG_HEIGHT=IMG_HEIGHT,\n",
    "    IMG_WIDTH=IMG_WIDTH,\n",
    "    IMG_CHANNELS=CHANNELS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    loss_function=LOSS_FUNCTION,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    # How many steps (batches of samples) to draw from generator before declaring one epoch finished and starting the next epoch\n",
    "    steps_per_epoch=(NUM_IMAGES // BATCH_SIZE) * AUGMENTATION_FACTOR,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    # How many steps (batches) to yield from validation generator at the end of every epoch\n",
    "    validation_steps=(NUM_IMAGES // BATCH_SIZE) * AUGMENTATION_FACTOR,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(30, 8))\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "ax[0].plot(epochs, loss, \"y\", label=\"Training loss\")\n",
    "ax[0].plot(epochs, val_loss, \"r\", label=\"Valdation loss\")\n",
    "ax[0].set_title(\"Training and validation loss\")\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "\n",
    "print(history.history.keys())\n",
    "# acc = history.history[\"mean_io_u\"]\n",
    "# val_acc = history.history[\"val_mean_io_u\"]\n",
    "\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "ax[1].plot(epochs, acc, \"y\", label=\"Training acc\")\n",
    "ax[1].plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
    "ax[1].set_title(\"Training and validation accuracy\")\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "if \"iou\" in history.history:\n",
    "    ax[1].plot(epochs, history.history[\"iou\"], \"b\", label=\"Training iou\")\n",
    "    ax[1].plot(epochs, history.history[\"val_iou\"], \"g\", label=\"Validation iou\")\n",
    "\n",
    "ax[1].legend()\n",
    "\n",
    "# acc = history.history[\"mean_io_u_1\"]\n",
    "# val_acc = history.history[\"val_mean_io_u_1\"]\n",
    "\n",
    "# ax[2].plot(epochs, acc, \"y\", label=\"Training acc\")\n",
    "# ax[2].plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
    "# ax[2].set_title(\"Training and validation accuracy\")\n",
    "# ax[2].set_xlabel(\"Epochs\")\n",
    "# ax[2].set_ylabel(\"Accuracy\")\n",
    "# ax[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results of the model on the testing set using the validation generator\n",
    "# Get the next batch from the generator\n",
    "(batch_x, batch_y) = next(validation_generator)\n",
    "# Predict the masks\n",
    "predicted_masks = model.predict(batch_x)\n",
    "# Threshold the masks\n",
    "threshold = 0.5\n",
    "predicted_masks = (predicted_masks > threshold).astype(np.uint8)\n",
    "# Show the results\n",
    "fig, ax = plt.subplots(len(batch_x), 4, figsize=(20, 10 * len(batch_x)))\n",
    "for index, (image, mask, predicted_mask) in enumerate(zip(batch_x, batch_y, predicted_masks)):\n",
    "    # Plot the images in a figure\n",
    "\n",
    "    ax[index, 0].imshow(image)\n",
    "    ax[index, 0].set_title(\"Image\")\n",
    "    ax[index, 1].imshow(mask)\n",
    "    ax[index, 1].set_title(\"True Mask\")\n",
    "    ax[index, 2].imshow(predicted_mask)\n",
    "    ax[index, 2].set_title(f\"Predicted Mask (thresholded at {threshold})\")\n",
    "    ax[index, 3].imshow(image)\n",
    "    ax[index, 3].imshow(predicted_mask, alpha=0.2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with date formatted as YYYY-MM-DD_HH-MM-SS\n",
    "# Also record the number of epochs, batch size, learning rate, and augmentation factor\n",
    "file_name = f\"haribonet_dna_only_single_class_extra_doritos_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_image-size-{IMG_HEIGHT}x{IMG_WIDTH}_epochs-{EPOCHS}_batch-size-{BATCH_SIZE}_learning-rate-{LEARNING_RATE}.h5\"\n",
    "\n",
    "model.save(MODEL_SAVE_DIR / file_name)\n",
    "\n",
    "print(f\"Model saved as {file_name} to {MODEL_SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "# model = tf.keras.models.load_model(\n",
    "#     MODEL_SAVE_DIR\n",
    "#     / \"haribonet_single_class_2023-12-19_13-13-45_image-size-256x256_epochs-30_batch-size-32_learning-rate-0.001.h5\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-or-truck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
