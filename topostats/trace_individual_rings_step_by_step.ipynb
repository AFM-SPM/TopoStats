{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union, Optional, Dict\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from skimage.morphology import binary_dilation, label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import label2rgb\n",
    "from skimage.graph import route_through_array\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import seaborn as sns\n",
    "from skimage.morphology import binary_erosion\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.feature import canny\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "from topostats.grain_finding_haribo_unet import (\n",
    "    predict_unet,\n",
    "    load_model,\n",
    "    predict_unet_multiclass_and_get_angle,\n",
    "    mean_iou,\n",
    "    predict_unet_multiclass,\n",
    ")\n",
    "\n",
    "from topostats.haribonet_process_grain_bound import process_grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_path = \"./haribonet_multiclass_improved_norm_big_95_bridging_v1_2024-01-17_10-58-46.h5\"\n",
    "print(f\"Loading Unet model: {model_path}\")\n",
    "model = load_model(model_path=model_path, custom_objects={\"mean_iou\": mean_iou})\n",
    "print(f\"Loaded Unet model: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ring images\n",
    "DATA_DIR = Path(\"/Users/sylvi/topo_data/hariborings/cas9_crops_p2nm/OT2_SC_p2nm\")\n",
    "IMAGE_SAVE_DIR = DATA_DIR / \"output_plots\"\n",
    "IMAGE_SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "image_files = sorted(DATA_DIR.glob(\"*.npy\"))\n",
    "print(f\"num images: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = image_files[0]\n",
    "print(f\"Processing image: {img_file}\")\n",
    "# Get the p_to_nm value from the file name. it comes after the image number and is a float\n",
    "p_to_nm = float(re.findall(r\"\\d+\\.\\d+\", img_file.name)[0])\n",
    "print(f\"p_to_nm: {p_to_nm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_masks = []\n",
    "# images = []\n",
    "# all_p_2_nm = []\n",
    "\n",
    "image_dict = {}\n",
    "\n",
    "for index, image_file in enumerate(image_files):\n",
    "    print(f\"Processing {image_file}\")\n",
    "    image = np.load(image_file)\n",
    "\n",
    "    p_to_nm = float(re.findall(r\"\\d+\\.\\d+\", image_file.name)[0])\n",
    "\n",
    "    if p_to_nm < 10.0:\n",
    "        # Predict mask\n",
    "        predicted_mask = predict_unet_multiclass(\n",
    "            model=model,\n",
    "            image=image,\n",
    "            confidence=0.5,\n",
    "            model_image_size=256,\n",
    "            image_output_dir=IMAGE_SAVE_DIR,\n",
    "            IMAGE_SAVE_DIR=IMAGE_SAVE_DIR,\n",
    "            filename=\"test\",\n",
    "            image_index=index,\n",
    "        )\n",
    "\n",
    "        # images.append(image)\n",
    "        # predicted_masks.append(predicted_mask)\n",
    "        # all_p_2_nm.append(p_to_nm)\n",
    "\n",
    "        image_dict[index] = {\n",
    "            \"image\": image,\n",
    "            \"predicted_mask\": predicted_mask,\n",
    "            \"p_to_nm\": p_to_nm,\n",
    "        }\n",
    "\n",
    "print(f\"len images: {len(image_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gallery of images and predicted masks\n",
    "def plot_images(images: list, masks: list, px_to_nms: list, width=5):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 2, figsize=(20, 30))\n",
    "    for i, (image, mask) in enumerate(zip(images, masks)):\n",
    "        ax[i // width, i % width * 2].imshow(image, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2].axis(\"off\")\n",
    "        ax[i // width, i % width * 2 + 1].imshow(mask, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2 + 1].axis(\"off\")\n",
    "        ax[i // width, i % width * 2].set_title(f\"p_to_nm: {px_to_nms[i]}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "plot_images(\n",
    "    images=[image_dict[i][\"image\"] for i in image_dict],\n",
    "    masks=[image_dict[i][\"predicted_mask\"] for i in image_dict],\n",
    "    px_to_nms=[image_dict[i][\"p_to_nm\"] for i in image_dict],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there is enough ring and gem pixels\n",
    "\n",
    "\n",
    "def check_ring_and_mask_exists(image, combined_predicted_mask):\n",
    "    # Check if there is a ring and mask larger than 100 pixels in the predicted mask\n",
    "\n",
    "    min_ring_pixels = 40\n",
    "    min_gem_pixels = 40\n",
    "\n",
    "    ring_mask = combined_predicted_mask == 1\n",
    "    if np.sum(ring_mask) < min_ring_pixels:\n",
    "        raise ValueError(f\"Ring pixels < {min_ring_pixels}\")\n",
    "    gem_mask = combined_predicted_mask == 2\n",
    "    if np.sum(gem_mask) < min_gem_pixels:\n",
    "        raise ValueError(f\"Gem pixels < {min_gem_pixels}\")\n",
    "\n",
    "    return combined_predicted_mask\n",
    "\n",
    "\n",
    "removed_images_large_enough_ring_gem = []\n",
    "removed_masks_large_enough_ring_gem = []\n",
    "\n",
    "image_dict_large_enough_ring_gem = {}\n",
    "\n",
    "# for index, (image, mask, p_2_nm) in enumerate(zip(images, predicted_masks, all_p_2_nm)):\n",
    "for index, image_dict_item in image_dict.items():\n",
    "    image = image_dict_item[\"image\"]\n",
    "    mask = image_dict_item[\"predicted_mask\"]\n",
    "    p_2_nm = image_dict_item[\"p_to_nm\"]\n",
    "\n",
    "    # Check if there is sufficient ring and gem pixels\n",
    "    try:\n",
    "        mask = check_ring_and_mask_exists(image, mask)\n",
    "        image_dict_large_enough_ring_gem[index] = image_dict_item\n",
    "        image_dict_large_enough_ring_gem[index][\"predicted_mask\"] = mask\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping image {index}: {e}\")\n",
    "        removed_images_large_enough_ring_gem.append(image)\n",
    "        removed_masks_large_enough_ring_gem.append(mask)\n",
    "        continue\n",
    "\n",
    "for removed_image, removed_mask in zip(removed_images_large_enough_ring_gem, removed_masks_large_enough_ring_gem):\n",
    "    plt.imshow(removed_image, cmap=\"viridis\")\n",
    "    plt.imshow(removed_mask, alpha=0.5, cmap=\"viridis\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_small_gem_regions_into_ring(image, combined_predicted_mask):\n",
    "    # Make a copy of the combined predicted mask\n",
    "    combined_predicted_mask_copy = combined_predicted_mask.copy()\n",
    "    gem_mask = combined_predicted_mask == 2\n",
    "\n",
    "    # Find the largest gem region\n",
    "    gem_labels = label(gem_mask)\n",
    "    gem_regions = regionprops(gem_labels)\n",
    "    gem_areas = [region.area for region in gem_regions]\n",
    "    print(f\"gem_areas: {gem_areas}\")\n",
    "    largest_gem_region = gem_regions[np.argmax(gem_areas)]\n",
    "\n",
    "    # For all the other regions, check if they touch a ring region\n",
    "    for region in gem_regions:\n",
    "        if region.label == largest_gem_region.label:\n",
    "            continue\n",
    "        # Get only the pixels in the region\n",
    "        region_mask = gem_labels == region.label\n",
    "        # Dilate the region\n",
    "        small_gem_dilation_strength = 5\n",
    "        dilated_region_mask = region_mask\n",
    "        for i in range(small_gem_dilation_strength):\n",
    "            dilated_region_mask = binary_dilation(dilated_region_mask)\n",
    "        # Get the intersection with the ring mask\n",
    "        predicted_ring_mask = combined_predicted_mask == 1\n",
    "        intersection = dilated_region_mask & predicted_ring_mask\n",
    "        # If there is an intersection, then it is a ring\n",
    "        if np.any(intersection):\n",
    "            combined_predicted_mask[dilated_region_mask] = 1\n",
    "\n",
    "    # # Plot them side by side\n",
    "    # fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    # ax[0].imshow(image)\n",
    "    # ax[0].set_title(\"Image\")\n",
    "    # ax[1].imshow(combined_predicted_mask_copy)\n",
    "    # ax[1].set_title(\"Predicted Mask (Before)\")\n",
    "    # ax[2].imshow(combined_predicted_mask)\n",
    "    # ax[2].set_title(\"Predicted Mask (After)\")\n",
    "    # plt.show()\n",
    "\n",
    "    return combined_predicted_mask\n",
    "\n",
    "\n",
    "image_dict_small_gem_regions_into_ring = {}\n",
    "\n",
    "# predicted_masks_small_gem_regions_into_ring = []\n",
    "# images_small_gem_regions_into_ring = []\n",
    "# p_2_nm_small_gem_regions_into_ring = []\n",
    "\n",
    "for index, image_dict_item in image_dict_large_enough_ring_gem.items():\n",
    "    image = image_dict_item[\"image\"]\n",
    "    mask = image_dict_item[\"predicted_mask\"]\n",
    "    p_2_nm = image_dict_item[\"p_to_nm\"]\n",
    "\n",
    "    print(f\"processing image {index}\")\n",
    "    combined_predicted_mask = mask.copy()\n",
    "    combined_predicted_mask = turn_small_gem_regions_into_ring(\n",
    "        image=image,\n",
    "        combined_predicted_mask=combined_predicted_mask,\n",
    "    )\n",
    "\n",
    "    image_dict_small_gem_regions_into_ring[index] = image_dict_item\n",
    "    image_dict_small_gem_regions_into_ring[index][\"predicted_mask\"] = combined_predicted_mask\n",
    "\n",
    "plot_images(\n",
    "    images=[image_dict_small_gem_regions_into_ring[i][\"image\"] for i in image_dict_small_gem_regions_into_ring],\n",
    "    masks=[image_dict_small_gem_regions_into_ring[i][\"predicted_mask\"] for i in image_dict_small_gem_regions_into_ring],\n",
    "    px_to_nms=[image_dict_small_gem_regions_into_ring[i][\"p_to_nm\"] for i in image_dict_small_gem_regions_into_ring],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all but largest ring region. Connectivity should not include diagonals\n",
    "\n",
    "image_dict_largest_ring = {}\n",
    "\n",
    "\n",
    "def remove_all_but_largest_ring_region(image, combined_predicted_mask):\n",
    "    ring_mask = combined_predicted_mask == 1\n",
    "    # Find the largest ring region\n",
    "    ring_labels = label(ring_mask, connectivity=1)\n",
    "    ring_regions = regionprops(ring_labels)\n",
    "    ring_areas = [region.area for region in ring_regions]\n",
    "    largest_ring_region = ring_regions[np.argmax(ring_areas)]\n",
    "    # For all the other regions, set them to 0\n",
    "    for region in ring_regions:\n",
    "        if region.label == largest_ring_region.label:\n",
    "            continue\n",
    "        # Get only the pixels in the region\n",
    "        region_mask = ring_labels == region.label\n",
    "        combined_predicted_mask[region_mask] = 0\n",
    "\n",
    "    return combined_predicted_mask\n",
    "\n",
    "\n",
    "for index, image_dict_item in image_dict_small_gem_regions_into_ring.items():\n",
    "    image = image_dict_item[\"image\"]\n",
    "    mask = image_dict_item[\"predicted_mask\"]\n",
    "    p_2_nm = image_dict_item[\"p_to_nm\"]\n",
    "\n",
    "    combined_predicted_mask = mask.copy()\n",
    "    combined_predicted_mask = remove_all_but_largest_ring_region(\n",
    "        image=image,\n",
    "        combined_predicted_mask=combined_predicted_mask,\n",
    "    )\n",
    "\n",
    "    image_dict_largest_ring[index] = image_dict_item\n",
    "    image_dict_largest_ring[index][\"predicted_mask\"] = combined_predicted_mask\n",
    "\n",
    "plot_images(\n",
    "    images=[image_dict_largest_ring[i][\"image\"] for i in image_dict_largest_ring],\n",
    "    masks=[image_dict_largest_ring[i][\"predicted_mask\"] for i in image_dict_largest_ring],\n",
    "    px_to_nms=[image_dict_largest_ring[i][\"p_to_nm\"] for i in image_dict_largest_ring],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine the number of connection points between ring and gem\n",
    "\n",
    "\n",
    "def get_number_of_connection_points(image, combined_mask):\n",
    "    # Get the number of connection points between the ring and gem\n",
    "    ring_mask = combined_mask == 1\n",
    "    gem_mask = combined_mask == 2\n",
    "    # Dilate the ring mask\n",
    "    gem_dilation_strength = 1\n",
    "    dilated_gem_mask = gem_mask\n",
    "    for i in range(gem_dilation_strength):\n",
    "        dilated_gem_mask = binary_dilation(dilated_gem_mask)\n",
    "    # Get the intersection with the gem mask\n",
    "    intersection = dilated_gem_mask & ring_mask\n",
    "\n",
    "    # Get number of separate connection point regions\n",
    "    intersection_labels = label(intersection)\n",
    "    intersection_regions = regionprops(intersection_labels)\n",
    "    num_connection_points = len(intersection_regions)\n",
    "    return num_connection_points, intersection_labels\n",
    "\n",
    "\n",
    "# def find_middle_of_connection_points(image, combined_mask, intersection_labels):\n",
    "#     # Find the middle of the connection points by finding the pixel with the shortest distance to the centroid\n",
    "#     intersection_regions = regionprops(intersection_labels)\n",
    "#     region_0 = intersection_regions[0]\n",
    "#     region_1 = intersection_regions[1]\n",
    "#     region_0_centroid = region_0.centroid\n",
    "#     region_1_centroid = region_1.centroid\n",
    "#     region_0_distances_to_centroid = []\n",
    "#     region_1_distances_to_centroid = []\n",
    "#     for pixel in region_0.coords:\n",
    "#         region_0_distances_to_centroid.append(\n",
    "#             np.linalg.norm(np.array(pixel) - np.array(region_0_centroid))\n",
    "#         )\n",
    "#     for pixel in region_1.coords:\n",
    "#         region_1_distances_to_centroid.append(\n",
    "#             np.linalg.norm(np.array(pixel) - np.array(region_1_centroid))\n",
    "#         )\n",
    "#     region_0_distances_to_centroid = np.array(region_0_distances_to_centroid)\n",
    "#     region_1_distances_to_centroid = np.array(region_1_distances_to_centroid)\n",
    "#     region_0_min_distance_to_centroid = np.min(region_0_distances_to_centroid)\n",
    "#     region_1_min_distance_to_centroid = np.min(region_1_distances_to_centroid)\n",
    "#     region_0_min_distance_to_centroid_index = np.argmin(\n",
    "#         region_0_distances_to_centroid\n",
    "#     )\n",
    "#     region_1_min_distance_to_centroid_index = np.argmin(\n",
    "#         region_1_distances_to_centroid\n",
    "#     )\n",
    "#     region_0_min_distance_to_centroid_pixel = region_0.coords[\n",
    "#         region_0_min_distance_to_centroid_index\n",
    "#     ]\n",
    "#     region_1_min_distance_to_centroid_pixel = region_1.coords[\n",
    "#         region_1_min_distance_to_centroid_index\n",
    "#     ]\n",
    "#     region_0_min_distance_to_centroid_pixel = np.array(\n",
    "#         region_0_min_distance_to_centroid_pixel\n",
    "#     )\n",
    "#     region_1_min_distance_to_centroid_pixel = np.array(\n",
    "#         region_1_min_distance_to_centroid_pixel\n",
    "#     )\n",
    "\n",
    "#     return (region_0_min_distance_to_centroid_pixel, region_1_min_distance_to_centroid_pixel)\n",
    "\n",
    "\n",
    "# Find connecting regions for all images\n",
    "image_dict_2_connection_points = {}\n",
    "# images_2_connection_points = []\n",
    "# masks_2_connection_points = []\n",
    "# p_2_nm_2_connection_points = []\n",
    "images_not_2_connection_points = []\n",
    "masks_not_2_connection_points = []\n",
    "# all_intersection_labels = []\n",
    "for index, image_dict_item in image_dict_largest_ring.items():\n",
    "    image = image_dict_item[\"image\"]\n",
    "    mask = image_dict_item[\"predicted_mask\"]\n",
    "    p_2_nm = image_dict_item[\"p_to_nm\"]\n",
    "\n",
    "    num_connection_points, intersection_labels = get_number_of_connection_points(\n",
    "        image=image,\n",
    "        combined_mask=mask,\n",
    "    )\n",
    "    if num_connection_points != 2:\n",
    "        images_not_2_connection_points.append(image)\n",
    "        masks_not_2_connection_points.append(mask)\n",
    "    else:\n",
    "        image_dict_2_connection_points[index] = image_dict_item\n",
    "        image_dict_2_connection_points[index][\"intersection_labels\"] = intersection_labels\n",
    "\n",
    "        # images_2_connection_points.append(image)\n",
    "        # masks_2_connection_points.append(mask)\n",
    "        # all_intersection_labels.append(intersection_labels)\n",
    "        # p_2_nm_2_connection_points.append(p_2_nm)\n",
    "\n",
    "print(f\"num failed: {len(images_not_2_connection_points)}\")\n",
    "print(f\"num passed: {len(image_dict_2_connection_points)}\")\n",
    "\n",
    "plot_images(\n",
    "    images=images_not_2_connection_points,\n",
    "    masks=masks_not_2_connection_points,\n",
    "    px_to_nms=[image_dict_2_connection_points[i][\"p_to_nm\"] for i in image_dict_2_connection_points],\n",
    ")\n",
    "\n",
    "# plot_images(\n",
    "#     images=images_2_connection_points,\n",
    "#     masks=masks_2_connection_points,\n",
    "# )\n",
    "\n",
    "\n",
    "def plot_images_with_overlays(images: list, masks: list, overlays: list, px_to_nms: list, width=5):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 2, figsize=(20, 30))\n",
    "    for i, (image, mask, overlay) in enumerate(zip(images, masks, overlays)):\n",
    "        ax[i // width, i % width * 2].imshow(image, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2].axis(\"off\")\n",
    "        ax[i // width, i % width * 2 + 1].imshow(mask, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2 + 1].imshow(overlay > 0, alpha=0.5, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2 + 1].axis(\"off\")\n",
    "        ax[i // width, i % width * 2].set_title(f\"p_to_nm: {px_to_nms[i]}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "plot_images_with_overlays(\n",
    "    images=[image_dict_2_connection_points[i][\"image\"] for i in image_dict_2_connection_points],\n",
    "    masks=[image_dict_2_connection_points[i][\"predicted_mask\"] for i in image_dict_2_connection_points],\n",
    "    overlays=[image_dict_2_connection_points[i][\"intersection_labels\"] for i in image_dict_2_connection_points],\n",
    "    px_to_nms=[image_dict_2_connection_points[i][\"p_to_nm\"] for i in image_dict_2_connection_points],\n",
    ")\n",
    "\n",
    "# image = images_largest_ring[0]\n",
    "# mask = masks_largest_ring[0]\n",
    "\n",
    "# num_connection_points, intersection_labels = get_number_of_connection_points(\n",
    "#     image=image,\n",
    "#     combined_mask=mask,\n",
    "# )\n",
    "\n",
    "# connecting_midpoints = find_middle_of_connection_points(\n",
    "#     image=image,\n",
    "#     combined_mask=mask,\n",
    "#     intersection_labels=intersection_labels,\n",
    "# )\n",
    "\n",
    "# plt.imshow(image, cmap=\"viridis\")\n",
    "# plt.imshow(mask, alpha=0.5, cmap=\"viridis\")\n",
    "# plt.scatter(connecting_midpoints[0][1], connecting_midpoints[0][0], c=\"r\", s=5)\n",
    "# plt.scatter(connecting_midpoints[1][1], connecting_midpoints[1][0], c=\"b\", s=5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get distance transform for the masks\n",
    "# index = 3\n",
    "# mask = masks_2_connection_points[index]\n",
    "# intersection_labels = all_intersection_labels[index]\n",
    "# plt.imshow(mask)\n",
    "# plt.imshow(intersection_labels > 0, alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "image_dict_paths = {}\n",
    "\n",
    "for index, image_dict_item in image_dict_2_connection_points.items():\n",
    "    image = image_dict_item[\"image\"]\n",
    "    mask = image_dict_item[\"predicted_mask\"]\n",
    "    p_2_nm = image_dict_item[\"p_to_nm\"]\n",
    "    intersection_labels = image_dict_item[\"intersection_labels\"]\n",
    "\n",
    "    # Get distance transform for the mask\n",
    "\n",
    "    distance_transform = distance_transform_edt(mask > 0)\n",
    "    distance_transform[mask == 2] = 0\n",
    "\n",
    "    # plt.imshow(distance_transform)\n",
    "    # plt.show()\n",
    "\n",
    "    # starting point is the point where intersection region 0 has the largest distance transform value\n",
    "    intersection_labels = label(intersection_labels)\n",
    "    intersection_regions = regionprops(intersection_labels)\n",
    "    region_0 = intersection_regions[0]\n",
    "    region_1 = intersection_regions[1]\n",
    "    region_0_distance_transform_values = []\n",
    "    region_1_distance_transform_values = []\n",
    "    for pixel in region_0.coords:\n",
    "        region_0_distance_transform_values.append(distance_transform[pixel[0], pixel[1]])\n",
    "    for pixel in region_1.coords:\n",
    "        region_1_distance_transform_values.append(distance_transform[pixel[0], pixel[1]])\n",
    "    region_0_distance_transform_values = np.array(region_0_distance_transform_values)\n",
    "    region_1_distance_transform_values = np.array(region_1_distance_transform_values)\n",
    "    region_0_max_distance_transform_value = np.max(region_0_distance_transform_values)\n",
    "    region_1_max_distance_transform_value = np.max(region_1_distance_transform_values)\n",
    "    region_0_max_distance_transform_value_index = np.argmax(region_0_distance_transform_values)\n",
    "    region_1_max_distance_transform_value_index = np.argmax(region_1_distance_transform_values)\n",
    "    region_0_max_distance_transform_value_pixel = region_0.coords[region_0_max_distance_transform_value_index]\n",
    "    region_1_max_distance_transform_value_pixel = region_1.coords[region_1_max_distance_transform_value_index]\n",
    "\n",
    "    # # plot the points\n",
    "    # plt.imshow(mask)\n",
    "    # plt.imshow(intersection_labels > 0, alpha=0.5)\n",
    "    # plt.scatter(region_0_max_distance_transform_value_pixel[1], region_0_max_distance_transform_value_pixel[0], c=\"r\", s=5)\n",
    "    # plt.scatter(region_1_max_distance_transform_value_pixel[1], region_1_max_distance_transform_value_pixel[0], c=\"b\", s=5)\n",
    "    # plt.show()\n",
    "\n",
    "    start_point = (\n",
    "        region_0_max_distance_transform_value_pixel[0],\n",
    "        region_0_max_distance_transform_value_pixel[1],\n",
    "    )\n",
    "    end_point = (\n",
    "        region_1_max_distance_transform_value_pixel[0],\n",
    "        region_1_max_distance_transform_value_pixel[1],\n",
    "    )\n",
    "\n",
    "    inverted_distance_transform = np.max(distance_transform) - distance_transform\n",
    "    # plt.imshow(inverted_distance_transform)\n",
    "    inverted_distance_transform[inverted_distance_transform == np.max(inverted_distance_transform)] = 1000\n",
    "\n",
    "    # Find the shortest path between the two points weighted by the inverted distance transform\n",
    "    route, weight = route_through_array(inverted_distance_transform, start_point, end_point)\n",
    "    route = np.array(route)\n",
    "\n",
    "    # plt.imshow(inverted_distance_transform)\n",
    "    # plt.plot(route[:, 1], route[:, 0], \"r-\")\n",
    "    # plt.show()\n",
    "\n",
    "    image_dict_paths[index] = image_dict_item\n",
    "    image_dict_paths[index][\"path\"] = route\n",
    "\n",
    "\n",
    "def plot_images_with_paths(images: list, masks: list, paths: list, px_to_nms: list, width=5):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 2, figsize=(20, 30))\n",
    "    for i, (image, mask, path) in enumerate(zip(images, masks, paths)):\n",
    "        ax[i // width, i % width * 2].imshow(image, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2].axis(\"off\")\n",
    "        ax[i // width, i % width * 2 + 1].imshow(mask, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2 + 1].plot(path[:, 1], path[:, 0], \"r-\")\n",
    "        ax[i // width, i % width * 2 + 1].axis(\"off\")\n",
    "        ax[i // width, i % width * 2].set_title(f\"p_to_nm: {px_to_nms[i]}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "plot_images_with_paths(\n",
    "    images=[image_dict_paths[i][\"image\"] for i in image_dict_paths],\n",
    "    masks=[image_dict_paths[i][\"predicted_mask\"] for i in image_dict_paths],\n",
    "    paths=[image_dict_paths[i][\"path\"] for i in image_dict_paths],\n",
    "    px_to_nms=[image_dict_paths[i][\"p_to_nm\"] for i in image_dict_paths],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate start and end angles for the paths\n",
    "\n",
    "\n",
    "def calculate_start_and_end_angles(path):\n",
    "    # Calculate the start and end angles for the path by averaging the angle from the start and end points to the next points\n",
    "\n",
    "    num_averaging_points = 5\n",
    "\n",
    "    start_origin = path[0]\n",
    "    end_origin = path[-1]\n",
    "\n",
    "    start_points = path[1:num_averaging_points]\n",
    "    end_points = path[-num_averaging_points:-1]\n",
    "\n",
    "    # Calculate mean vector from start point to next points\n",
    "    start_vectors = start_points - start_origin\n",
    "    start_mean_vector = np.mean(start_vectors, axis=0)\n",
    "\n",
    "    # Calculate mean vector from end point to next points\n",
    "    end_vectors = end_points - end_origin\n",
    "    end_mean_vector = np.mean(end_vectors, axis=0)\n",
    "\n",
    "    # Calculate start and end angles\n",
    "    start_angle = np.arctan2(start_mean_vector[0], start_mean_vector[1])\n",
    "    end_angle = np.arctan2(end_mean_vector[0], end_mean_vector[1])\n",
    "\n",
    "    angle_difference = np.abs(start_angle - end_angle)\n",
    "    if angle_difference > np.pi:\n",
    "        angle_difference = 2 * np.pi - angle_difference\n",
    "\n",
    "    # convert to degrees\n",
    "    angle_difference = angle_difference * 180 / np.pi\n",
    "\n",
    "    return (\n",
    "        angle_difference,\n",
    "        start_angle,\n",
    "        end_angle,\n",
    "        start_mean_vector,\n",
    "        end_mean_vector,\n",
    "        start_origin,\n",
    "        end_origin,\n",
    "    )\n",
    "\n",
    "\n",
    "# index = 22\n",
    "# path = paths[index]\n",
    "# image = images_2_connection_points[index]\n",
    "# mask = masks_2_connection_points[index]\n",
    "\n",
    "# (\n",
    "#     angle_difference,\n",
    "#     start_angle,\n",
    "#     end_angle,\n",
    "#     start_mean_vector,\n",
    "#     end_mean_vector,\n",
    "#     start_origin,\n",
    "#     end_origin,\n",
    "# ) = calculate_start_and_end_angles(path)\n",
    "\n",
    "# # Plot the start and end points and vectors\n",
    "# plt.imshow(image)\n",
    "# plt.imshow(mask, alpha=0.5)\n",
    "# plt.scatter(start_origin[1], start_origin[0], c=\"r\", s=5)\n",
    "# plt.scatter(end_origin[1], end_origin[0], c=\"b\", s=5)\n",
    "# # plot path\n",
    "# plt.plot(path[:, 1], path[:, 0], \"r-\")\n",
    "# plt.quiver(\n",
    "#     start_origin[1],\n",
    "#     start_origin[0],\n",
    "#     start_mean_vector[1],\n",
    "#     -start_mean_vector[0],\n",
    "#     color=\"r\",\n",
    "#     scale=10,\n",
    "# )\n",
    "# plt.quiver(\n",
    "#     end_origin[1],\n",
    "#     end_origin[0],\n",
    "#     end_mean_vector[1],\n",
    "#     -end_mean_vector[0],\n",
    "#     color=\"b\",\n",
    "#     scale=10,\n",
    "# )\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"angle difference: {angle_difference}\")\n",
    "\n",
    "\n",
    "def plot_images_with_paths_and_angles(\n",
    "    images: list,\n",
    "    masks: list,\n",
    "    paths: list,\n",
    "    angles: list,\n",
    "    start_angles: list,\n",
    "    end_angles: list,\n",
    "    start_origins: list,\n",
    "    end_origins: list,\n",
    "    px_to_nms: list,\n",
    "    width=5,\n",
    "):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 2, figsize=(20, 40))\n",
    "    for i, (\n",
    "        image,\n",
    "        mask,\n",
    "        path,\n",
    "        angle,\n",
    "        start_angle,\n",
    "        end_angle,\n",
    "        start_origin,\n",
    "        end_origin,\n",
    "    ) in enumerate(zip(images, masks, paths, angles, start_angles, end_angles, start_origins, end_origins)):\n",
    "        ax[i // width, i % width * 2].imshow(image, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2].axis(\"off\")\n",
    "        ax[i // width, i % width * 2 + 1].imshow(mask, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2 + 1].plot(path[:, 1], path[:, 0], \"r-\")\n",
    "        ax[i // width, i % width * 2 + 1].quiver(\n",
    "            start_origin[1],\n",
    "            start_origin[0],\n",
    "            np.cos(start_angle),\n",
    "            -np.sin(start_angle),\n",
    "            color=\"r\",\n",
    "            scale=3,\n",
    "        )\n",
    "        ax[i // width, i % width * 2 + 1].quiver(\n",
    "            end_origin[1],\n",
    "            end_origin[0],\n",
    "            np.cos(end_angle),\n",
    "            -np.sin(end_angle),\n",
    "            color=\"b\",\n",
    "            scale=3,\n",
    "        )\n",
    "        ax[i // width, i % width * 2 + 1].axis(\"off\")\n",
    "        ax[i // width, i % width * 2 + 1].set_title(f\"angle: {angle:.2f} degrees\")\n",
    "        ax[i // width, i % width * 2].set_title(f\"p_to_nm: {px_to_nms[i]}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "image_dict_angles = {}\n",
    "\n",
    "for index, image_dict_item in image_dict_paths.items():\n",
    "    image = image_dict_item[\"image\"]\n",
    "    mask = image_dict_item[\"predicted_mask\"]\n",
    "    p_2_nm = image_dict_item[\"p_to_nm\"]\n",
    "    path = image_dict_item[\"path\"]\n",
    "    (\n",
    "        angle_difference,\n",
    "        start_angle,\n",
    "        end_angle,\n",
    "        start_mean_vector,\n",
    "        end_mean_vector,\n",
    "        start_origin,\n",
    "        end_origin,\n",
    "    ) = calculate_start_and_end_angles(path)\n",
    "\n",
    "    image_dict_angles[index] = image_dict_item\n",
    "    image_dict_angles[index][\"angle_difference\"] = angle_difference\n",
    "    image_dict_angles[index][\"start_angle\"] = start_angle\n",
    "    image_dict_angles[index][\"end_angle\"] = end_angle\n",
    "    image_dict_angles[index][\"start_mean_vector\"] = start_mean_vector\n",
    "    image_dict_angles[index][\"end_mean_vector\"] = end_mean_vector\n",
    "    image_dict_angles[index][\"start_origin\"] = start_origin\n",
    "    image_dict_angles[index][\"end_origin\"] = end_origin\n",
    "\n",
    "plot_images_with_paths_and_angles(\n",
    "    images=[image_dict_angles[i][\"image\"] for i in image_dict_angles],\n",
    "    masks=[image_dict_angles[i][\"predicted_mask\"] for i in image_dict_angles],\n",
    "    paths=[image_dict_angles[i][\"path\"] for i in image_dict_angles],\n",
    "    angles=[image_dict_angles[i][\"angle_difference\"] for i in image_dict_angles],\n",
    "    start_angles=[image_dict_angles[i][\"start_angle\"] for i in image_dict_angles],\n",
    "    end_angles=[image_dict_angles[i][\"end_angle\"] for i in image_dict_angles],\n",
    "    start_origins=[image_dict_angles[i][\"start_origin\"] for i in image_dict_angles],\n",
    "    end_origins=[image_dict_angles[i][\"end_origin\"] for i in image_dict_angles],\n",
    "    px_to_nms=[image_dict_angles[i][\"p_to_nm\"] for i in image_dict_angles],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elongation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the elongation metric\n",
    "\n",
    "\n",
    "def signed_angle_between_vectors(v1, v2):\n",
    "    # Check that neither vector is 0\n",
    "    if np.all(v1 == 0) or np.all(v2 == 0):\n",
    "        raise ValueError(\"One of the vectors is 0\")\n",
    "\n",
    "    # Calculate the dot product\n",
    "    dot_product = np.dot(v1, v2)\n",
    "\n",
    "    # Calculate the norms of each vector\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "\n",
    "    # Calculate the cosine of the angle\n",
    "    cos_theta = dot_product / (norm_v1 * norm_v2)\n",
    "\n",
    "    angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
    "\n",
    "    # Calculate the cross product\n",
    "    cross_product = np.cross(v1, v2)\n",
    "\n",
    "    # If the cross product is positive, then the angle is negative\n",
    "    if cross_product > 0:\n",
    "        angle = -angle\n",
    "\n",
    "    # Convert to angle and return\n",
    "    return angle\n",
    "\n",
    "\n",
    "def rotate_points(points: np.ndarray, angle: float):\n",
    "    # Rotate the points by the angle\n",
    "    # print(f\"rotating by {np.degrees(angle)} degrees\")\n",
    "    # rotation_matrix = np.array([[-np.sin(angle), np.cos(angle)], [np.cos(angle), np.sin(angle)]])\n",
    "    rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
    "    rotated_points = np.dot(points, rotation_matrix)\n",
    "    return rotated_points\n",
    "\n",
    "\n",
    "def align_points_to_vertical(points: np.ndarray, orientation_vector: np.ndarray):\n",
    "    # Align the points to the vertical by rotating them by the angle between the orientation vector and the vertical\n",
    "    vertical_vector = np.array([1, 0])\n",
    "    angle = signed_angle_between_vectors(orientation_vector, vertical_vector)\n",
    "    rotated_points = rotate_points(points, angle)\n",
    "    rotated_orientation_vector = rotate_points(orientation_vector, angle)\n",
    "    return rotated_points, rotated_orientation_vector, -angle\n",
    "\n",
    "\n",
    "def plot_images_with_paths(\n",
    "    images: list,\n",
    "    masks: list,\n",
    "    paths: list,\n",
    "    centroids: list,\n",
    "    midpoints: list,\n",
    "    elongations: list,\n",
    "    px_to_nms: list,\n",
    "    bounding_boxes: list,\n",
    "    aspect_ratios: list,\n",
    "    width=5,\n",
    "    save_dir=None,\n",
    "):\n",
    "    num_images = len(images)\n",
    "    fig, ax = plt.subplots(np.ceil(num_images / width).astype(int), width * 2, figsize=(30, 30))\n",
    "    for i, (image, mask, path) in enumerate(zip(images, masks, paths)):\n",
    "        ax[i // width, i % width * 2].imshow(image, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2].axis(\"off\")\n",
    "        ax[i // width, i % width * 2 + 1].imshow(mask, cmap=\"viridis\")\n",
    "        ax[i // width, i % width * 2 + 1].plot(path[:, 1], path[:, 0], \"r-\")\n",
    "        ax[i // width, i % width * 2 + 1].axis(\"off\")\n",
    "        ax[i // width, i % width * 2 + 1].scatter(centroids[i][1], centroids[i][0], c=\"r\", s=5)\n",
    "        ax[i // width, i % width * 2 + 1].scatter(midpoints[i][1], midpoints[i][0], c=\"g\", s=5)\n",
    "        # Draw a line between midpoint and centroid\n",
    "        ax[i // width, i % width * 2 + 1].plot(\n",
    "            [centroids[i][1], midpoints[i][1]],\n",
    "            [centroids[i][0], midpoints[i][0]],\n",
    "            \"g-\",\n",
    "        )\n",
    "        # Plot the bounding box\n",
    "        ax[i // width, i % width * 2 + 1].plot(bounding_boxes[i][:, 1], bounding_boxes[i][:, 0], color=\"orange\")\n",
    "        ax[i // width, i % width * 2 + 1].set_title(\n",
    "            f\"||| elongation: {elongations[i]:.2f} nm | aspect ratio: {aspect_ratios[i]:.2f} | px_to_nm: {px_to_nms[i]} |||\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_dir is not None:\n",
    "        plt.savefig(save_dir, dpi=500)\n",
    "\n",
    "\n",
    "image_dict_elongation = {}\n",
    "\n",
    "for index, image_dict_path in image_dict_paths.items():\n",
    "    image = image_dict_path[\"image\"]\n",
    "    mask = image_dict_path[\"predicted_mask\"]\n",
    "    p_2_nm = image_dict_path[\"p_to_nm\"]\n",
    "    path = image_dict_path[\"path\"]\n",
    "\n",
    "    # Get the centroid of the path\n",
    "    path_centroid = np.mean(path, axis=0)\n",
    "\n",
    "    path_points_shifted = np.copy(path) - path_centroid\n",
    "\n",
    "    # Get the start and end points of the path\n",
    "    start_point = path[0]\n",
    "    end_point = path[-1]\n",
    "    start_point_end_point_midpoint = (start_point + end_point) / 2\n",
    "\n",
    "    elongation_vector = start_point_end_point_midpoint - path_centroid\n",
    "    elongation_vector_points = np.array(\n",
    "        [[start_point_end_point_midpoint[0], start_point_end_point_midpoint[1]], [path_centroid[0], path_centroid[1]]]\n",
    "    )\n",
    "\n",
    "    shifted_elongation_vector_points = elongation_vector_points - path_centroid\n",
    "\n",
    "    # Distance between midpoint and centroid\n",
    "    distance = np.linalg.norm(elongation_vector)\n",
    "\n",
    "    # Rotate the points\n",
    "    shifted_rotated_path_points, shifted_rotated_elongation_vector, angle_rad = align_points_to_vertical(\n",
    "        path_points_shifted, elongation_vector\n",
    "    )\n",
    "    # print(f\"rotated by {np.degrees(angle_rad)} degrees\")\n",
    "\n",
    "    # Plot image\n",
    "    # plt.imshow(image, cmap=\"viridis\")\n",
    "    # plt.plot(path[:, 1], path[:, 0])\n",
    "    # plt.scatter(path_centroid[1], path_centroid[0], c=\"r\", s=5)\n",
    "    # plt.plot(elongation_vector_points[:, 1], elongation_vector_points[:, 0])\n",
    "    # plt.title(f\"orientation: {np.degrees(angle_rad):.2f} degrees\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Plot points before rotation\n",
    "    # plt.scatter(path_points_shifted[:, 1], path_points_shifted[:, 0])\n",
    "    # plt.plot(shifted_elongation_vector_points[:, 1], shifted_elongation_vector_points[:, 0])\n",
    "    # plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Plot the points after rotation\n",
    "    # Move the points back to the original position\n",
    "    shifted_rotated_points = shifted_rotated_path_points\n",
    "    shifted_rotated_elongation_vector_points = np.array([[0, 0], shifted_rotated_elongation_vector])\n",
    "    # Find the bounding box of the rotated points\n",
    "    min_x = np.min(shifted_rotated_points[:, 0])\n",
    "    max_x = np.max(shifted_rotated_points[:, 0])\n",
    "    min_y = np.min(shifted_rotated_points[:, 1])\n",
    "    max_y = np.max(shifted_rotated_points[:, 1])\n",
    "\n",
    "    rotated_bounding_box = np.array([[min_x, min_y], [max_x, min_y], [max_x, max_y], [min_x, max_y], [min_x, min_y]])\n",
    "\n",
    "    aspect_ratio = (max_x - min_x) / (max_y - min_y)\n",
    "\n",
    "    # plt.scatter(shifted_rotated_points[:, 1], shifted_rotated_points[:, 0])\n",
    "    # plt.plot(shifted_rotated_elongation_vector_points[:, 1], shifted_rotated_elongation_vector_points[:, 0])\n",
    "    # # Plot the bounding box\n",
    "    # plt.plot(rotated_bounding_box[:, 1], rotated_bounding_box[:, 0], \"r-\")\n",
    "    # plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    # plt.show()\n",
    "\n",
    "    # Un-rotate the bounding box and points\n",
    "    unrotated_bounding_box = rotate_points(rotated_bounding_box, angle_rad) + path_centroid\n",
    "    unrotated_points = rotate_points(shifted_rotated_points, angle_rad) + path_centroid\n",
    "    unrotated_elongation_vector_points = (\n",
    "        rotate_points(shifted_rotated_elongation_vector_points, angle_rad) + path_centroid\n",
    "    )\n",
    "\n",
    "    # Plot the un-rotated bounding box with un-rotated points\n",
    "    # plt.scatter(unrotated_points[:, 1], unrotated_points[:, 0])\n",
    "    # plt.plot(unrotated_bounding_box[:, 1], unrotated_bounding_box[:, 0], \"r-\")\n",
    "    # plt.plot(unrotated_elongation_vector_points[:, 1], unrotated_elongation_vector_points[:, 0], \"g-\")\n",
    "    # plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    # plt.show()\n",
    "\n",
    "    image_dict_elongation[index] = image_dict_path\n",
    "    image_dict_elongation[index][\"path_centroid\"] = path_centroid\n",
    "    image_dict_elongation[index][\"start_point\"] = start_point\n",
    "    image_dict_elongation[index][\"end_point\"] = end_point\n",
    "    image_dict_elongation[index][\"start_point_end_point_midpoint\"] = start_point_end_point_midpoint\n",
    "    image_dict_elongation[index][\"distance\"] = distance * p_2_nm\n",
    "    image_dict_elongation[index][\"rotated_bounding_box\"] = unrotated_bounding_box\n",
    "    image_dict_elongation[index][\"aspect_ratio\"] = aspect_ratio\n",
    "\n",
    "    # if index > 5:\n",
    "    #     break\n",
    "\n",
    "\n",
    "# Plot the paths and centroids\n",
    "plot_images_with_paths(\n",
    "    images=[image_dict_elongation[i][\"image\"] for i in image_dict_elongation],\n",
    "    masks=[image_dict_elongation[i][\"predicted_mask\"] for i in image_dict_elongation],\n",
    "    paths=[image_dict_elongation[i][\"path\"] for i in image_dict_elongation],\n",
    "    centroids=[image_dict_elongation[i][\"path_centroid\"] for i in image_dict_elongation],\n",
    "    midpoints=[image_dict_elongation[i][\"start_point_end_point_midpoint\"] for i in image_dict_elongation],\n",
    "    elongations=[image_dict_elongation[i][\"distance\"] for i in image_dict_elongation],\n",
    "    px_to_nms=[image_dict_elongation[i][\"p_to_nm\"] for i in image_dict_elongation],\n",
    "    bounding_boxes=[image_dict_elongation[i][\"rotated_bounding_box\"] for i in image_dict_elongation],\n",
    "    aspect_ratios=[image_dict_elongation[i][\"aspect_ratio\"] for i in image_dict_elongation],\n",
    "    save_dir=IMAGE_SAVE_DIR / \"elongation_images.png\",\n",
    ")\n",
    "\n",
    "# Save the elongation values to numpy file\n",
    "elongations = [image_dict_elongation[i][\"distance\"] for i in image_dict_elongation]\n",
    "np.save(IMAGE_SAVE_DIR / \"elongations.npy\", elongations)\n",
    "\n",
    "# Save the aspect ratios to numpy file\n",
    "aspect_ratios = [image_dict_elongation[i][\"aspect_ratio\"] for i in image_dict_elongation]\n",
    "np.save(IMAGE_SAVE_DIR / \"aspect_ratios.npy\", aspect_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot([image_dict_angles[i][\"angle_difference\"] for i in image_dict_angles], bins=\"auto\")\n",
    "plt.show()\n",
    "sns.kdeplot([image_dict_angles[i][\"angle_difference\"] for i in image_dict_angles])\n",
    "plt.show()\n",
    "\n",
    "np.save(\n",
    "    IMAGE_SAVE_DIR / \"angle_differences.npy\",\n",
    "    [image_dict_angles[i][\"angle_difference\"] for i in image_dict_angles],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edges(grain_mask: np.ndarray):\n",
    "    \"\"\"Class method that takes a 2D boolean numpy array image of a grain and returns a python list of the\n",
    "    coordinates of the edges of the grain.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    grain_mask : np.ndarray\n",
    "        A 2D numpy array image of a grain. Data in the array must be boolean.\n",
    "    edge_detection_method : str\n",
    "        Method used for detecting the edges of grain masks before calculating statistics on them.\n",
    "        Do not change unless you know exactly what this is doing. Options: \"binary_erosion\", \"canny\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    edges : list\n",
    "        List containing the coordinates of the edges of the grain.\n",
    "    \"\"\"\n",
    "    # Fill any holes\n",
    "    filled_grain_mask = binary_fill_holes(grain_mask)\n",
    "\n",
    "    # Add padding (needed for erosion)\n",
    "    padded = np.pad(filled_grain_mask, 1)\n",
    "    # Erode by 1 pixel\n",
    "    eroded = binary_erosion(padded)\n",
    "    # Remove padding\n",
    "    eroded = eroded[1:-1, 1:-1]\n",
    "\n",
    "    # Edges is equal to the difference between the\n",
    "    # original image and the eroded image.\n",
    "    edges = filled_grain_mask.astype(int) - eroded.astype(int)\n",
    "\n",
    "    nonzero_coordinates = edges.nonzero()\n",
    "    # Get vector representation of the points\n",
    "    # FIXME : Switched to list comprehension but should be unnecessary to create this as a list as we can use\n",
    "    # np.stack() to combine the arrays and use that...\n",
    "    # return np.stack(nonzero_coordinates, axis=1)\n",
    "    # edges = []\n",
    "    # for vector in np.transpose(nonzero_coordinates):\n",
    "    #     edges.append(list(vector))\n",
    "    # return edges\n",
    "    return [list(vector) for vector in np.transpose(nonzero_coordinates)]\n",
    "\n",
    "\n",
    "def is_clockwise(p_1: tuple, p_2: tuple, p_3: tuple) -> bool:\n",
    "    \"\"\"Function to determine if three points make a clockwise or counter-clockwise turn.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_1: tuple\n",
    "        First point to be used to calculate turn.\n",
    "    p_2: tuple\n",
    "        Second point to be used to calculate turn.\n",
    "    p_3: tuple\n",
    "        Third point to be used to calculate turn.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "        Indicator of whether turn is clockwise.\n",
    "    \"\"\"\n",
    "    # Determine if three points form a clockwise or counter-clockwise turn.\n",
    "    # I use the method of calculating the determinant of the following rotation matrix here. If the determinant\n",
    "    # is > 0 then the rotation is counter-clockwise.\n",
    "    rotation_matrix = np.array(((p_1[0], p_1[1], 1), (p_2[0], p_2[1], 1), (p_3[0], p_3[1], 1)))\n",
    "    return not np.linalg.det(rotation_matrix) > 0\n",
    "\n",
    "\n",
    "def get_triangle_height(base_point_1: np.array, base_point_2: np.array, top_point: np.array) -> float:\n",
    "    \"\"\"Returns the height of a triangle defined by the input point vectors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_point_1: np.ndarray\n",
    "        a base point of the triangle, eg: [5, 3].\n",
    "\n",
    "    base_point_2: np.ndarray\n",
    "        a base point of the triangle, eg: [8, 3].\n",
    "\n",
    "    top_point: np.ndarray\n",
    "        the top point of the triangle, defining the height from the line between the two base points, eg: [6,10].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        The height of the triangle - ie the shortest distance between the top point and the line between the two\n",
    "    base points.\n",
    "    \"\"\"\n",
    "\n",
    "    # Height of triangle = A/b = ||AB X AC|| / ||AB||\n",
    "    a_b = base_point_1 - base_point_2\n",
    "    a_c = base_point_1 - top_point\n",
    "    return np.linalg.norm(np.cross(a_b, a_c)) / np.linalg.norm(a_b)\n",
    "\n",
    "\n",
    "def get_max_min_ferets(edge_points: list):\n",
    "    \"\"\"Returns the minimum and maximum feret diameters for a grain.\n",
    "    These are defined as the smallest and greatest distances between\n",
    "    a pair of callipers that are rotating around a 2d object, maintaining\n",
    "    contact at all times.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edge_points: list\n",
    "        a list of the vector positions of the pixels comprising the edge of the\n",
    "        grain. Eg: [[0, 0], [1, 0], [2, 1]]\n",
    "    Returns\n",
    "    -------\n",
    "    min_feret: float\n",
    "        the minimum feret diameter of the grain\n",
    "    max_feret: float\n",
    "        the maximum feret diameter of the grain\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The method starts out by calculating the upper and lower convex hulls using\n",
    "    an algorithm based on the Graham Scan Algorithm [1]. Using these upper and\n",
    "    lower hulls, the callipers are simulated as rotating clockwise around the grain.\n",
    "    We determine the order in which vertices are encountered by comparing the\n",
    "    gradients of the slopes between vertices. An array of pairs of points that\n",
    "    are in contact with either calliper at a given time is created in order to\n",
    "    be able to calculate the maximum feret diameter. The minimum diameter is a\n",
    "    little tricky, since it won't simply be the shortest distance between two\n",
    "    contact points, but it will occur somewhere during the rotation around a\n",
    "    pair of contact points. It turns out that the point will always be such\n",
    "    that two points are in contact with one calliper while the other calliper\n",
    "    is in contact with another point. We can use this fact to be sure of finding\n",
    "    the smallest feret diameter, simply by testing each triangle of 3 contact points\n",
    "    as we iterate, finding the height of the triangle that is formed between the\n",
    "    three aforementioned points, as this will be the perpendicular distance between\n",
    "    the callipers.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] Graham, R.L. (1972).\n",
    "        \"An Efficient Algorithm for Determining the Convex Hull of a Finite Planar Set\".\n",
    "        Information Processing Letters. 1 (4): 132-133.\n",
    "        doi:10.1016/0020-0190(72)90045-2.\n",
    "    \"\"\"\n",
    "\n",
    "    min_feret_triangle = None\n",
    "\n",
    "    # Sort the vectors by their x coordinate and then by their y coordinate.\n",
    "    # The conversion between list and numpy array can be removed, though it would be harder\n",
    "    # to read.\n",
    "    edge_points.sort()\n",
    "    edge_points = np.array(edge_points)\n",
    "\n",
    "    # Construct upper and lower hulls for the edge points. Sadly we can't just use the standard hull\n",
    "    # that graham_scan() returns, since we need to separate the upper and lower hulls. I might streamline\n",
    "    # these two into one method later.\n",
    "    upper_hull = []\n",
    "    lower_hull = []\n",
    "    for point in edge_points:\n",
    "        while len(lower_hull) > 1 and is_clockwise(lower_hull[-2], lower_hull[-1], point):\n",
    "            lower_hull.pop()\n",
    "        lower_hull.append(point)\n",
    "        while len(upper_hull) > 1 and not is_clockwise(upper_hull[-2], upper_hull[-1], point):\n",
    "            upper_hull.pop()\n",
    "        upper_hull.append(point)\n",
    "\n",
    "    upper_hull = np.array(upper_hull)\n",
    "    lower_hull = np.array(lower_hull)\n",
    "\n",
    "    # Create list of contact vertices for calipers on the antipodal hulls\n",
    "    contact_points = []\n",
    "    upper_index = 0\n",
    "    lower_index = len(lower_hull) - 1\n",
    "    min_feret = None\n",
    "    while upper_index < len(upper_hull) - 1 or lower_index > 0:\n",
    "        contact_points.append([lower_hull[lower_index, :], upper_hull[upper_index, :]])\n",
    "        # If we have reached the end of the upper hull, continute iterating over the lower hull\n",
    "        if upper_index == len(upper_hull) - 1:\n",
    "            lower_index -= 1\n",
    "            small_feret = get_triangle_height(\n",
    "                np.array(lower_hull[lower_index + 1, :]),\n",
    "                np.array(lower_hull[lower_index, :]),\n",
    "                np.array(upper_hull[upper_index, :]),\n",
    "            )\n",
    "            if min_feret is None or small_feret < min_feret:\n",
    "                min_feret = small_feret\n",
    "                min_feret_triangle = [\n",
    "                    lower_hull[lower_index + 1, :],\n",
    "                    lower_hull[lower_index, :],\n",
    "                    upper_hull[upper_index, :],\n",
    "                ]\n",
    "        # If we have reached the end of the lower hull, continue iterating over the upper hull\n",
    "        elif lower_index == 0:\n",
    "            upper_index += 1\n",
    "            small_feret = get_triangle_height(\n",
    "                np.array(upper_hull[upper_index - 1, :]),\n",
    "                np.array(upper_hull[upper_index, :]),\n",
    "                np.array(lower_hull[lower_index, :]),\n",
    "            )\n",
    "            if min_feret is None or small_feret < min_feret:\n",
    "                min_feret = small_feret\n",
    "                min_feret_triangle = [\n",
    "                    lower_hull[lower_index + 1, :],\n",
    "                    lower_hull[lower_index, :],\n",
    "                    upper_hull[upper_index, :],\n",
    "                ]\n",
    "        # Check if the gradient of the last point and the proposed next point in the upper hull is greater than the gradient\n",
    "        # of the two corresponding points in the lower hull, if so, this means that the next point in the upper hull\n",
    "        # will be encountered before the next point in the lower hull and vice versa.\n",
    "        # Note that the calculation here for gradients is the simple delta upper_y / delta upper_x > delta lower_y / delta lower_x\n",
    "        # however I have multiplied through the denominators such that there are no instances of division by zero. The\n",
    "        # inequality still holds and provides what is needed.\n",
    "        elif (upper_hull[upper_index + 1, 1] - upper_hull[upper_index, 1]) * (\n",
    "            lower_hull[lower_index, 0] - lower_hull[lower_index - 1, 0]\n",
    "        ) > (lower_hull[lower_index, 1] - lower_hull[lower_index - 1, 1]) * (\n",
    "            upper_hull[upper_index + 1, 0] - upper_hull[upper_index, 0]\n",
    "        ):\n",
    "            # If the upper hull is encoutnered first, increment the iteration index for the upper hull\n",
    "            # Also consider the triangle that is made as the two upper hull vertices are colinear with the caliper\n",
    "            upper_index += 1\n",
    "            small_feret = get_triangle_height(\n",
    "                np.array(upper_hull[upper_index - 1, :]),\n",
    "                np.array(upper_hull[upper_index, :]),\n",
    "                np.array(lower_hull[lower_index, :]),\n",
    "            )\n",
    "            if min_feret is None or small_feret < min_feret:\n",
    "                min_feret = small_feret\n",
    "        else:\n",
    "            # The next point in the lower hull will be encountered first, so increment the lower hull iteration index.\n",
    "            lower_index -= 1\n",
    "            small_feret = get_triangle_height(\n",
    "                np.array(lower_hull[lower_index + 1, :]),\n",
    "                np.array(lower_hull[lower_index, :]),\n",
    "                np.array(upper_hull[upper_index, :]),\n",
    "            )\n",
    "\n",
    "            if min_feret is None or small_feret < min_feret:\n",
    "                min_feret = small_feret\n",
    "                min_feret_triangle = [\n",
    "                    lower_hull[lower_index + 1, :],\n",
    "                    lower_hull[lower_index, :],\n",
    "                    upper_hull[upper_index, :],\n",
    "                ]\n",
    "\n",
    "    contact_points = np.array(contact_points)\n",
    "\n",
    "    # Find the minimum and maximum distance in the contact points\n",
    "    max_feret = None\n",
    "    for point_pair in contact_points:\n",
    "        dist = np.sqrt((point_pair[0, 0] - point_pair[1, 0]) ** 2 + (point_pair[0, 1] - point_pair[1, 1]) ** 2)\n",
    "        if max_feret is None or max_feret < dist:\n",
    "            max_feret = dist\n",
    "\n",
    "    return min_feret, max_feret, min_feret_triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate min, max feret diameters for the ring masks\n",
    "\n",
    "image_dict_ferets = {}\n",
    "\n",
    "iteration_index = 0\n",
    "for index, image_dict_item in image_dict_angles.items():\n",
    "    # print(f\"iteration index: {iteration_index} / {len(image_dict_angles)}\")\n",
    "    iteration_index += 1\n",
    "\n",
    "    image = image_dict_item[\"image\"]\n",
    "    mask = image_dict_item[\"predicted_mask\"]\n",
    "    p_2_nm = image_dict_item[\"p_to_nm\"]\n",
    "    path = image_dict_item[\"path\"]\n",
    "\n",
    "    ring_mask = mask == 1\n",
    "\n",
    "    edge_points = calculate_edges(ring_mask)\n",
    "    # plot edge points\n",
    "    # plt.imshow(ring_mask)\n",
    "\n",
    "    min_feret, max_feret, min_feret_triangle = get_max_min_ferets(edge_points)\n",
    "\n",
    "    image_dict_ferets[index] = image_dict_item\n",
    "    image_dict_ferets[index][\"min_feret\"] = min_feret * p_2_nm\n",
    "    image_dict_ferets[index][\"max_feret\"] = max_feret * p_2_nm\n",
    "\n",
    "    # a_b = min_feret_triangle[0] - min_feret_triangle[1]\n",
    "    # a_c = min_feret_triangle[0] - min_feret_triangle[2]\n",
    "\n",
    "    # return np.linalg.norm(np.cross(a_b, a_c)) / np.linalg.norm(a_b)\n",
    "\n",
    "    # plt.imshow(image)\n",
    "    # plt.scatter(np.array(edge_points)[:, 1], np.array(edge_points)[:, 0], c=\"r\", s=5)\n",
    "    # plt.scatter(\n",
    "    #     np.array(min_feret_triangle)[:-1, 1], np.array(min_feret_triangle)[:-1, 0], c=\"y\", s=20\n",
    "    # )\n",
    "    # plt.scatter(\n",
    "    #     np.array(min_feret_triangle)[-1, 1], np.array(min_feret_triangle)[-1, 0], c=\"aqua\", s=20\n",
    "    # )\n",
    "\n",
    "    # min_feret_triangle = np.append(min_feret_triangle, [min_feret_triangle[0]], axis=0)\n",
    "    # plt.plot(\n",
    "    #     np.array(min_feret_triangle)[:, 1], np.array(min_feret_triangle)[:, 0], \"y\", linewidth=2\n",
    "    # )\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.imshow(image, cmap=\"viridis\")\n",
    "    # plt.show()\n",
    "    # plt.imshow(ring_mask, cmap=\"viridis\")\n",
    "    # plt.show()\n",
    "    # print(f\"min feret: {min_feret * p_2_nm}\")\n",
    "    # print(f\"min feret pixels: {min_feret} px_2_nm: {p_2_nm}\")\n",
    "\n",
    "\n",
    "# sns.histplot(\n",
    "#     [image_dict_ferets[i][\"min_feret\"] for i in image_dict_ferets], bins=\"auto\", label=\"min feret\"\n",
    "# )\n",
    "# sns.histplot(\n",
    "#     [image_dict_ferets[i][\"min_feret\"] for i in image_dict_ferets], bins=\"auto\", label=\"max feret\"\n",
    "# )\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "sns.kdeplot([image_dict_ferets[i][\"min_feret\"] for i in image_dict_ferets], label=\"min feret\")\n",
    "sns.kdeplot([image_dict_ferets[i][\"max_feret\"] for i in image_dict_ferets], label=\"max feret\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"min ferets: {[image_dict_ferets[i]['min_feret'] for i in image_dict_ferets]}\")\n",
    "print(f\"mean min feret: {np.mean([image_dict_ferets[i]['min_feret'] for i in image_dict_ferets])}\")\n",
    "\n",
    "\n",
    "np.save(\n",
    "    IMAGE_SAVE_DIR / \"min_ferets_updated.npy\",\n",
    "    [image_dict_ferets[i][\"min_feret\"] for i in image_dict_ferets],\n",
    ")\n",
    "np.save(\n",
    "    IMAGE_SAVE_DIR / \"max_ferets_updated.npy\",\n",
    "    [image_dict_ferets[i][\"min_feret\"] for i in image_dict_ferets],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rim_curvature(xs: np.ndarray, ys: np.ndarray, periodic: bool = True):\n",
    "    \"\"\"Calculate the curvature of a set of points. Uses the standard curvature definition of the derivative of the\n",
    "    tangent vector.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    xs: np.ndarray\n",
    "        One dimensional numpy array of x-coordinates of the points\n",
    "    ys: np.ndarray\n",
    "        One dimensional numpy array of y-coordinates of the points\n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        One-dimensional numpy array of curvatures for the spline.\n",
    "    \"\"\"\n",
    "\n",
    "    extension_length = xs.shape[0]\n",
    "    if periodic:\n",
    "        xs_extended = np.append(xs, xs)\n",
    "        xs_extended = np.append(xs_extended, xs)\n",
    "\n",
    "        ys_extended = np.append(ys, ys)\n",
    "        ys_extended = np.append(ys_extended, ys)\n",
    "        dx = np.gradient(xs_extended)\n",
    "        dy = np.gradient(ys_extended)\n",
    "    else:\n",
    "        dx = np.gradient(xs)\n",
    "        dy = np.gradient(ys)\n",
    "\n",
    "    d2x = np.gradient(dx)\n",
    "\n",
    "    d2y = np.gradient(dy)\n",
    "    curv = abs((dx * d2y - d2x * dy) / (dx * dx + dy * dy) ** 1.5)\n",
    "\n",
    "    if periodic:\n",
    "        curv = curv[extension_length : (len(curv) - extension_length)]\n",
    "\n",
    "    return curv\n",
    "\n",
    "\n",
    "def _interpolate_points_spline(points: np.ndarray, num_points: int, smoothing: float = 0.0, periodic: int = 1):\n",
    "    \"\"\"Interpolate a set of points using a spline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points: np.ndarray\n",
    "        Nx2 Numpy array of coordinates for the points.\n",
    "    num_points: int\n",
    "        The number of points to return following the calculated spline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    interpolated_points: np.ndarray\n",
    "        An Ix2 Numpy array of coordinates of the interpolated points, where I is the number of points\n",
    "        specified.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = splprep(points.T, u=None, s=smoothing, per=periodic)\n",
    "    x_spline = np.linspace(y.min(), y.max(), num_points)\n",
    "    x_new, y_new = splev(x_spline, x, der=0)\n",
    "    interpolated_points = np.array((x_new, y_new)).T\n",
    "    return interpolated_points\n",
    "\n",
    "\n",
    "def interpolate_spline_and_get_curvature(\n",
    "    points: np.ndarray, interpolation_number: int, smoothing: float = 0.0, periodic: int = 1\n",
    "):\n",
    "    \"\"\"Calculate the curvature for a set of points in a closed loop. Interpolates the points using a spline\n",
    "    to reduce anomalies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points: np.ndarray\n",
    "        2xN Numpy array of coordinates for the points.\n",
    "    interpolation_number: int\n",
    "        Number of interpolation points per point. Eg: for a set of 10 points and 2 interpolation points,\n",
    "        there will be 20 points in the spline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    interpolated_curvatures: np.ndarray\n",
    "        1xN Numpy array of curvatures corresponding to the interpolated points.\n",
    "    interpolated_points: np.ndarray\n",
    "        2xN Numpy array of interpolated points generated from the spline of the\n",
    "        original points.\n",
    "    \"\"\"\n",
    "    # Ensure we do not alter the original points array\n",
    "    points = points.copy()\n",
    "\n",
    "    # Interpolate the data using cubic splines\n",
    "    num_points = interpolation_number * points.shape[0]\n",
    "    interpolated_points = _interpolate_points_spline(\n",
    "        points=points, num_points=num_points, smoothing=smoothing, periodic=periodic\n",
    "    )\n",
    "    x = interpolated_points[:, 0]\n",
    "    y = interpolated_points[:, 1]\n",
    "\n",
    "    # Calculate the curvature\n",
    "    interpolated_curvatures = _rim_curvature(x, y, periodic=bool(periodic))\n",
    "\n",
    "    return interpolated_curvatures, interpolated_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate curvature and ring masks\n",
    "\n",
    "\n",
    "def calculate_path_length(path: np.ndarray):\n",
    "    \"\"\"Calculate the length of a path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: np.ndarray\n",
    "        Nx2 numpy array of points in the path.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The length of the path.\n",
    "    \"\"\"\n",
    "    path_length = 0\n",
    "    for i in range(1, len(path)):\n",
    "        path_length += np.linalg.norm(path[i] - path[i - 1])\n",
    "    return path_length\n",
    "\n",
    "\n",
    "image_dict_curvatures = {}\n",
    "\n",
    "for index, image_dict_item in image_dict_ferets.items():\n",
    "    path = image_dict_item[\"path\"]\n",
    "\n",
    "    px_2_nm = image_dict_item[\"p_to_nm\"]\n",
    "\n",
    "    if px_2_nm > 0.59:\n",
    "        continue\n",
    "\n",
    "    # Check if the path is overall clockwise or counter-clockwise and reverse if necessary by summing over the edge points\n",
    "    # (x2 - x1)(y2 + y1)\n",
    "    # If the sum is positive, the path is clockwise, if negative, it is counter-clockwise\n",
    "    # clockwise_sum = 0\n",
    "    # for i in range(1, len(path)):\n",
    "    #     clockwise_sum += (path[i, 1] - path[i - 1, 1]) * (path[i, 0] + path[i - 1, 0])\n",
    "    # if clockwise_sum > 0:\n",
    "    #     path = np.flip(path, axis=0)\n",
    "\n",
    "    # # Plot the image, the path\n",
    "    plt.imshow(image_dict_item[\"image\"])\n",
    "    plt.plot(path[:, 1], path[:, 0], \"r-\")\n",
    "    plt.scatter(path[0, 1], path[0, 0], c=\"g\", s=50)\n",
    "    plt.scatter(path[-1, 1], path[-1, 0], c=\"b\", s=50)\n",
    "    plt.show()\n",
    "\n",
    "    path_length_pixels = calculate_path_length(path)\n",
    "    path_length_nm = path_length_pixels * px_2_nm\n",
    "    print(f\"path length: {path_length_nm} nm | {path_length_pixels} pixels\")\n",
    "\n",
    "    # Try to find a way to smooth consistently across different image sizes\n",
    "    smoothing = 4 * 1 / px_2_nm\n",
    "\n",
    "    # Calculate the curvature of the path\n",
    "    interpolated_curvatures, interpolated_points = interpolate_spline_and_get_curvature(\n",
    "        points=path, interpolation_number=2, smoothing=smoothing, periodic=1\n",
    "    )\n",
    "\n",
    "    # Convert interpolated curavtures to 1 / nm units\n",
    "    interpolated_curvatures_nm = interpolated_curvatures * 1 / px_2_nm\n",
    "\n",
    "    image_dict_curvatures[index] = image_dict_item\n",
    "    image_dict_curvatures[index][\"curvature\"] = interpolated_curvatures_nm\n",
    "    image_dict_curvatures[index][\"path_length_nm\"] = path_length_nm\n",
    "    image_dict_curvatures[index][\"smoothing\"] = smoothing\n",
    "    image_dict_curvatures[index][\"path_length_pixels\"] = path_length_pixels\n",
    "\n",
    "    # Keep cmap consistent across images\n",
    "    cmap = \"afmhot\"\n",
    "    cmap_max = 0.4\n",
    "    cmap_min = 0.0\n",
    "\n",
    "    # Plot the curvature\n",
    "    plt.imshow(image_dict_item[\"image\"])\n",
    "    # plt.plot(path[:, 1], path[:, 0], \"r-\")\n",
    "    plt.scatter(\n",
    "        interpolated_points[:, 1],\n",
    "        interpolated_points[:, 0],\n",
    "        c=interpolated_curvatures_nm,\n",
    "        cmap=\"afmhot\",\n",
    "        vmin=cmap_min,\n",
    "        vmax=cmap_max,\n",
    "        s=5,\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"p_2_nm: {px_2_nm} smoothing: {smoothing}\")\n",
    "\n",
    "    # Plot the curvature on another plot as a standard plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    ax.plot(interpolated_curvatures_nm)\n",
    "    ax.set_ylim(0.0, cmap_max)\n",
    "    # Draw a line at 0\n",
    "    # ax.axhline(0, c=\"k\")\n",
    "    ax.set_ylabel(\"Curvature (absolute, 1/nm)\")\n",
    "    # Set x ticks to be from 0 to the length of the path in nm\n",
    "    len_path_nm = len(path) * px_2_nm\n",
    "\n",
    "    # Get the x ticks\n",
    "    x_ticks = np.linspace(0, len(interpolated_curvatures_nm), 5)\n",
    "    # Create labels in nm\n",
    "    x_tick_labels = []\n",
    "    for tick in x_ticks:\n",
    "        tick_label = int((tick / len(interpolated_curvatures_nm)) * len_path_nm)\n",
    "        x_tick_labels.append(tick_label)\n",
    "    # Set the ticks and labels\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_tick_labels)\n",
    "    ax.set_xlabel(\"Distance along path (nm)\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the curvatures normalized to the same scale\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "for index, image_dict_item in image_dict_curvatures.items():\n",
    "    length_nm = image_dict_item[\"path_length_nm\"]\n",
    "    # Plot the curvature so that the x axis is in nm\n",
    "    ax.plot(\n",
    "        np.linspace(0, length_nm, len(image_dict_item[\"curvature\"])),\n",
    "        image_dict_item[\"curvature\"],\n",
    "        label=f\"{index}\",\n",
    "    )\n",
    "ax.set_ylabel(\"Curvature (absolute, 1/nm)\")\n",
    "ax.set_xlabel(\"Distance along path (nm)\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make another plot for the average curvature with error bars as the standard deviation at each point\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "max_nm_length = np.max([image_dict_curvatures[i][\"path_length_nm\"] for i in image_dict_curvatures])\n",
    "print(f\"max length: {max_nm_length}\")\n",
    "\n",
    "# For each nm in the range of the longest path, calculate the average curvature and standard deviation over all samples\n",
    "average_curvatures = []\n",
    "std_curvatures = []\n",
    "points_in_average = []\n",
    "interval = 0.5\n",
    "for nm in np.arange(0, max_nm_length, interval):\n",
    "    # print(f\"nm: {nm}\")\n",
    "    # For each sample, calculate the average curvature for the span of that nm\n",
    "    sample_average_curvatures_for_this_nm = []\n",
    "    for index, image_dict_item in image_dict_curvatures.items():\n",
    "        curvatures = image_dict_item[\"curvature\"]\n",
    "        path_length_nm = image_dict_item[\"path_length_nm\"]\n",
    "        # Create a list of the nm values for each pixel value in the curvature array\n",
    "        nm_values = np.linspace(\n",
    "            0, path_length_nm, len(curvatures)\n",
    "        )  # 0 to the length of the path in nm, using the length of the curvature array as the number of points\n",
    "        # Find the indices of the curvatures that are within the range of the current nm\n",
    "        indices = np.where((nm_values >= nm) & (nm_values < nm + 1))\n",
    "        # Calculate the average curvature for this sample over the range of the current nm\n",
    "        mean_curvature = np.mean(curvatures[indices])\n",
    "        # Check if the mean curvature is nan, if so, skip this sample\n",
    "        if np.isnan(mean_curvature):\n",
    "            continue\n",
    "        sample_average_curvatures_for_this_nm.append(mean_curvature)\n",
    "    # Calculate the average curvature for all samples for the current nm\n",
    "    average_curvature = np.mean(sample_average_curvatures_for_this_nm)\n",
    "    # print(f\"len sample average curvatures: {len(sample_average_curvatures_for_this_nm)}\")\n",
    "    std_curvature = np.std(sample_average_curvatures_for_this_nm)\n",
    "    average_curvatures.append(average_curvature)\n",
    "    std_curvatures.append(std_curvature)\n",
    "    points_in_average.append(len(sample_average_curvatures_for_this_nm))\n",
    "\n",
    "# Plot the average curvature with error bars, the size of the marker is proportional to the number of points in the average and the error bars in gray and the line in blue\n",
    "ax.errorbar(\n",
    "    np.arange(len(average_curvatures)),\n",
    "    average_curvatures,\n",
    "    yerr=std_curvatures,\n",
    "    fmt=\"-\",\n",
    "    markersize=5,\n",
    "    ecolor=\"gray\",\n",
    "    elinewidth=2,\n",
    "    capsize=5,\n",
    "    label=\"Average curvature\",\n",
    ")\n",
    "\n",
    "# Set just the plot background to dark gray\n",
    "# ax.set_facecolor(\"lightgray\")\n",
    "\n",
    "# Plot scatter plot overlaid on the average curvature plot where each point is the average curvature for a given nm and the colour is the number of points in the average\n",
    "# Plot the average curvature with error bars, and the standard deviation as the error. Error bars should be gray and the line should be coloured as a propotion of how many points are in the average\n",
    "colours = [num_points for num_points in points_in_average]\n",
    "# size= [num_points / np.max(points_in_average) * 100 for num_points in points_in_average]\n",
    "# Colour schemes to try: \"afmhot\", \"viridis\", \"cividis\", \"inferno\", \"plasma\", \"magma\", \"rainbow\"\n",
    "scatter_colourmap = \"rainbow\"\n",
    "ax.scatter(\n",
    "    np.arange(len(average_curvatures)),\n",
    "    average_curvatures,\n",
    "    c=colours,\n",
    "    s=50,\n",
    "    cmap=scatter_colourmap,\n",
    "    label=\"Average curvature\",\n",
    ")\n",
    "# Add a colorbar with maximum and minimum number of points in the average as the limits\n",
    "cbar = plt.colorbar(\n",
    "    ax.scatter(np.arange(len(average_curvatures)), average_curvatures, c=colours, cmap=scatter_colourmap)\n",
    ")\n",
    "cbar.set_label(\"Number of points in average\")\n",
    "\n",
    "ax.set_ylabel(\"Average curvature (absolute, 1/nm)\")\n",
    "ax.set_xlabel(\"Distance along path (nm)\")\n",
    "plt.suptitle(\n",
    "    f\"Average curvature along path for each nm position, irrespective of proportional distance along sample. Averaging interval: {interval} nm\"\n",
    ")\n",
    "# Subtitle\n",
    "plt.title(\"Error bars are the standard deviation of the average curvature for each nm position.\")\n",
    "\n",
    "# save the plot\n",
    "plt.savefig(IMAGE_SAVE_DIR / \"average_curvatures.png\")\n",
    "\n",
    "# Save the average curvatures and standard deviations to numpy files\n",
    "np.save(IMAGE_SAVE_DIR / \"average_curvatures.npy\", average_curvatures)\n",
    "np.save(IMAGE_SAVE_DIR / \"std_curvatures.npy\", std_curvatures)\n",
    "np.save(IMAGE_SAVE_DIR / \"points_in_average.npy\", points_in_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also do curvature as a function of proportional distance along the sample\n",
    "average_curvatures_proportional = []\n",
    "std_curvatures_proportional = []\n",
    "points_in_average_proportional = []\n",
    "percentage_interval = 0.05\n",
    "\n",
    "for percentage in np.arange(0, 1, percentage_interval):\n",
    "    # For each sample, calculate the average curvature for the span of that percentage\n",
    "    sample_average_curvatures_for_this_percentage = []\n",
    "    for index, image_dict_item in image_dict_curvatures.items():\n",
    "        curvatures = image_dict_item[\"curvature\"]\n",
    "        path_length_pixels = image_dict_item[\"path_length_pixels\"]\n",
    "        # Create a list of the percentage values for each pixel value in the curvature array\n",
    "        percentage_values = np.linspace(\n",
    "            0, 1, len(curvatures)\n",
    "        )  # 0 to the length of the path in nm, using the length of the curvature array as the number of points\n",
    "        # Find the indices of the curvatures that are within the range of the current percentage\n",
    "        indices = np.where((percentage_values >= percentage) & (percentage_values < percentage + percentage_interval))\n",
    "        # Calculate the average curvature for this sample over the range of the current percentage\n",
    "        mean_curvature = np.mean(curvatures[indices])\n",
    "        # Check if the mean curvature is nan, if so, skip this sample\n",
    "        if np.isnan(mean_curvature):\n",
    "            continue\n",
    "        sample_average_curvatures_for_this_percentage.append(mean_curvature)\n",
    "    # Calculate the average curvature for all samples for the current percentage\n",
    "    average_curvature = np.mean(sample_average_curvatures_for_this_percentage)\n",
    "    std_curvature = np.std(sample_average_curvatures_for_this_percentage)\n",
    "    average_curvatures_proportional.append(average_curvature)\n",
    "    std_curvatures_proportional.append(std_curvature)\n",
    "    points_in_average_proportional.append(len(sample_average_curvatures_for_this_percentage))\n",
    "\n",
    "\n",
    "# Plot the average curvature with error bars, the size of the marker is proportional to the number of points in the average and the error bars in gray and the line in blue\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.errorbar(\n",
    "    np.arange(len(average_curvatures_proportional)),\n",
    "    average_curvatures_proportional,\n",
    "    yerr=std_curvatures_proportional,\n",
    "    fmt=\"-\",\n",
    "    markersize=5,\n",
    "    ecolor=\"gray\",\n",
    "    elinewidth=2,\n",
    "    capsize=5,\n",
    "    label=\"Average curvature\",\n",
    ")\n",
    "\n",
    "# Set just the plot background to dark gray\n",
    "# ax.set_facecolor(\"lightgray\")\n",
    "\n",
    "# Plot scatter plot overlaid on the average curvature plot where each point is the average curvature for a given nm and the colour is the number of points in the average\n",
    "# Plot the average curvature with error bars, and the standard deviation as the error. Error bars should be gray and the line should be coloured as a propotion of how many points are in the average\n",
    "colours = [num_points for num_points in points_in_average_proportional]\n",
    "# size= [num_points / np.max(points_in_average) * 100 for num_points in points_in_average]\n",
    "# Colour schemes to try: \"afmhot\", \"viridis\", \"cividis\", \"inferno\", \"plasma\", \"magma\", \"rainbow\"\n",
    "scatter_colourmap = \"rainbow\"\n",
    "ax.scatter(\n",
    "    np.arange(len(average_curvatures_proportional)),\n",
    "    average_curvatures_proportional,\n",
    "    c=colours,\n",
    "    s=50,\n",
    "    cmap=scatter_colourmap,\n",
    "    label=\"Average curvature\",\n",
    ")\n",
    "# Add a colorbar with maximum and minimum number of points in the average as the limits\n",
    "cbar = plt.colorbar(\n",
    "    ax.scatter(\n",
    "        np.arange(len(average_curvatures_proportional)),\n",
    "        average_curvatures_proportional,\n",
    "        c=colours,\n",
    "        cmap=scatter_colourmap,\n",
    "    )\n",
    ")\n",
    "cbar.set_label(\"Number of points in average\")\n",
    "\n",
    "ax.set_ylabel(\"Average curvature (absolute, 1/nm)\")\n",
    "ax.set_xlabel(\"Proportional distance along path\")\n",
    "plt.suptitle(\n",
    "    f\"Average curvature along path for each proportional distance along sample. Averaging interval: {percentage_interval*100} %\"\n",
    ")\n",
    "# Subtitle\n",
    "plt.title(\"Error bars are the standard deviation of the average curvature for each proportional distance.\")\n",
    "\n",
    "# save the plot\n",
    "plt.savefig(IMAGE_SAVE_DIR / \"average_curvatures_proportional.png\")\n",
    "\n",
    "# Save the average curvatures and standard deviations to numpy files\n",
    "np.save(IMAGE_SAVE_DIR / \"average_curvatures_proportional.npy\", average_curvatures_proportional)\n",
    "np.save(IMAGE_SAVE_DIR / \"std_curvatures_proportional.npy\", std_curvatures_proportional)\n",
    "np.save(IMAGE_SAVE_DIR / \"points_in_average_proportional.npy\", points_in_average_proportional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-or-truck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
